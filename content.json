[{"title":"netty的一些基础概念","date":"2021-02-24T01:54:00.000Z","path":"2021/02/24/netty的一些基础概念/","text":"Java框架的问题就是概念很多，Netty作为“用Java必会的网络编程框架”，其实并不复杂，就是其他语言中的事件驱动。如果写过原生epoll的话，对这玩意儿不难理解。问题在于Java的框架抽象了一堆概念，所以重点就是把这些概念和其他语言中的东西做映射。 有一点要清楚：epoll其实是一个同步非阻塞模型，并不是异步的，只有AIO才是异步模型（但是AIO目前是通过线程池实现的，内核和用户态的上下文切换导致效率并不高）。同样，netty也是同步模型。 调用方式EpollEventLoop底层使用epoll实现多路复用。 EpollEventLoop中会初始化epollFd、eventFd、timerFd。 epollFd是调用系统方法生成的epoll对象，后续会使用其管理所有需要监听的fd eventFd是用于线程通讯，程序会把eventFd添加到epollFd中，监听eventFd，一旦eventFd有操作，则会唤醒调用epoll_wait的线程。 timerFd是用于计时，同样的监听timerFd，一旦时间到达，则会唤醒调用epoll_wait的线程。 每当连接接入或者断连，都会调用epoll_ctl_add/epoll_ctl_del方法来操作epoll对象。 在EpollEventLoop的run方法中，会调用epoll_wait来监听所有fd，一旦有fd就绪，会拷贝至EpollEventArray中，应用程序遍历EpollEventArray处理所有就绪事件。 概念解释","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"netty","slug":"netty","permalink":"http://yiuterran.github.io/tags/netty/"}]},{"title":"golang文件操作的一个坑","date":"2020-06-05T05:52:07.000Z","path":"2020/06/05/golang文件操作的一个坑/","text":"今天遇到一个蛋疼的问题，定位了很久，发现在windows上path.Dir获取的结果总是.，后来发现： 在windows上永远只用filepath这个库里面的函数，不要直接用path 哎，浪费了一上午=_=","tags":[{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"}]},{"title":"Workflow入门.md","date":"2020-05-21T03:31:49.000Z","path":"2020/05/21/Workflow入门/","text":"目前业务需要引入工作流引擎，现在开始调研相关技术和概念。目前开源的工作流引擎基本都是base在BPMN这套概念上的，所以对其深入了解是必须的（其实也很简单）。 入门文档最好的材料是国产的某个paas官方中文文档，比较翔实。 选型这块其实可选的很少，最知名的是Activiti，目前最新版本是7，亮点是支持k8s集成等云原生组件；然后就是Activiti早期版本fork出来的camunda；最后是Activiti后期版本fork出来的flowable. 这里我选择flowable，因为资料比较丰富，而且自带的前端界面有中文，方便内部使用。目前我们遇到的问题是不太清楚客户的具体需求，所以要使用工作流引擎保证可扩展性，但是不需要用户自己配置工作流（而是我们替他们配置好），所以自带的中文界面就比较重要了。这样是最简单快速的集成方案，后续可以自己实现一套前后端增删改查的接口，集成到自己的平台上。 那么这里主要描述如何将flowable集成到我们目前的系统里（一个SpringBoot项目，单db，暂时还没拆分成微服务）。 目标是： 搞清楚如何通过自带的界面创建表单、流程； 如何把flowable整合到现有的业务中； 理清楚flowable创建表格/数据的意义，自己开发对应的API； 准备工作因为是测试，所以先切换到一个新分支进行开发。然后根据官方指南，先把maven依赖集成到项目中： 12345&lt;dependency&gt; &lt;groupId&gt;org.flowable&lt;&#x2F;groupId&gt; &lt;artifactId&gt;flowable-spring-boot-starter&lt;&#x2F;artifactId&gt; &lt;version&gt;$&#123;flowable.version&#125;&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt; 我这里用的是最新的6.5.0版本，倒入依赖，重新编译项目。发现Jar包比原来大了13M左右，这个引擎的依赖还是挺多的… 在配置文件里加入 123flowable.async-executor-activate&#x3D;falseflowable.database-schema-update&#x3D;true# 必要的字体设置 注意后面那个必须设置为true，即使要手动建表。不过默认就是true，所以可以不设置。 第一次运行mvn clean install之后，mvn -o spring-boot:run -Drun.profiles=dev试图跑起来，结果发现缺失某个依赖，加上： 1234&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.module&lt;&#x2F;groupId&gt; &lt;artifactId&gt;jackson-module-jaxb-annotations&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt; 然后再跑，报beantaskExecutor报冲突。 这里可以自己配置一下异步线程，避免和自己定义的默认线程池冲突。 1234567891011121314151617181920212223242526272829303132333435363738@Configurationpublic class FlowableConfig &#123; @Process @Bean public TaskExecutor processTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(3); executor.setMaxPoolSize(10); executor.setQueueCapacity(100); executor.setKeepAliveSeconds(60); String threadNamePrefix = &quot;flowable-task-&quot;; executor.setThreadNamePrefix(threadNamePrefix); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(120); executor.initialize(); return executor; &#125; @Cmmn @Bean public TaskExecutor cmmnTaskExecutor() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(1); executor.setMaxPoolSize(5); executor.setQueueCapacity(100); executor.setKeepAliveSeconds(60); String threadNamePrefix = &quot;flowable-cmmn-&quot;; executor.setThreadNamePrefix(threadNamePrefix); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(120); executor.initialize(); return executor; &#125;&#125; 再跑，会报表不存在的错误。在datasource后面加上&amp;nullCatalogMeansCurrent=true，让程序自己建表。 不过建议还是手动建表，因为默认的编码有点问题。mysql的原始sql在https://raw.githubusercontent.com/flowable/flowable-engine/flowable-6.5.0/distro/sql/create/all/flowable.mysql.all.create.sql，下下来改一下编码到utf8mb4，然后手动建表。 现在再跑，应该一切正常了。可以看到flowable的表都是大写的，不管是字段还是表名。 概念官方中文指南在此 首先BPMN图形本质上是一段xml代码，然后我们又知道xml可以与bean映射，所以这就完美融合了，即BPMN就是“代码生成器”。 基本步骤首先通过手动或者springboot的自动注册生成ProcessEngine对象，即规则引擎的工厂（线程安全）。然后手动编写流程bpmn对应的xml，或者通过界面生成也行。 然后利用服务部署这个流程。 每个流程有一个唯一id，调用流程就是通过id启动流程。把参数传进去，开始状态机的转换。 未完待续","tags":[{"name":"flowable","slug":"flowable","permalink":"http://yiuterran.github.io/tags/flowable/"}]},{"title":"linux无人值守安装镜像制作.md","date":"2020-04-29T06:29:20.000Z","path":"2020/04/29/linux无人值守安装镜像制作/","text":"这里需要批量安装的是centos 7服务器版，首先下载centos 7最新版，带上GUI的镜像，装在虚拟机里面。然后下载centos 7 minimal镜像用作批量安装的母盘。 注意：不要装centos 8，这货特别大，而且没有图形化配置工具。 概述不同发行版支持的自动安装镜像技术不太一样，红帽这一系的主要使用kickstart，debian则使用preseed。这里安装的是centos7，所以用的主要是kickstart技术。 kickstart配置首先使用yum安装图形化工具system-config-kickstart，对语法熟悉的也可以不用这玩意儿直接撸。 把镜像挂在到centos里，然后cp -r(需要包含隐藏文件）光盘里面的所有的内容到某个路径，比如/root/iso/。在/root/iso下建立文件夹存放kickstart配置文件，比如/root/iso/kickstart/ks.cfg。 打开图形化配置工具kickstart，根据个人需求进行配置。具体可以参考这里的介绍。最后保存为刚才路径下的文件即可。 网络和个人帐户无需配置，因为可以离线安装。如果自己想装的额外的rpm包，使用repotrack工具下载到Packages文件夹里，在ks的packages部分中加入即可。 最后生成的ks文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465#platform&#x3D;x86, AMD64, 或 Intel EM64T#version&#x3D;DEVEL# Install OS instead of upgradeinstall# Keyboard layoutskeyboard &#39;us&#39;# Root passwordrootpw --iscrypted $1$0Rnj3JYy$.O6bjrhyiBucwxVpIg8eF1# System languagelang en_US# System authorization informationauth --useshadow --passalgo&#x3D;sha512# Use CDROM installation mediacdrom# Use text mode installtext# SELinux configurationselinux --disabled# Do not configure the X Window Systemskipx# System bootloader configurationbootloader --location&#x3D;mbr# Firewall configurationfirewall --disabledservices --disabled&#x3D;&quot;chronyd&quot;services --enabled&#x3D;&quot;sshd&quot;# System timezonetimezone Asia&#x2F;Shanghai# Clear the Master Boot Recordzerombr# Partition clearing informationclearpart --all --initlabel# Disk partitioning informationpart &#x2F;boot --fstype&#x3D;&quot;xfs&quot; --size&#x3D;500part &#x2F;boot&#x2F;efi --fstype&#x3D;&quot;xfs&quot; --size&#x3D;500part swap --fstype&#x3D;&quot;swap&quot; --size&#x3D;1024part &#x2F; --fstype&#x3D;&quot;ext4&quot; --grow --size&#x3D;1poweroff%packages --multilib --ignoremissinglrzsznet-toolsopensslpython3screentcpdumpzipunzipvim-enhancedwgetyum-utilsnanoNetworkManager-tui%end%addon com_redhat_kdump --enable --reserve-mb&#x3D;&#39;auto&#39;%end%post --nochrootcp -fr &#x2F;mnt&#x2F;install&#x2F;repo&#x2F;plus&#x2F;* &#x2F;mnt&#x2F;sysimage&#x2F;root&#x2F;echo &quot;&#x2F;bin&#x2F;bash &#x2F;root&#x2F;init.sh&quot; &gt;&gt; &#x2F;mnt&#x2F;sysimage&#x2F;etc&#x2F;rc.localchmod a+x &#x2F;mnt&#x2F;sysimage&#x2F;etc&#x2F;rc.local%end 其他配置每次修改packages里面的安装条目，需要重新生成repo数据库，语法是在镜像根目录执行createrepo -g repodata/xxxx-c7-minimal-x86_64-comps.xml .，文件的名字可能是一串随机字符，根据个人情况生成。 下面是修改isolinux.cfg保证使用kickstart文件： 1234567891011121314default vesamenu.c32timeout 50#省略一部分label linux menu label ^Auto Install CentOS 7 menu default kernel vmlinuz append initrd&#x3D;initrd.img inst.stage2&#x3D;hd:LABEL&#x3D;CENTOS7 inst.ks&#x3D;hd:LABEL&#x3D;CENTOS7:&#x2F;kickstart&#x2F;ks.cfg quiet# 省略一部分menu end 注意这里通过label指定ks文件的路径，防止U盘安装的时候找不到路径。卷标名在生成iso文件的时候可以修改，尽量不要用空格。 同样在EFI/BOOT/grub.cfg里面增加一个入口： 1234menuentry &#39;Auto Install CentOS 7&#39; --class fedora --class gnu-linux --class gnu --class os &#123; linuxefi &#x2F;images&#x2F;pxeboot&#x2F;vmlinuz inst.stage2&#x3D;hd:LABEL&#x3D;CENTOS7 inst.ks&#x3D;hd:LABEL&#x3D;CENTOS7:&#x2F;kickstart&#x2F;ks.cfg quiet initrdefi &#x2F;images&#x2F;pxeboot&#x2F;initrd.img&#125; 生成iso文件123cd /root/iso &amp;&amp; mkisofs -v -cache-inodes -joliet-long -R -J -T -V CENTOS7 -o /root/centos7.iso -c isolinux/boot.cat -b isolinux/isolinux.bin -no-emul-boot -boot-load-size 4 -boot-info-table -eltorito-alt-boot -e images/efiboot.img -no-emul-boot .isohybrid /root/centos7.isoimplantisomd5 /root/centos7.iso 上面是一个简单的脚本用来生成iso文件，注意这里使用-V改了卷标，和上面的hd:label保持一致。最后的alt-boot是efi启动支持。 最后使用dd刻盘到u盘，就可以安装了。 自动配置脚本注意到ks文件的post段里面，创建了一个一次性自运行的服务。在镜像根目录下创建plus文件夹，把想要复制到系统的文件都拷贝进去。cp -fr /mnt/install/repo/plus/* /mnt/sysimage/root/这句会将所有的文件拷贝到/root/目录下。 其中init.sh的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117#!/bin/bash# wait other service startsleep 5# iot-devicemv /root/cron /etc/cron.d/iot-device# paramsecho &quot;&quot; &gt;&gt; /etc/ssh/sshd_configecho &quot;ClientAliveInterval 30&quot; &gt;&gt; /etc/ssh/sshd_configecho &quot;ClientAliveCountMax 86400&quot; &gt;&gt; /etc/ssh/sshd_configecho &quot;* - noproc 11000&quot; &gt;&gt; /etc/security/limits.confecho &quot;root soft nofile 1048576&quot; &gt;&gt; /etc/security/limits.confecho &quot;root hard nofile 1048576&quot; &gt;&gt; /etc/security/limits.confecho &quot;* hard nofile 1048576&quot; &gt;&gt; /etc/security/limits.confecho &quot;* soft nofile 1048576&quot; &gt;&gt; /etc/security/limits.confecho &quot;fs.file-max = 1048576&quot; &gt;&gt; /etc/sysctl.confecho &quot;net.core.somaxconn=32768&quot; &gt;&gt; /etc/sysctl.confecho &quot;DefaultLimitNOFILE=1048576&quot; &gt;&gt; /etc/systemd/system.confsysctl -psysctl -w net.core.somaxconn=32768sysctl -w net.ipv4.tcp_max_syn_backlog=16384sysctl -w net.core.netdev_max_backlog=16384sysctl -w net.ipv4.ip_local_port_range=&#x27;1000 65535&#x27;sysctl -w net.core.rmem_default=262144sysctl -w net.core.wmem_default=262144sysctl -w net.core.rmem_max=16777216sysctl -w net.core.wmem_max=16777216sysctl -w net.core.optmem_max=16777216sysctl -w net.ipv4.tcp_rmem=&#x27;1024 4096 16777216&#x27;sysctl -w net.ipv4.tcp_wmem=&#x27;1024 4096 16777216&#x27;sysctl -w net.ipv4.tcp_max_tw_buckets=1048576sysctl -w net.ipv4.tcp_fin_timeout=15sed -i &#x27;/.*init.*/d&#x27; /etc/rc.local# 清空在安装阶段从光盘安装的所有文件rm -fr /mnt/*rm /root/*.cfgrm /root/TRAN*rm $0#主动启动网卡interface=$(ls /sys/class/net| grep -v &quot;lo&quot; | head -1)ifup $interfaceif [$? -ne 0];then echo &quot;can&#x27;t start network, please run nmtui to connect Wi-Fi&quot; exit 1fi#获取当前网络信息default_route=$(ip route show)default_interface=$(echo $default_route | sed -e &#x27;s/^.*dev \\([^ ]*\\).*$/\\1/&#x27; | head -n 1)address=$(ip addr show label $default_interface scope global | awk &#x27;$1 == &quot;inet&quot; &#123; print $2,$4&#125;&#x27;)ip=$(echo $address | awk &#x27;&#123;print $1 &#125;&#x27;)ip=$&#123;ip%%/*&#125;mask=$(route -n |grep &#x27;U[ \\t]&#x27; | head -n 1 | awk &#x27;&#123;print $3&#125;&#x27;)gateway=$(route -n | grep &#x27;UG[ \\t]&#x27; | awk &#x27;&#123;print $2&#125;&#x27;)dns=$(cat /etc/resolv.conf | grep nameserver | awk &#x27;&#123;print $2&#125;&#x27;)#判断default_interface是否为空if [ -z $default_interface ]then default_interface=$interfacefi#显示网络信息echo -e &quot;The current net info [dynamic]&quot;echo -e &quot;------------------------------------------&quot;echo -e &quot; device: $default_interface&quot;echo -e &quot; ipaddr: $ip&quot;echo -e &quot;netmask: $mask&quot;echo -e &quot;gateway: $gateway&quot;echo -e &quot; dns: $dns&quot;echo -e &quot;------------------------------------------&quot;echo -e &quot;&quot;# set last ip to 200IFS=&#x27;.&#x27; read -r -a array &lt;&lt;&lt; &quot;$ip&quot;array[3]=200newip=$(IFS=. eval &#x27;echo &quot;$&#123;array[*]&#125;&quot;&#x27;)echo &quot;newip is $newip&quot;#网络配置cp /etc/sysconfig/network-scripts/ifcfg-$default_interface /etc/sysconfig/network-scripts/ifcfg-$default_interface.bakuuid=$(cat /etc/sysconfig/network-scripts/ifcfg-$default_interface |grep UUID|sed -e &#x27;s/&quot;//g&#x27;)echo &quot;IPV6INIT=yes&quot; &gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;IPV6_AUTOCONF=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;BOOTPROTO=none&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;DEVICE=$default_interface&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;ONBOOT=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;$uuid&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;TYPE=Ethernet&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;PROXY_METHOD=none&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;BROWSER_ONLY=no&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;IPADDR=$newip&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;NETMASK=$mask&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;GATEWAY=$gateway&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;DNS1=114.114.114.114&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;DEFROUTE=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;IPV4_FAILURE_FATAL=no&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;IPV6_DEFROUTE=yes&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interfaceecho &quot;IPV6_FAILURE_FATAL=no&quot; &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-$default_interface#DNS配置cp /etc/resolv.conf /etc/resolv.conf.bakecho &quot;# Generated by NetworkManager&quot; &gt; /etc/resolv.confecho &quot;nameserver 114.114.114.114&quot; &gt;&gt; /etc/resolv.conf#重启一下网络 使配置生效systemctl restart networksleep 5ping -c 4 www.baidu.comif [ $? != 0 ]then echo -e &quot;Error! Cant link to Internet&quot; #breakfi 简单来说，根据dhcp自动配置的ip地址，将其最后一位换成200，改成静态ip写死。如果怕ip地址冲突，直接将获得的ip写成静态ip也可以。然后是一些常见服务器参数的改写，最后是禁止并删除掉一次性脚本的自启动，然后删除掉自身。 如果需要做一些服务相关配置，在这里也可以初始化，比如配置cron定期检查更新。 上面ks文件设置了安装完毕后自动关机，在合适的环境下插上网线开机，就会自动运行上面的初始化脚本，安装好服务。 无线网卡如果不是插网线，而是用无线网卡，这里的逻辑就比较复杂，必须让用户手动设置Wi-Fi。然后再手动运行脚本设置为静态ip。 在Package里面增加NetworkManager-tui这个包，init.sh里面判断如果ifup失败，就直接退出。 此时需要用户运行nmtui设置好Wi-Fi（注意Wi-Fi的ssid应为英文，不然显示是乱码）。然后运行如下脚本来将Wi-Fi设置成静态ip： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#获取当前网络信息default_route=$(ip route show)default_interface=$(echo $default_route | sed -e &#x27;s/^.*dev \\([^ ]*\\).*$/\\1/&#x27; | head -n 1)address=$(ip addr show label $default_interface scope global | awk &#x27;$1 == &quot;inet&quot; &#123; print $2,$4&#125;&#x27;)ip=$(echo $address | awk &#x27;&#123;print $1 &#125;&#x27;)ip=$&#123;ip%%/*&#125;mask=$(route -n |grep &#x27;U[ \\t]&#x27; | head -n 1 | awk &#x27;&#123;print $3&#125;&#x27;)gateway=$(route -n | grep &#x27;UG[ \\t]&#x27; | awk &#x27;&#123;print $2&#125;&#x27;)dns=$(cat /etc/resolv.conf | grep nameserver | awk &#x27;&#123;print $2&#125;&#x27;)#判断default_interface是否为空if [ -z $default_interface ]then echo &quot;no working network, exit! if you want to use Wi-Fi, please run nmtui to set&quot; exit 1ficfg_name=$(cd /etc/sysconfig/network-scripts &amp;&amp; grep -l Wireless *|grep ifcfg)echo &quot;config file is $cfg_name&quot;#download iot-device/bin/python3 /root/cron_update.py#显示网络信息echo -e &quot;The current net info [dynamic]&quot;echo -e &quot;------------------------------------------&quot;echo -e &quot; device: $default_interface&quot;echo -e &quot; ipaddr: $ip&quot;echo -e &quot;netmask: $mask&quot;echo -e &quot;gateway: $gateway&quot;echo -e &quot; dns: $dns&quot;echo -e &quot;------------------------------------------&quot;echo -e &quot;&quot;# set last ip to 200IFS=&#x27;.&#x27; read -r -a array &lt;&lt;&lt; &quot;$ip&quot;array[3]=200newip=$(IFS=. eval &#x27;echo &quot;$&#123;array[*]&#125;&quot;&#x27;)#网络配置cp /etc/sysconfig/network-scripts/$cfg_name /etc/sysconfig/network-scripts/$cfg_name.baksed -i &quot;/.*dhcp.*/d&quot; /etc/sysconfig/network-scripts/$cfg_nameecho &quot;IPADDR=$newip&quot; &gt;&gt; /etc/sysconfig/network-scripts/$cfg_nameecho &quot;NETMASK=$mask&quot; &gt;&gt; /etc/sysconfig/network-scripts/$cfg_nameecho &quot;GATEWAY=$gateway&quot; &gt;&gt; /etc/sysconfig/network-scripts/$cfg_nameecho &quot;DNS1=114.114.114.114&quot; &gt;&gt; /etc/sysconfig/network-scripts/$cfg_nameifdown $cfg_name &amp;&amp; ifup $cfg_namesleep 5ping -c 4 www.baidu.comif [ $? != 0 ]then echo -e &quot;Error! Cant link to Internet&quot;fiecho &quot;current ip is $newip&quot; 这里仍然是直接设置成200，实际使用的时候可以根据情况编辑。","tags":[{"name":"linux","slug":"linux","permalink":"http://yiuterran.github.io/tags/linux/"},{"name":"devops","slug":"devops","permalink":"http://yiuterran.github.io/tags/devops/"}]},{"title":"mybatis-plus自定义枚举","date":"2020-02-18T01:53:04.000Z","path":"2020/02/18/mybatis自定义枚举/","text":"问题概述枚举值在db中存储一般是整形或者字符串，在代码里一般是枚举。我们的需求是在model里使用一种自定义类型，能够： 校验用户提供的数据在枚举允许范围内，否则自动报错； 在输出给用户时，json序列化自动加上枚举的中文含义； 自动通过json反序列化到该类型； 存入db时自动转化为对应的整形和字符串； 从db中取出数据时自动转为该自定义类型； 其中1通过自定义validator实现，2/3通过自定义序列化/反序列化实现，4/5通过自定义typeHandler实现。 数据字典枚举值有两种实现方式：写死在代码里，或者使用数据字典存储在db/redis里。下面只介绍数据字典存储在db里的方案，其他几种情况处理手段类似。假设数据字典sys_dict包括以下几列： 123feat_code varchar(64) default &#x27;&#x27; not null comment &#x27;英文代码&#x27;,value_str varchar(32) default &#x27;&#x27; not null comment &#x27;枚举值&#x27;,value_cn varchar(128) default &#x27;&#x27; not null comment &#x27;枚举值（中文）&#x27;, 并且使用以下服务： 123456789101112131415161718192021@Servicepublic class SysDictService extends ServiceImpl&lt;SysDictMapper, SysDict&gt; &#123; @Cacheable(cacheNames = Constants.AUTO_CACHE_PREFIX) public Map&lt;String, String&gt; getCodeEnums(@NotNull String code) &#123; Wrapper&lt;SysDict&gt; wrapper = new QueryWrapper&lt;SysDict&gt;() .eq(SysDict.COL_FEAT_CODE, code); return this.list(wrapper).stream().collect( Collectors.toMap( SysDict::getValueStr, SysDict::getValueCN ) ); &#125; public boolean isValidValue(String key, String value) &#123; Wrapper&lt;SysDict&gt; wrapper = new QueryWrapper&lt;SysDict&gt;() .eq(SysDict.COL_FEAT_CODE, key) .eq(SysDict.COL_VALUE_STR, value); return this.getOne(wrapper) != null; &#125;&#125; 定义自定义类型使用内置枚举类型mybatis-plus其实内置了这部分支持，不过他是直接将枚举值替换成对应的中文。我们在此基础上进行扩展： 12345678910111213public interface IDictEnum&lt;T extends Serializable&gt; extends IEnum&lt;T&gt; &#123; /** * 数据库中存储的值 */ @JsonValue @Override T getValue(); /** * 从数据库保存的字典ID */ String getDictCode();&#125; 使用的时候，自定义枚举类型实现上述接口。例如： 12345678910111213141516171819public enum CorpKindEnum implements IDictEnum&lt;Integer&gt; &#123; CORPORATION(0), GOVERNMENT(1), COMMON(2); private Integer v; CorpKindEnum(Integer v) &#123; this.v = v; &#125; @Override public Integer getValue() &#123; return v; &#125; @Override public String getDictCode() &#123; return &quot;CORP_KIND_CODE&quot;; &#125;&#125; 这是一个整形枚举，我们使用CORP_KIND_CODE作为feat_code，在数据字典里插入对应的值和中文释疑。自定义Json序列化如下： 1234567891011121314151617181920212223242526272829303132333435363738@Componentpublic class DictEnumSerializer extends JsonSerializer&lt;IDictEnum&gt; &#123; private static SysDictService service; //JsonSerializer初始化比bean更早，所以不能直接字段注入 @Autowired public DictEnumSerializer(SysDictService service) &#123; DictEnumSerializer.service = service; &#125; public DictEnumSerializer() &#123; super(); &#125; @Override public void serialize(IDictEnum value, JsonGenerator generator, SerializerProvider provider) throws IOException &#123; if (value == null) &#123; generator.writeNull(); return; &#125; generator.writeObject(value.getValue()); generator.writeFieldName(generator.getOutputContext().getCurrentName() + &quot;CN&quot;); generator.writeString(getEnumDesc(value)); &#125; @Override public Class handledType() &#123; return IDictEnum.class; &#125; private String getEnumDesc(IDictEnum dictEnum) &#123; Map&lt;String, String&gt; map = service.getCodeEnums(dictEnum.getDictCode()); return map.get(dictEnum.getValue().toString()); &#125;&#125; 这里在序列化的时候将字段名后面加上CN，同时通过数据字典查询对应的中文含义注入。 由于我们这里扩展了mybatis-plus的内置类型，使用时就不需要加上typeHandler的注解了。 问题：jackson在通过整数反序列化到枚举时，无法通过指定的值来反序列化，而是通过整数的顺序(ordinal)来进行的。如果枚举类型不是从0-N这种赋值，则反序列化结果不正确。这是一个存在历史很悠久的bug。 解决方案是在枚举里自定义JsonCreator： 123456789@JsonCreatorpublic static CorpKindEnum fromValue(Integer v) &#123; for (CorpKindEnum element : values()) &#123; if (element.getValue().equals(v)) &#123; return element; &#125; &#125; return null; //or throw exception if you like...&#125; 由于Java语言的限制，我们无法扩展内置的enum类型，所以每个自定义枚举上都要自己加上JsonCreator。一个简单的解决方案是全部使用字符串枚举，当然这会比使用integer更慢，也比tinyint/smallint更占数据库空间。 使用自定义类上述方案可以解决大部分枚举的问题。但是有些情况下，枚举值特别多，我们又不想在代码里全部列出来，这时候使用内置枚举类型就不太合适了。我们自定义一个抽象类： 123456789101112131415@EqualsAndHashCode@ToStringpublic abstract class BaseDictValue&lt;T extends Serializable&gt; implements IDictEnum&lt;T&gt; &#123; @Setter private T value; public BaseDictValue(T value) &#123; this.value = value; &#125; @Override public T getValue() &#123; return value; &#125;&#125; 可以看到实际上和刚才的接口是一致的，不再赘述。然后我们实现自定义的typeHandler： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Slf4jpublic class DictValueHandler&lt;E extends BaseDictValue&lt;?&gt;&gt; extends BaseTypeHandler&lt;E&gt; &#123; private final Class&lt;E&gt; type; public DictValueHandler(Class&lt;E&gt; type) &#123; if (type == null) &#123; throw new IllegalArgumentException(&quot;Type argument cannot be null&quot;); &#125; this.type = type; &#125; @Override public void setNonNullParameter(PreparedStatement ps, int i, E e, JdbcType jdbcType) throws SQLException &#123; ps.setObject(i, e.getValue()); &#125; private E convertResult(Object vs) &#123; if (vs == null) &#123; return null; &#125; try &#123; if (vs instanceof Number) &#123; //这里假设枚举只有整数和字符串两种类型，理论上够用了 return type.getConstructor(Integer.class).newInstance(vs); &#125; return type.getConstructor(String.class).newInstance(vs); &#125; catch (Exception e) &#123; log.error(&quot;fail to construct dict value&quot;, e); return null; &#125; &#125; @Override public E getNullableResult(ResultSet resultSet, String s) throws SQLException &#123; return convertResult(resultSet.getObject(s)); &#125; @Override public E getNullableResult(ResultSet resultSet, int i) throws SQLException &#123; return convertResult(resultSet.getObject(i)); &#125; @Override public E getNullableResult(CallableStatement callableStatement, int i) throws SQLException &#123; return convertResult(callableStatement.getObject(i)); &#125;&#125; 然后自定义序列化仍然复用刚才的即可（因为该抽象类实现了对应的接口）。 最后将刚才的枚举类改成这样： 123456789101112131415@EqualsAndHashCode(callSuper = true)@ToString(callSuper=true)public class CorpKindEnum extends BaseDictValue&lt;Integer&gt; &#123; public static final Integer CORPORATION = 0; //只需要用来解析的一些枚举，不必全部列出所有枚举值了… @JsonCreator public CorpKindEnum(Integer v) &#123; super(v); &#125; @Override public String getDictCode() &#123; return &quot;CORP_KIND_CODE&quot;; &#125;&#125; 这里必须要实现一个单参数构造函数，用来转换对应的基础类型，并将其标注为@JsonCreator用来反序列化。 注意事项 如果要使用mybatis-plus自带的函数进行增删改查，需要在model的@TableName里标注autoResultMap = true；并在对应的字段的@TableField里标注typeHandler = DictValueHandler.class，这样才能正确的进行orm类型转换； 同样，如果自己写resultMap想要进行类型转换，也要在xml里指定上述typeHandler。 参数校验这个简单，写一个自定义注解： 12345678@Target(ElementType.FIELD)@Retention(RetentionPolicy.RUNTIME)@Constraint(validatedBy = DictFieldValidator.class)public @interface DictField &#123; String message() default &quot;参数错误，枚举值不在允许范围内&quot;; Class&lt;?&gt;[] groups() default &#123;&#125;; Class&lt;? extends Payload&gt;[] payload() default &#123;&#125;;&#125; 然后实现校验逻辑： 123456789101112131415@Componentpublic class DictFieldValidator implements ConstraintValidator&lt;DictField, Object&gt; &#123; @Autowired private SysDictService service; @Override public boolean isValid(Object o, ConstraintValidatorContext constraintValidatorContext) &#123; if (o instanceof IDictEnum) &#123; IDictEnum v = (IDictEnum) o; return service.isValidValue(v.getDictCode(), v.getValue().toString()); &#125; return false; &#125;&#125; 用的时候，在对应的字段上加上@DictField注解，对应的类参数前面加上@Valid或者@Validated就可以了. 题外话 mybatis-plus自带了一个JacksonTypeHandler，可以将数据库字段转换成任意类型，它的原理和上面是一致的。 上述Jackson的Serializer需要通过SimpleModule手动注册上去。在springboot中可以通过bean进行配置。这里给一个参考配置： 1234567891011121314151617181920212223242526@Beanpublic ObjectMapper objectMapper() &#123; ObjectMapper objectMapper = new ObjectMapper(); // 对于空的对象转json的时候不抛出错误 objectMapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS); // 禁用遇到未知属性抛出异常 objectMapper.disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES); // 序列化BigDecimal时不使用科学计数法输出 objectMapper.configure(JsonGenerator.Feature.WRITE_BIGDECIMAL_AS_PLAIN, true); //自定义枚举序列化 DictEnumSerializer dictEnumSerializer = new DictEnumSerializer(); SimpleModule simpleModule = new SimpleModule(); simpleModule.addSerializer(dictEnumSerializer); // 日期和时间格式化 JavaTimeModule javaTimeModule = new JavaTimeModule(); javaTimeModule.addSerializer(LocalDateTime.class, new LocalDateTimeSerializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;))); javaTimeModule.addSerializer(LocalDate.class, new LocalDateSerializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;))); javaTimeModule.addSerializer(LocalTime.class, new LocalTimeSerializer(DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;))); javaTimeModule.addDeserializer(LocalDateTime.class, new LocalDateTimeDeserializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;))); javaTimeModule.addDeserializer(LocalDate.class, new LocalDateDeserializer(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;))); javaTimeModule.addDeserializer(LocalTime.class, new LocalTimeDeserializer(DateTimeFormatter.ofPattern(&quot;HH:mm:ss&quot;))); javaTimeModule.addSerializer(Date.class, new DateSerializer(false, new SimpleDateFormat(&quot;yyyy-MM-dd HH:mm:ss&quot;))); objectMapper.registerModule(javaTimeModule); objectMapper.registerModule(simpleModule); return objectMapper;&#125;","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"mybatis","slug":"mybatis","permalink":"http://yiuterran.github.io/tags/mybatis/"},{"name":"json","slug":"json","permalink":"http://yiuterran.github.io/tags/json/"},{"name":"spring","slug":"spring","permalink":"http://yiuterran.github.io/tags/spring/"}]},{"title":"gb28181实现调研","date":"2019-12-23T02:48:56.000Z","path":"2019/12/23/gb28181实现调研/","text":"由于工地接入的摄像头五花八门，依靠厂家提供的平台不足以满足需求。公司需要直连摄像头和NVR进行视频取流等工作，我现在进行技术调研。 首先直接搜gb28181的话，可以看到github上有一个c#的平台，用的.net core实现。然后仔细看相关文档，你会发现这玩意用了sip协议，后者开源的框架就相当多了，不过大部分是c/c++的，纯c的比较多。java的实现也有比较完整的版本，但是很久没更新了。go的话，目前还没有比较稳定的开源实现，有一些不太完整的版本。 视频流这块，用了RTP/RTCP协议，发送的是PS流，发送给客户端的话，需要转换成可以拿来直播的其他流。 换句话说，我们需要实现一个sip网关用来进行控制，和一个媒体流网关用来传输实时媒体数据。 如果想要做嵌入式网关的话，推荐用纯C版本的库(pjsip实现了sip/RTP/RTCP/RTSP等所有的功能，live555/ffmpeg和gstreamer都是C实现)，自己写上层C++代码实现。 考虑开发速度可以用高等语言来写其中的一部分，那个开源的.net core就是用C#写的（但是没有流媒体相关的实现）。为了熟悉协议，也可以自己先造个轮子（工作量很大）。 值得注意的是标准的SDP协议部分使用了扩展字段y，一般开源代码并不支持，需要拿到源码!进行修改。 协议解析github上那个c#的repo里面有协议的pdf文件，可以先下载下来。以下部分内容直接引用自协议文本。 安全注册、实时视音频点播、历史视音频的回放等应用的会话控制采用IETFRFC3261规定的 Register、Invite 等请求和响应方法实现,历史视音频回放控制采用SIP扩展协议IETFRFC2976规定的INFO方法实现,前端设备控制、信息查询、报警事件通知和分发等应用的会话控制采用SIP扩展协议IETFRFC3428规定的Mesage方法实现。 这里提到的几个方法，都是SIP协议规定的内容。SIP基于TCP/UDP，在应用层是纯文本协议，类似HTTP，也可以使用证书进行加密。 类似HTTP，sip有标准的header和body。一个标准的SIP Message请求如下： 12345678910111213141516171819To:sip:目的设备编码@目的域名CSeq:1 MessageCal-ID:a84b4c76e66710Via:SIP&#x2F;2.0&#x2F;UDP源域名或IP地址From:&lt;sip:源设备编码@源域名&gt;;tag&#x3D;237f57dcContent-Type:Application&#x2F;MANSCDP+xmlMax-Forwards:69Content-Length:消息实体的字节长度&lt;?xmlversion&#x3D;&quot;1.0&quot;?&gt;&lt;Control&gt;&lt;CmdType&gt;DeviceControl&lt;&#x2F;CmdType&gt;&lt;SN&gt;11&lt;&#x2F;SN&gt;&lt;DeviceID&gt;64010000041310000345&lt;&#x2F;DeviceID&gt;&lt;PTZCmd&gt;A50F4D1000001021&lt;&#x2F;PTZCmd&gt;&lt;Info&gt;&lt;ControlPriority&gt;5&lt;&#x2F;ControlPriority&gt;&lt;&#x2F;Info&gt;&lt;&#x2F;Control&gt; 注意sip是长链接协议，所以规定了标准的register流程。 经过实际调研，最终决定暂时搁置这块的开发，其实SIP服务器实现起来不难，关键是流媒体转码相关的技术水比较深。目前公司还有其他优先级更高的事情，本文等待后续更新。","tags":[{"name":"camera","slug":"camera","permalink":"http://yiuterran.github.io/tags/camera/"},{"name":"design","slug":"design","permalink":"http://yiuterran.github.io/tags/design/"}]},{"title":"通用多租户自定义角色权限模型","date":"2019-12-23T01:25:55.000Z","path":"2019/12/23/通用多租户自定义角色权限模型/","text":"前段时间在忙一个saas系统的设计，这里总结一下经验。 首先是用户付费方式一般以模块的形式进行，如果saas系统各租户的需求在细节上有很多不同，那就要对模块进行一些微调，在代码上使用策略模式进行归类区分抽象。但是总的来说，系统大的功能点应该相差不大，否则就属于定制化开发的范畴了。 权限系统可以抽象为以下部分： 功能点。功能点是一个全集，与后台的API对应。不同用户能够看到的功能点是不一样的，这取决于购买的需求； UI。功能点对应的UI可以由很多套，不同平台的客户端，不同版本的移动端，都可能有不同的UI；功能点分别关联到UI和API； 角色。各租户除了内置的管理员，其他角色可以由用户自己定义；注意：并不是所有的saas系统都有这种需求，统一设计角色的话，系统设计会精简很多； 权限。角色在定义的时候关联了功能点的权限。 详细解释如下—— 功能点系统按着模块拆分功能点，功能点是最细的权限粒度。保证UI和API相对功能点都是一对多的关系，不存在多对多的关系。 如果感觉用户操作功能点分配权限过于繁琐，可以对功能点做一个功能集，这样分配的粒度就会比较粗，但是也可以随时细化。 功能点都有一个对应的权限描述方式，可以采用二进制位运算表示，也可以用权限字符串（参考shiro）。如果权限的判定需要根据用户请求的参数来决定，那就要动态的权限字符串（参考spel）。我这里用了spel的方式来描述权限，可以用Spring security来实现，或者自己用Spring AOP写一个权限描述。最后的形式类似于#prj:device:view，表示某个project的设备查看。 每个API都有自己的权限需求，这与功能点的权限描述字符串对应。这里也是一对多的关系，API可以要求多个权限。用户必须拥有全部权限才能访问API。 功能点理论上也是树型的，不过某些功能点可能对其他功能点有额外的依赖。 UIUI分为两部分，一个是匹配规则，一个是UI树本身。 这个比较简单，就是为不同版本、产品，甚至租户设置不同的UI，根据客户端的情况和用户的功能点权限返回UI树给用户渲染。 UI树不一定需要在服务器存一套完整的，需要权限控制的部分才需要存入数据库。 角色简单起见，只有租户的管理员才可以给组织建立对应的角色树。 角色树关联功能点，某些功能点可能和具体的数据有关，需要额外选择。 数据权限指的是不同人看到的字段都不一样，或者字段的渲染不一样。 这个比较麻烦，不太好做成通用的。非要做的话，每个API返回的字段都要存到表里，然后在功能点那一层，最后关联到字段。即#prj:device:view:field，但是这样太过繁琐，对执行效率影响很大。如果没有很通用的需求，可以在代码里对一些特殊API做单独的处理。","tags":[{"name":"design","slug":"design","permalink":"http://yiuterran.github.io/tags/design/"}]},{"title":"sass项目顶层设计","date":"2019-11-19T07:42:52.000Z","path":"2019/11/19/sass项目顶层设计/","text":"概述sass本质上是想做一个标准化的平台，供使用者接入。但是由于接入者是付费方，或者说甲方，对于平台使用中总会有各种各样的诉求，这就导致平台在开发过程中总是会收到各种各样的定制化需求。如何处理标准化与定制化之间的取舍成为每个saas平台都要面临的问题。 几个需要讨论的问题： 所在行业是否能够做成saas，这是立项之基。很多事情表面上看可以抽象成同一种模式，实际实行起来千差万别，这就导致很难对行业进行标准化的过程抽象。做起来会淹没在无尽的需求细节之中； 平台的服务边界在哪里。既然要做标准化，那就要知道哪些是平台应该提供的，哪些集成第三方的； 如何架构系统。saas要满足多租户需求，即一套平台，N种接入。后端服务拆分/微服务化，前端组件化是一种必须；理想情况下，可以做到前端一套代码，根据后端配置动态渲染客户所需的页面；后端接入新客户时，只需要运营在中台进行适当的配置，无需编码即可提供标准化的服务； 如何应对定制化需求。saas就是上面千条线，下面一根针。客户提出的需求有些是通用的，可以加入标准化组件。有些则是很特殊的，可能需要进行回绝，或者评估工作量进行商务上的会谈； 如何对现有系统进行改造。平台建设早期被项目推着走，积累了一些经验，但是也产生了一些技术债务。在公司正常运营的情况下，如何将已有项目平缓过渡到重构后的平台服务中去，也是需要商讨的话题之一； 架构细节待议话题： 目前已有系统如何抽象、拆分服务； 前端展示层如何设计； 重构后要保证平台满足当前所有已接入所有业务；","tags":[{"name":"sass","slug":"sass","permalink":"http://yiuterran.github.io/tags/sass/"}]},{"title":"当代编程语言简评","date":"2019-11-09T05:48:16.000Z","path":"2019/11/09/当代编程语言简评/","text":"著名大喷子王垠最喜欢点评各种语言的优缺点（当然基本上都是缺点居多），作为技术人也写一篇东西表达一下自己的看法。 原初C和Lisp是流行至今的最古老的两门编程语言，从一开始就走向了不同的道路。 C：高效、简洁，直接操控内存和cpu，面向机器Lisp：抽象，强大，但是效率不高，gc语言，面向业务 从这时候开始，语言演化就是在这两门语言的基础上取长补短 C -&gt; ObjectC/C++ -&gt; RustC++完全兼容C90，这是它成功的原因，也是它失败的原因。 C++最开始就是C with class，随着OO的流行，C语言抽象能力不足的问题越来越明显。于是C++之父往里面塞入了类，以及随之而来的各种概念。后来，又加了模版，于是才有了STL。 C++非常复杂，包含了各种流行的编程范式。抽象能力得到了巨大的补充，但是并没有引入GC，仍然坚持zero-cost abstraction。虽然后来在C++11中引入了智能指针，但是已经有一些积重难返的感觉了。 OC也是C的超集，设计的更加不爽了，苹果自己也想要用Swift替代之。 Rust也坚持零成本抽象，但是它另辟蹊径，从语言和编译器层面上试图解决内存问题，引入了生命周期、各类指针等各种复杂的设计。Rust有现代语言完善的包管理系统，这是比C++好的地方，但是它试图解决问题的手段有些奇怪，有时候有一些因噎废食的感觉。这也是我不太看好Rust流行的原因。真正的高手，用Modern C++就够了。 Smalltalk -&gt; C#/Java -&gt; Scala -&gt; Kotlin和C同时期的OO语言，最出名的是Smalltalk（lisp并不是OO语言，它可以抽象出一切，Smalltalk的诞生也是受了lisp的影响）。Java的创造者受够了C++的复杂，决定另起炉灶融合Smalltalk和C++的长处，做出一门新语言。 Java是工业界长时间以来最流行的语言，虽然C#改进了Java，并引入了linq等方便至极的语法，但是.net core开源的太迟了。 Java太OO了，这是它成功的地方，也是它失败的地方。Java的流行导致所谓设计模式的泛滥，Java的抽象能力过于局限于OO，导致很多本来很简单的东西写起来复杂无比，Spring这类框架的流行本质上就是在弥补Java语言的缺陷。 Java7以前的Java足够简单，这为业界量产初级程序员打下了良好的基础。 Scala是一门学术语言，类似C++，它过于复杂，所以不可能得到流行。Kotlin就好得多，它语言特性优越，并且积极演变。唯一的问题是，它必须运行在jvm上，那到头来你还是承受Java的历史遗留问题。 Python/Perl/Ruby/Javascript虽然动态语言当初走的是完全不同的道路，到最后也慢慢引入类型化，比如Python3也开始支持类型注解，毕竟编译器还是能帮上很多忙的。 动态语言在开发速度上无与伦比，所以更适合用来搭原型，写脚本。对于I/O密集型工程，也可以选择他们快速开发。 JS的流行是一个历史上的错误，别的没啥好说的了… Erlang/Go/SwiftErlang是一门分布式设计语言，它纯粹为了解决工程问题而生，它正确而强大。但是，它的生态不够开放，语法也略显怪异，效率上也不是很尽如人意，所以最终未能大规模流行。 Go在分布式上做的没有Erlang那么激进，netchan这玩意儿最终还是没有内置到语言里。不过Go的优势是足够快，足够简单。 Swift目前还是主要用作客户端开发，但是已经开源。啥时候引入async/await以后，也可以用来做服务端开发，可惜没有生态。 Haskell/OCaml/F#函数式编程语言过于学院派，有一种学之则生，用之则死的感觉，如同Lisp一般。 不过，他们有一种数学美。 PHPPHP没啥好说的，在HTML里面写代码决定了这玩意儿的用处太受限了。如果不是Facebook抱残守缺，早就应该被淘汰了。 最好的语言后端来说，目前就是Java，但是Go2有希望超越。 顺便说一句，我可不喜欢Java了，我宁愿选Go1。 题外话历史并不能给人们以教训，人们总是犯同样的错误。 C++引入模版，Java和.NET都是半路引入泛型，Go却还要重滔覆辙。C++开始就用异常代替了错误码，Go非要到Go2再还这些技术债，这是何苦。","tags":[{"name":"杂谈","slug":"杂谈","permalink":"http://yiuterran.github.io/tags/%E6%9D%82%E8%B0%88/"}]},{"title":"并发编程模型浅谈","date":"2019-11-02T01:03:43.000Z","path":"2019/11/02/并发编程模型浅谈/","text":"当我们设计一个业务模型的代码架构时，不同语言的选择对我们的思维有很大的影响。本文根据个人经验，以设计斗地主服务器为例，试图总结一下其中的区别。 概述主流设计语言中，C/C++甚至没有线程的概念，全靠调用操作系统自己的接口；Python由于GIL的原因，多线程效率十分底下，一般采用多进程模型；Java是最早采用多线程模型的语言；Erlang是内置Actor模型；Golang是内置CSP模型。值得注意的是，对操作系统而言，最底层的就是线程（不过Windows有内置的Fiber），所以协程（coroutine）在任何语言中其实都可以自己实现，多个协程共同运行在同一个线程中。 多进程设计如果选用Python作为目标任务的编程语言，显然应该采用多进程模型，在进程内部可以使用协程来加快速度。比如我们用Tornado来完成这个游戏： 首先可以设计一个路由服务（HTTP服务），完成用户身份校验后，根据负载均衡算法随机分配一个实例，将websocket监听地址返回给客户端。并将这个分配地址记录下来，供用户断线重连使用； Tornado是单进程单线程模型，这里主要完成游戏逻辑。一个新用户加入后，游戏服在内存中遍历有空闲的房间，将用户加入其中。每个房间有自己的id，游戏逻辑本身靠用户动作来驱动，即通过用户动作来修改房间上下文，直到游戏结束；同时游戏可以使用ioloop的定时器来定义超时，代替用户驱动游戏； 到游戏结算时，需要入库，可以通过线程池的方法避免阻塞，或者用async-http在路由层完成入库操作。 进程间通信上述过程中，可以把路由和Tornado设计到一起，使用类似prefork的方案，在路由进程中启动tornado的进程池，这种情况下可以使用python内置的多进程通信组件（multiprocessing包里面的）。不过这个设计显然不是很好，不符合现在微服务的设计理念。 将路由和Tornado作为独立的服务，二者之间的进程通信可以用socket（有应答），或者mq等中间件（无应答），同时也将监听的handler加入ioloop的主循环中。 注意独立进程之间可能存在数据不一致问题，单节点挂掉的话需要考虑如何处理。 多线程设计以Java的Netty为例。其实和多进程差不多，不过这时候路由和游戏本身肯定是在一个进程里作为一个整体的服务了，那么假设这里通过dns进行负载均衡，用户随机连接到一台服务器上。可以通过redis的setnx这种类分布式锁的机制保证用户断线重连到同一台机器。 一个单独的线程作为路由服务，将用户分配到不同房间； 建立房间游戏逻辑线程池。这个线程池可以用netty的，也可以用jdk的。不过棋牌类游戏需要使用大量定时器，所以一般还是用netty的。netty的I/O线程和业务线程在这里是分开的，避免相互阻塞； 只要保证同一个房间的游戏逻辑总是被同一个线程处理，即可达到无锁编程的目的； 线程间通信线程间通信的可靠性显然比进程间强了许多，基本无需考虑数据不一致问题。 一般使用语言自带的组件来完成线程间通信，比如Future/Promise（有应答），或者直接submit到对应的线程（无应答）。耗时任务一般采用线程池的方法来避免阻塞。 协程设计以Go为例。这里就简单多了： 一个单独的协程完成路由服务； 每个房间一个单独的协程完成无锁游戏逻辑计算； 耗时任务单开协程处理，随用随销毁； 协程间通过channel通信； 联系与区别按着上面这些分析，其实他们的设计思路大体上是一样的。通过IO多路复用，使用尽量少的系统资源完成更多的任务，通过使同一个房间在同一个线程/协程里，尽量达到无锁编程的目的。 但是由于操作系统的一个基本运行单位是进程，多进程设计其实就是分布式设计。因此多进程需要更多考虑的到数据一致性的问题，进程间通信的代价昂贵。多线程编程和协程其实差不多，但是协程的代价更低，因此可以每个房间一个协程但不能每个房间一个线程。同样，某些耗时的任务协程可以随时开一个新的，用完再销毁。但是线程不行，这么操作的代价有点大，一般需要做一个池化处理。换句话来说，线程编程要更有总体规划一些，要更加精细的设计，因为一个进程最多有几千个线程，但是却可以有上百万个协程。所以Java这边还是建议把耗时操作封装成类，内部使用池化，同时类对外提供阻塞应答和异步调用等常用通信方式。 同时需要注意的是，IO操作还要关心外部资源的限制。比如MySQL读写，并发量不大的时候，可以随时开一个线程去读。但是并发量有限的情况下，就要池化以限制资源（在Go里面可以通过Channel扇入扇出来限制）。 总结其实道理是相通的，上面的思路其实也大同小异，但是具体到代码的书写难度上，肯定是依次递减的。协程编程的时代早已到来，这也是为啥Go能这么快速流行的一个原因。但是go的channel并不能跨进程通信，所以实际上来说，Erlang这门古早的语言，才是集群设计最终的答案。 注意不管是哪种方案，都有data race的情况，这取决于你对业务的设计和架构。并发编程虽然比以前简单了很多，但是没想清楚的时候，还是很容易出问题的（而且很难调试）。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"},{"name":"concurrent","slug":"concurrent","permalink":"http://yiuterran.github.io/tags/concurrent/"},{"name":"python","slug":"python","permalink":"http://yiuterran.github.io/tags/python/"}]},{"title":"leaf框架代码解析和改造","date":"2019-10-31T05:18:00.000Z","path":"2019/10/31/leaf框架代码解析和改造/","text":"在接游戏外包的一段时间里，选型了golang的leaf框架作为游戏开发的基础框架，但是进行了一系列改造以更好的完成业务需求。简单记录如下： 基本思路leaf本质上其实不是一个游戏框架，而是一个网络工程的脚手架，换句话来说你可以用它来写任何服务端而不仅仅是游戏。 它的基本思路是将每个socket封装成一个agent，使用独立的协程进行读写。主要分为几个模块： 提供Skeleton这个脚手架，可以把它当成一个功能更加完善的协程。它提供了保证函数执行时序的一些工具，允许callback形式的代码；通过chanRPCServer抽象了一种类似RPC的协程间通信（通过channel），方便快速进行开发； 按业务抽象了Module，进行生命周期管理； 抽象了网络接口，并提供了裸TCP和websocket的实现，可以通过简单的配置同时支持多种协议； 提供了protobuf和json的序列化支持； 路由机制； 通过telnet提供pprof接口，同时也可以自定义命令，方便进行debug； 其他一些工具库； 细节分析下面按着模块进行一些代码难点解析。 Module这个比较简单，规定了一个接口，里面是一些生命周期的回调函数，供leaf启动时注册运行，同时提供了一个chan bool作为关闭的信号。 注意每个模块运行在单独的协程里。 Processor序列化接口，支持序列化、反序列化和路由消息到对应的handler。框架给出了json和protobuf两种序列化方案。 json是明文传输，直接用类的名字作为消息的标示即可。protobuf是二进制传输，需要两个字节来描述消息的id，直到id才能正确的反序列化。 network对TCP和WebSocket通信的抽象，Conn是抽象出的接口。 TCP和WebSocket最大的不同是前者是传输层协议，后者是应用层协议。所以前者需要自定义消息格式，这里采用的是头X个字节描述消息大小，后面是序列化消息的方式，另外注意这里还有大小端的问题。读的过程很简单，每次都是先读前X个字节，然后读出整个消息体；写的过程也类似。 Gate路由主要作用是将socket封装成Agent，这里为了可以同时当作TCP和WebSocket服务器，将相关设置项直接当作Gate的成员变量了。 消息的路由通过注册processor来实现，通过Run来启动server，显然gate应该被封装作为一个Module在leaf中运行。这里还注册了打开关闭socket的固定回调(“NewAgent”和”CloseAgent”)。 下面看一下Server启动后做了啥，以TCPServer为例： 在一个单独的协程中启动server，server本身是一个死循环； Accept请求以后，通过server的NewAgent回调创造agent，并在一个单独的协程中运行agent； agent的Run也是一个死循环，它简单的读取消息并进行路由处理； agent的写消息是在调用协程里异步完成的，它将消息写入conn的writeChan缓冲区后返回；每个conn有个单独的协程遍历channel并完成真正的写操作； 因此3，4为一个socket的读写各创建了一个单独的协程； 3中路由处理，在这里分为几种情况，如果对Processor调用了SetHandler或者SetRawHandler，那么就在读消息的协程里直接同步处理了消息。如果调用了SetRouter选择把消息路由到某个chanrpc中，则会把消息塞到队列中进行异步处理（回调的格式写死为f(args []interface{})。 command一个方便调试的工具。 用户可以通过telnet访问内存情况，通过自定义command指令获取内存中的数据并进行调试。 chanrpc该模块通过精巧的设计，为协程间通信增加了异步回调执行、同步调用、异步通知等常见模式。我们一般不直接使用它，而是通过Skeleton来使用。 Skeleton可以理解为一个胖协程，我们不再单独使用go func()&#123;&#125;运行协程，而是新建一个Skeleton，通过go skeleton.Run()来运行协程。 这样创建的协程，就可以通过内置的chanrpc来进行通信。此外，这里还对timer进行了封装，go默认的timer是在单独的协程里运行的，这里在时间到达后，将回调函数重新塞回调用chanTimer里，最终仍然在同一个协程里执行函数。同样，内置的Go也是通过类似的方法保证协程的同步。 所以Skeleton的Run函数就是一个select的死循环，使用io多路复用，依次中上述组件对应的channel中获取结果并执行对应的动作。 简单改进由于leaf常年不再更新，fork了一个版本并修正了一些问题，地址在：https://github.com/YiuTerran/leaf 主要修正包括： 移除了一些不需要的模块，如mongo的支持等，这些直接用第三方库即可； 将自己实现的log模块改为zap的，性能更好并支持json格式的日志； 将websocket的RemoteAddr返回值改为透过代理的（如果存在）； 加上go mod支持，修改版本号为规范格式； 移除了conf文件夹，这个设计不太符合类库的使用规范；","tags":[{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"},{"name":"leaf","slug":"leaf","permalink":"http://yiuterran.github.io/tags/leaf/"}]},{"title":"微服务设计迷思-数据存储","date":"2019-10-31T03:14:08.000Z","path":"2019/10/31/微服务设计迷思-数据存储/","text":"概述后台数据的存储，其演变路线是非常明晰的。从全部用传统DBMS(oracle/mysql)到NoSQL配合db，直到现在的分布式数据库(NewSQL)。对应的，后台服务的主流架构也由单体式到SOA到微服务。当然，OLAP还引入了hbase，hive等大数据分析系统；然后各专业领域还有es或者neo4j之类的数据库，这里先不讨论这个。 这么多年，后端的设计其实没有大的改变，主要解决的就是流量问题：越来越庞大的访问量，和随之产生的数据量。银行证券等金融系统，最开始使用的是db2，sysbase等硬件数据库，然后是oracle这种较为成熟的单点数据库，这两年才逐渐拥抱开源，用pgsql代替oracle或是引入分布式数据库。访问量更为庞大、同时实时性也要求更高的互联网服务（很多金融系统的实时性其实很差，比如跨国swift汇款，可能要一个星期才到账。它涉及到风控等外部因素，实时性并不是第一位的。当然也有要求高的，比如股票购买。），则更为激进，在移动互联网时代就大规模引入redis、mongodb等NoSQL组件，以提高响应速度。 单点时代即使C10K时代，单点数据库一般也足够满足需求。这时候最多考虑的是HA问题，mysql等常见db都提供了副本集的设计，也有比较成熟的集群架构（比如PXC架构）。这些技术在当今也很常见，中小规模的互联网公司仍在使用。oracle自带的分区功能也可以较少单表读写压力。 分片稍大规模的服务，也可以根据key值进行手动的分片。虽然麻烦了一些，但是仍然够用，事务的一致性可以通过db得到保证。但是如果引入了NoSQL，如redis，不同组件之间的数据一致性和事务性无法得到保证。 在代码里进行分库分表耦合太深，所以出现了mycat这一类透明代理，这样代码里仍然把数据库当作单点处理。代理反向解析sql语句，将请求送入正确的db，并进行数据汇总。当然OLAP用这个会有join问题，分页问题等。 mongodb虽然支持集群，但是不支持表之间的join操作，所以其实也算是一种分片。关于分片的设计，前面的博客有分析（数据密集型应用设计）。 一库一服有人说微服务与SOA最大的区别就是一库一服，实际上这并没有解决任何问题，只是转移了问题，并且带来了新的问题。 将服务拆分成更小粒度的服务，每个服务使用单独的数据库。这些单独的数据库仍然可以使用分片进行水平扩展分解压力，显然这是一种分治的思想。但是分库破坏了db的acid特性，会导致数据失去强一致性。 以支付服务为例，在同一个db中，可以利用数据库的事务性保证付款和减少库存两个操作的一致性。如果通过微服务，支付服务和库存服务独立的情况下，只能拆分成支付服务扣钱-&gt;通知库存服务减少-&gt;库存减少成功/失败-&gt;回调支付服务确认，这就是所谓的TCC解决方案。 显然，某些业务（比如股票/火车票购买）是不能用这种模型的，扣钱成功必须保证买到商品，否则用户肯定会投诉的。所以这时候就只能用二阶段提交等一致性搞好的方案，但是效率又得不到保证。 分布式数据库NewSQL的分布式数据库，从db层面上解决了数据扩展性的问题。说白了，它是将分布式事务的问题从服务层面重新转回db层面。于是一切又回到了单点时代，对于服务而言，分布式数据库就当作一个单点来使用即可。 当然分布式数据库至今仍然有一些问题，不过已经可以在生产上使用。 未来从程序设计的角度来看，一切正在回到初始。 ServiceMesh和NewSQL，这两项技术将一切外部组件的复杂性进行了屏蔽，那么很多业务就重新回到CURD的简单工作了。 然而终究没有银弹，在很长一段时间内，上面的技术都会并存于世。合理的进行选型设计才是架构师应该考虑的问题。 多嘴说一句，Dubbo, SpringCloud这种架构注定会过时的，它将外部组件的复杂性引入了代码，这不符合低耦合高聚集的程序设计原则，注定会被ServiceMesh替代。","tags":[{"name":"db","slug":"db","permalink":"http://yiuterran.github.io/tags/db/"},{"name":"微服务","slug":"微服务","permalink":"http://yiuterran.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"}]},{"title":"面试刷题总结","date":"2019-10-18T10:07:21.000Z","path":"2019/10/18/刷题总结/","text":"题目类型字符串/数组字符串是数组的一个特例，常用处理方案是一致的。思路包括： 双指针（首尾） 回溯 贪心/dp Trie树 二分搜索（各种变种） 特殊题型 旋转数组：多次反转 判断是否存在，超大规模使用布隆过滤器（能精准判断不存在，但是不能精准判断存在） 矩阵相关：注意遍历的起始位置，根据矩阵的特点从右上角、左下角开始能迅速计算出目标 堆在Java中通过PriorityQueue实现最大/最小堆（默认是最小）python中通过heapq这个库来实现数组堆化，当然也可以用queue.PriorityQueue堆可以用来解决topK问题 栈栈通常用来解决优先级问题，一系列的操作中，有些优先级高，有些优先级低。可以将优先级低的先压栈，取出优先级高的进行处理。 队列队列可以用来解决二叉树层次遍历问题。 链表 双指针（快慢） 快慢指针能相遇则链表有环 相遇点和链表头各设一个指针，同时前进，交点即环的入口 两个链表的问题，可以根据长度差X设置两个指针，长链表指针先走X步 二叉树概念： 1. 满二叉树：除了叶子节点，所有节点都有两个子节点的二叉树；层数为K，节点数为2^K - 1个 2. 完全二叉树：最后一层节点从左到右连续，其他层节点达到最大值。满二叉树是完全二叉树的特殊情况 3. 二叉搜索树(BST)：左子树的节点均小于根结点，右子树的节点均大于根结点，子节点也是二叉搜索树 1. 中序遍历BST得到排序后的数组； 2. 反向转换：取mid作为根，左边递归是左子树，右边递归是右子树 3. 二叉搜索树的所有操作复杂度为O(h)，h为树的高度，当树高度不平衡时，退化为O(n)，即链表操作 4. 平衡二叉树：左右子树高度差不超过1，且子节点都是平衡二叉树 5. AVL：自平衡二叉搜索树 6. 红黑树：也是自平衡二叉搜索树，理论性能优于AVL树 =&gt; 由于十分难写，很多实现采用skiplist代替 7. 区间树/线段树：二叉搜索树的元素不再是元素，而是某个区间 8. B树：自平衡多叉树，高度较低，适用于磁盘存储 9. R树：一般用于存储空间位置信息 解法： 1. 递归。由于二叉树本身就是递归结构，所以几乎所有的解法都需要递归 2. 遍历：前序、中序、后序都是深度优先搜索（DFS），使用递归即可；层次遍历是广度优先搜索（BFS），使用队列辅助完成； 3. 序列化：用层次遍历即可，先把root放进去然后分别放入其子节点 排序和搜索概念： 1. 经典排序算法：插入、选择、冒泡，复杂度都是O(n^2)，实际上一般并不单独使用 2. 普通排序算法的最佳复杂度就是O(nlgn)，一般我们使用快排，但是它的最差复杂度是O(n^2)，相比之下归并排序具有更稳定的复杂度但是却需要占用更多的空间 3. 如果需要稳定排序，一般还是用归并排序 4. 特殊情况下，可以达到线性事件排序，如桶排序、基数排序等 5. 求Kth最大/小的值，一般采用类似快速排序的切割算法，期望复杂度是O(n)，C++中可以用STL中的nth实现 6. 二分搜索的前提是数组已经排好序 动态规划dp问题没有固定的解法，一般用于最优化问题（统筹规划），需要根据观察列出dp方程，并找到剪枝方式，从而简化求解过程。dp方程的个数取决于状态的个数，自变量的个数则需要分析题意。 使用动态规划将问题划分为若干个子问题，这些子问题之间相互重叠，通过记忆化查表的方式简化这些计算，动态规划一般分为自底向上和自顶向下两种设计方式。贪心算法则是对子问题直接作出贪心选择，从而简化计算，贪心算法一般都是自顶向下的。 图论掌握dfs，bfs和并查集并查集主要是join和search两个操作最短路径算法最小生成树","tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://yiuterran.github.io/tags/leetcode/"},{"name":"面试","slug":"面试","permalink":"http://yiuterran.github.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"docker常见命令","date":"2019-02-17T13:26:39.000Z","path":"2019/02/17/docker常见命令/","text":"日志类12docker logs -f &lt;container&gt; # 查看日志journalctl 容器类12345678docker ps # 查看正在运行的容器docker ps -a -q # 查看全部容器和信息docker ps topdocker pull/commit/tag/push/diff/attachdocker create/build/run/rmdocker start/stop/pausedocker exec -it &#123;&#123;containerName or containerID&#125;&#125; bash # 进入容器交互docker cp 镜像12345678910111213141516171819202122# 列出本地所有镜像docker images# 本地镜像名为 ubuntu 的所有镜像docker images ubuntu# 查看指定镜像的创建历史docker history [id]# 本地移除一个或多个指定的镜像docker rmi# 移除本地全部镜像docker rmi `docker images -a -q`# 指定镜像保存成 tar 归档文件， docker load 的逆操作docker save# 将镜像 ubuntu:14.04 保存为 ubuntu14.04.tar 文件docker save -o ubuntu14.04.tar ubuntu:14.04# 从 tar 镜像归档中载入镜像， docker save 的逆操作docker load# 上面命令的意思是将 ubuntu14.04.tar 文件载入镜像中docker load -i ubuntu14.04.tardocker load &lt; /home/save.tar# 构建自己的镜像docker build -t &lt;镜像名&gt; &lt;Dockerfile路径&gt;docker build -t xx/gitlab .","tags":[{"name":"docker","slug":"docker","permalink":"http://yiuterran.github.io/tags/docker/"}]},{"title":"k8s学习纪要","date":"2019-02-17T12:18:59.000Z","path":"2019/02/17/k8s学习纪要/","text":"近两年来，由于互联网规模再次扩大，原有的分布式技术（SOA、ESB等）都存在各种各样的缺陷，不能满足日益复杂的需求，所以各种新概念和框架应用而生，目前服务端最流行的是将复杂业务拆分微服务化，以减轻业务和代码的复杂度。在运维端，使用k8s和docker进行快速部署、扩容、监控、编排、回滚等常见运维操作，同时使用istio等Service mesh组件，达到分布式事务、track、router、限流、断路等常见服务需求。 k8s及其概念k8s的架构有一点类似linux的分层技术，比较复杂，所以最好边学变实践，不然根本记不住。API对象是K8s集群中的管理操作单元。K8s集群系统每支持一项新功能，引入一项新技术，一定会新引入对应的API对象，支持对该功能的管理操作。例如副本集Replica Set对应的API对象是RS。下面是各种API对象： podPod是在K8s集群中运行部署应用或服务的最小单元，它是可以支持多容器的。 Node节点是所有Pod运行所在的工作主机，可以是物理机也可以是虚拟机。工作主机的统一特征是上面要运行kubelet管理节点上运行的容器。 RS副本集，在MongoDB中有此概念，这里其实差不多。提供服务的高可用性。 Deployment即部署，可以是创建一个新的服务，更新一个新的服务，也可以是滚动升级一个服务。部署通过创建新的RS，将流量转移到新的RS，然后逐渐关闭旧的RS来实现。 Service客户端直接访问的服务对象，长期伺服型。每个Service会对应一个集群内部有效的虚拟IP，集群内部通过虚拟IP访问一个服务。在K8s集群中微服务的负载均衡是由Kube-proxy实现的。Kube-proxy是K8s集群内部的负载均衡器。它是一个分布式代理服务器，在K8s的每个节点上都有一个。 JobJob是K8s用来控制批处理型任务的API对象，有点类似Oracle数据库中的Job，例如定时任务等。 DaemonSet后台支撑服务集，运行存储，日志和监控等在每个节点上支持K8s集群运行的服务。 PetSet有状态服务集，显然RS是无状态的，这样才能迅速deployment。但是对于db对象，更新的时候显然不能把数据扔了，这时候就需要用PetSet新建一个同名的pod，然后挂载存储继续服务。 Federation集群联邦，为提供跨Region跨服务商K8s集群服务而设计，适用于超大规模集群。 Volume类似docker的存储卷，但是更加抽象，pod支持多种存储卷，包括各种云服务的存储（如s3等） PV和PVC持久存储卷（声明），用以抽象具体的存储逻辑。 SecretSecret是用来保存和传递密码、密钥、认证凭证这些敏感信息的对象。 Namespace为集群提供隔离功能的命名空间。 RBAC访问授权集群的管理需要一定的授权控制，引入常见的RBAC API对象 单机搭建k8s环境单机使用minikube进行环境搭建，首先使用包管理器安装minikube和推荐的驱动hyperkit（或者你装virtualbox也可以)，然后运行minikube start --vm-driver=hyperkit激活管理器。 在demo文件下创建server.js，内容如下： 123456789var http = require(&#x27;http&#x27;);var handleRequest = function(request, response) &#123; console.log(&#x27;Received request for URL: &#x27; + request.url); response.writeHead(200); response.end(&#x27;Hello World!&#x27;);&#125;;var www = http.createServer(handleRequest);www.listen(8080); 显然这个js只是简单的创建了一个对任意请求返回hello world的http服务器，然后在demo文件夹下创建Dockerfile，内容如下： 1234FROM node:6.14.2EXPOSE 8080COPY server.js .CMD node server.js 显然这里就是简单的从node环境中导出8080端口并运行上面的server.js。运行minikube dashboard可以打开网页控制台查看相关信息。 使用kubectl create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node创建一个部署信息，使用kubectl get deployments获取部署信息，使用kubectl get pods获取节点信息，使用kubectl get events获取事件日志，使用kubectl config view查看配置信息。 使用kubectl expose deployment hello-node --type=LoadBalancer --port=8080根据刚才的结点创建一个Service，默认情况下pod只能通过内部ip访问，如果想要在k8s外部（即客户端）来访问pod，需要将其导出为服务。现在使用kubectl get services即可看到hello-node的Service。最后使用minikube service hello-node即可访问该服务。 最后，使用minikube addons enable/disable xxx即可打开/关闭附加服务。使用kubectl delete service hello-node kubectl最常用的命令格式： kubectl get - list resources kubectl describe - show detailed information about a resource kubectl logs - print the logs from a container in a pod kubectl exec - execute a command on a container in a pod 搭建副本集使用scale命令进行副本集的扩展：kubectl scale deployments/kubernetes-bootcamp --replicas=2 滚动升级使用set image进行升级，使用rollout undo进行回滚","tags":[{"name":"docker","slug":"docker","permalink":"http://yiuterran.github.io/tags/docker/"},{"name":"k8s","slug":"k8s","permalink":"http://yiuterran.github.io/tags/k8s/"}]},{"title":"摄影笔记","date":"2018-10-07T01:57:51.000Z","path":"2018/10/07/摄影笔记/","text":"参数 快门：取值的倒数，数据越大快门速度越快。高速记录瞬间，低速记录过程； 光圈：由于光圈值是以 2 的倍数变化的，直接用光圈数值表示镜头的通光量，光圈直径应呈 √2（约等于 1.4）系数关系递增。光圈值越大，通光量越小，景深越小； 焦距：即镜片中心到 CMOS 底面的距离，焦距越长，景深越浅，且角度越小；短焦距的一般称作广角镜头，长焦距就称为长焦镜头。 曝光补偿：用以修正曝光值； 感光度（ISO）：感光度越大，需要的光线越少，但是图像的质量越低。在相同曝光值下，ISO 越低越好； 长曝光：曝光时间超过 1s，一般用以夜拍，需要三脚架稳定，增大光圈获取更多光线；另外长曝光可以让运动物体呈现梦幻效果（车流、星轨、流水等）； 快门的参数 B 门（BuLb），也称为手控快门，是指按下快门时，快门打开，开始曝光，松开快门，快门关闭即停止曝光。也就是说，B 门是由快门按下时间的长短来决定每一次曝光时间的，无需设定曝光时间，可以自由控制。B 门的名称取自英语的“球”（bulb），它起源于旧时照相馆摄影师开启快门时所挤捏的橡皮球。这种橡皮球快门释放装置沿用至今，仍可以在很多现代照相馆的照相机上看到。 T 门，是指按下快门按钮快门打开，开始曝光，而且快门持续打开，直至再次按下按钮时快门关闭即停止曝光。T 门与 B 门在功能上比较接近，由于 T 门无需一直按住快门按钮，即可使快门持续打开，因此 T 门比 B 门使用方便一些。 长曝光 白天的长时间曝光一般都可以直接使用相机的光圈优先模式，先选定光圈，然后由相机决定快门时间，30 秒内的曝光无需进入 M 档，如果相机出现 LO 字样，则需要切换到 M 档进行曝光；白天的长时间曝光，在相机能够自动识别场景，能进行自动对焦的时候，有主体的画面对着主体对焦，无明显主体的场景对着场景的前三分之一处对焦；有主体但是无法自动对焦时，用强光电筒照亮主体对焦处再按相机自动对焦按钮；对焦完成，切记要把对焦模式转为 MF 手动模式。 夜间长时间曝光选用相机的 M 档（M 模式），先选定光圈，然后旋转相机的主拨轮调节快门时间，超过 30 秒后就出现 BULB，即相机的 B 门，用 B 门进行长时间曝光；用 B 门进行曝光的时候必须使用快门线；靠手按住相机的快门按钮进行长时间曝光是不现实的，晃动的几率太大，非常容易失败； 倒易率倒易律指出底片的响应取决于总曝光量，即光线强度 × 时间。因此，在减少曝光时间但增加光线强度的情况下，底片的响应（比如显影后胶卷的光学密度）不变，反之亦然。换句话说，一般对于某一给定的曝光结果，光圈与快门之间呈反比例关系，即若开大光圈则需要更快的快门以保持曝光不变。 景深三要素 与光圈成反比 与焦距成反比 与对焦距离成正比 所以一般拍虚化人像（即散景）时，需要用大光圈长焦镜头。画幅越大越容易拍出更好的虚化效果。 测光手动曝光需要测光，合适的曝光值会显示在屏幕/取景器的测光表上。影响曝光的要素包括： 快门速度 光圈大小 感光度 曝光补偿 即使测光宝校 0 成功，也不一定是合适的曝光，需要自己用眼睛去确认。根据被拍摄物体的颜色进行曝光补偿的调整，一般是白加黑减。 AF-L &amp; AE-L「AF-L」用來锁定对焦，「AE-L」用來锁定曝光，两者主要在 AF 模式下使用。其中AE-L使用较多，先选择场景中灰度适中的物体进行测光，点击AE-L后，再进行构图对角拍照；AF-L一般是拍摄运动物体，用于提前锁定焦点。 AF-S &amp; AF-CS和C分别表示单张和连续多张 BKT包围曝光。在测光困难的场景下，可以设置包围曝光，按下快门后根据当前参数下不同的曝光补偿连续拍下多张图片，方便后期进行合成。 夜景 使用三脚架（关闭防抖）、长曝光拍摄。如果拍摄星轨，还需要关闭长曝光降噪。 如果要拍人像，使用闪光灯（后帘同步、白平衡使用闪光灯模式），快门优先，稍高的 ISO、稍大的光圈，先拍摄背景，确定合适的快门速度，在此基础上加快 1~2 倍的快门速度；试拍看一下，根据需要做闪光补偿； ND减光镜在风光拍摄时，有时候光照可能过于强烈，即使在小光圈+低ISO时，仍然有高光溢出的问题。此时可以使用在镜头前使用减光镜减少进光量。 恒定光圈变焦镜头从进光原理上说，焦距越大光圈越小，相机厂家通过复杂的机械结构实现了无论焦距多大其最大光圈都不变的镜头，即称为恒定光圈镜头。","tags":[{"name":"摄影","slug":"摄影","permalink":"http://yiuterran.github.io/tags/%E6%91%84%E5%BD%B1/"}]},{"title":"读书笔记-数据密集型应用设计","date":"2018-02-16T00:49:36.000Z","path":"2018/02/16/读书笔记-数据密集型应用设计/","text":"本书原著为英文，即《Designing Data-Intensive Applications》，主要讲述数据库底层原理和设计思路，读来受益颇多。 基本原则我们期望数据系统可靠、可扩展、可维护，但是由于 CAP 原理的限制，我们无法完全做到这些，因此在设计分布式数据库系统时，必然存在各种考量与限制。这里的数据库，指的不是狭义的关系型数据库，或者非关系型数据库。而是一种广泛的Data System，包括消息队列、RDBMS, NOSQL, 以及图数据库、列式数据库等等负责存储数据的组件。 可靠性考量以下几点： 提供正常正确的功能； 错误容忍性； 性能； 安全认证； 其中错误容忍性又分为硬件错误（如断电、内存不足、磁盘不足、网络断开等）和软件错误（各种软件 bug 等），以及人工错误（操作错误、输入错误等） 可扩展性当组件性能、容量无法满足需求时，组件能够通过扩展的方式满足需求，这就是所谓的可扩展性。 书中举了 Twitter 的 timeline 设计作为例子，我们知道 timeline 展示的是 follower 的发布的状态，那么不考虑任何优化的情况下，设计如下：如果用关系型来描述的话，需要一个 user 表，一个用户 follow 关系表，一个 tweets 表，对于 user id 为 1 的用户，其首页的 timeline 生成是 1select t.* from tweets t join follow f on f.follower_id=t.user_id where f.user_id=1 order by t.created_at limit 20; 显然 tweets 表会迅速膨胀成一个超大的表，这种设计不能满足性能的需求。采用写扩散的方案，将每个用户的 timeline 独立存储，用户新的 post 插入 tweets 表后，还要将这个 tweet 插入用户的 follower的timeline 缓存中。除了这个方案以外，还有很多其他的方法，比如使用消息队列。用户 ins/del po, follow/unfollow some one 触发事件，需要对 timeline 进行重新生成。Twitter最终采用了两种方案混合的方式。 性能描述的常用指标包括：延迟、吞吐量、响应时间等。平均响应时间有时候并不能很好的描述性能，中位数响应时间更合适（一半的请求小于该时间，另一半的大于该时间）。中位数响应时间即 50%分位响应时间，如果要求的更严格，可能需要使用 95%分位响应时间等，甚至 99.9%分位。99%分位以上的又被称为尾部延迟。 一般将可扩展性分为水平扩展和垂直扩展，两者可以结合起来。如果系统具有自动根据负载进行扩展的能力，这种系统是所谓的“弹性系统”。 可维护性这里主要指的是系统本身简单可维护，且代码清晰易改动。可维护性显然不仅仅是架构的问题，涉及到方方面面吧，比如： 系统健康监控 错误跟踪系统 自动化部署 完善的文档系统 优雅的抽象，模块化 持续迭代 显然这些其实项目管理的内容。 数据模型和查询语言常见的数据模型包括关系型数据模型，文档性数据模型，网络数据模型和图数据模型 关系型数据模型关系型数据库是最经典的数据库，也是最常用的模型。在 1 对多环境下，文档性数据模型（一般是类 JSON 格式）可以很好的描述数据关系；但是多对多就比较麻烦了。而且现在已有的文档型数据库中，大部分是不支持不同表格之前关联查询的。 随着技术的进步，关系型数据库和文档型数据库产生了一些融合，现在关系型数据库一般也支持 JSON 字段了，虽然这种有效的融合本质上是反模式的。 关系型数据库统一使用 sql 语言操作，sql 是一种 DML，类似 CSS。文档型、图数据库的查询语言不通用由各个实现自己定义。当然随着分布式关系型数据库的发展，sql 仍然是最重要的数据操纵语言。 图数据模型比较复杂，按着一般图的概念，结点和关系构成了整张图。属性图模型的设计如下： 一个图中会记录节点和关系 关系可以用来关联两个节点 节点和关系都可以拥有自己的属性 可以赋予节点多个标签(类别) 在某些应用场景里（如社交网络、金融风控等多对多场景），图数据库在描述关系上具有无与伦比的优势，可以大幅简化查询设计。除了属性图外，还有其他图数据模型实现，如 Triple-Stores，将数据存为主谓宾三元组，一般是使用 SPARQL 进行查询；然后还有 RDF 数据模型，一般使用 XML 语言描述。 存储和取回本章阐述了数据库底层存储和查询的原理。文中先举例了一个 KV 数据库最简单的实现，将数据存在文件中，写入就直接写在文件尾部，读取则用 tail 值（逆序查找即可）。这种直接写到文件尾部的只读文件，本质上是一种 log. 当然这个实现有个很明显的问题：写入很快，但是查找很慢。如果 key 根本不存在，需要遍历整个文件，因此需要引入索引(index)的实现。比如这里将所有的 key 存入一个红黑树或者哈希表，然后存放对应的偏移量作为值，即成为一个索引。 由于数据存入文件是 append only 的，很容易导致磁盘空间耗尽，因此需要周期性的对文件进行压缩。对于 KV 数据库而言，每个 key 值最后对应的 value 是唯一的，所谓的压缩其实就是将对同一个 key 的赋值仅保留最后一个。显然这个过程可以分片同步进行（类似归并排序的流程），也可以放在后台进行，不影响前台正常的读写。 哈希索引是最快的查询索引，仅需要 O(1)时间，但是问题是哈希表必须存入内存之中，一般多用在内存数据库中。而对于存储在磁盘上的数据，一般使用 b-tree 来存放。 SSTABLE 和 LSM-TREE如果将上述实现的 KV 数据库中的 KEY 排序，得到的表就是所谓 SSTABLE(SORTED STRING TABLE)，这种表格归并和查找的速度都明显超过普通的文件，这样就不再需要额外的完整索引来进行查找加速（但是可能需要稀疏索引来加速搜索）。 SSTABLE 在内存中可以使用各种平衡二叉树，比如红黑树或者 AVL 树。为了性能考虑，先把数据写入内存表（即缓存），然后等到内存中的数据达到一定的阈值后，再序列化写入硬盘，写入硬盘的部分也可以分片。最后，周期性运行数据压缩，消除冗余 key 值。 SSTABLE 的设计比较完善，考虑到掉电问题，还需要对内存表的操作保留一份日志，以便进行错误恢复。可以使用 WAL（WRITE AHEAD LOG)日志来记录。 以上思路，就是所谓的 LOG STRUCTURED MERGE-TREE, 即 LSM-TREE，Lucence 这个搜索引擎在底层即使用了这种数据结构，然后 Level DB 等数据库也使用了这种数据结构，Level 指的是数据归并压缩时使用的策略。将 key 根据范围划分为不同的 Level，从而用来加速归并和压缩的速度。 可以使用Bloom filters算法加速搜索，确认 key 不存在。 B-TREEb-tree 是磁盘存储数据时最常用的索引结构，这是一种自平衡多路查找树，特点是能够保持较低的高度。 b-tree 将数据抽象成固定大小的 block 或者说 page，一般是 4Kb 每页（机器硬盘），每次读写一页。每个 page 里面是数据和指向其他 page 的指针，这棵树也有一个根节点，是每次搜索的开始。每页包含指向子叶的指针数，即所谓的“分支因子”（一般是几百个）。page 里面是索引列的有序键值，但是这个键值是稀疏的排序，树的高度被保证为较小的值，这样通过 3~4 层的搜索能够找到大部分 key 值。 还有一些常见的其他的优化措施，如 WAL 啊，多线程保护（latch）啊，写时复制啊，或者使用变体的分型树、b+树、b*树等. 对比B-Tree和LSM-Tree，后者拥有更好的写性能（速度和吞吐量），前者拥有更好的读性能。同时，后者由于会定期重写SSTables清除碎片，对磁盘空间的需求量也小的多。但是LSM-Tree在压缩数据时会影响磁盘的IO性能，进而影响到数据库的读写速度。 聚簇索引与非聚簇索引简单来说，直接将值放在索引里的是聚簇索引；放的是数据的引用/指针的则是非聚簇索引。后者需要回表索取原始数据，所以性能会差一些。综合两者的被称为覆盖索引。 多列索引简单的实现是直接将多列拼接成同一个 key，复杂情况使用其他优化的数据结构。Mysql中通常成为复合索引，适用最左匹配原则。 GIS 中的地理位置索引，包含经度和纬度，一般使用 R-TREE 来实现。 全文索引对于搜索引擎，需要的是进行模糊查询，一般的索引技术不能满足需求。数据结构以外，还需要结合分词技术、机器学习等其他技术才能满足各种需求。 内存数据库随着内存价格的降低和容量的增加，全内存型数据库也开始涌现。对于 IO 性能要求较高的场合，大量使用内存数据库（如游戏）。关系型内存数据库常见的如 voltdb，KV 型的如 redis 等。 内存数据库速度快的原因不是把所有数据都放在内存里，因为传统关系型数据库也有 cache，这个优势并没有想象的那么大。内存数据库避免了序列化/反序列化的额外负担，同时还可以实现一些无法在磁盘中实现的功能，如 Redis 中的 set, zset 等。 内存数据库可以存放超过内存大小的数据，简单来说就是将最近未使用的数据写入磁盘，需要的时候再重载入内存，类似操作系统的虚拟内存技术。随着非易失性内存技术的发展，最终硬盘和内存将会殊途同归，也就不用再考虑这些问题了。 OLTP 与 OLAP前者用于大量写入，对事务的性能要求较高，后者用于数据分析。 刚开始的时候都用普通 db，随着量级的发展，OLAP 一般使用独立的数仓来完成。数仓将 OLTP 数据库中的数据进行 ETL，存入专门用来数据分析的 db. OLAP 数据库和 OLTP 使用不同的优化方式，前者使用了一些其他的索引技术。 OLAP 一般使用星型模型/雪花模型，将多维度数据聚合到事实表中，从而避免大量 join 查询。此外，OLAP 会使用列式数据库（如HBase），列式可以更方便的进行数据压缩，对查询进行更好的优化。 列式数据库的写入很麻烦，一般使用 LSM-TREE 进行优化，先写入内存，异步写入文件。 除了这些技术以外，还有很多其他辅助手段用来提升 OLAP 的查询速度，如物化视图。对于需要经常查询的聚合数据，适用物化视图相当于加了个触发器，自动根据原始数据更新对应的聚合数据表。这样查询的时候就不要实时聚合，大幅度提高了查询速度。 编码与迭代本章主要讨论消息序列化的编码结构（不是字符编码），以及这些编码形式如何应对字段变更、滚动升级等需求。 二进制序列化各个语言有自己的二进制序列化机制，但是一般并不推荐使用，其兼容性、适用性和安全性都有一些问题。不过二进制序列化速度一般比纯文本格式要快一些。 JSON, XML 和二进制编码一般情况下，JSON 和 XML 足够用了，除了一些缺点。JSON 的问题是只支持浮点数，且无法指定精度，有溢出风险。XML 的话就是有点过于笨重，但是支持 XPATH 这种高级检索语言。基于 JSON 和 XML 也有一些二进制编码。 如果使用 RPC 通信，可以考虑使用二进制编码，例如 Thift 或者 Protobuf，此外还有 Avro 等. 显然 JSON 是通过字段的 key 值来保持兼容性的，而 XML 则使用属性。而 Thift 和 Protobuf 则使用的是字段的 tag，旧的代码读到不认识的 tag，就会忽略掉对应的字段，从而保持兼容性。当然，这里有个问题，新增的字段不可定义为required，就如同给关系型数据库新增字段不能为 NOT NULL 且没有 DEFAULT 值一样。如果是移除字段，也只能移除optional的，且该字段的 tag 将来一定不能被重复使用。如果想要修改字段类型，就有一定的风险，需要视字段间的兼容性和精度而定。protobuf3移除了这两个关键字（并且加入了map），所有的字段都被视为optional.protobuf的一个问题是他不允许嵌套的array和map（当然可以通过嵌套message变相实现），Thrift则允许。 对于 Avro，其 IDL 里面根本没有 tag，读方的 schema 和写方的 schema 可以不一致，avro 会自动处理兼容的字段，忽略不兼容的字段（或者赋默认值）。Avro 是为了给 Hadoop 使用的，这种设计的目的是为了关系型数据库增减字段时不需要人工手动修改 IDL 的 schema. HTTP, RPC, MQ基于不同传输协议的数据封装讨论，都是一些开发者耳熟能详的知识点，不再赘述。 副本集副本集一般有三种架构：single leader，multi leader， no leader。对应mysql，一主多从的架构有MHA，多主的架构有PXC。副本集的主要目的是保证数据高可用，副效果是降低单机的负载。 主从模式即单主模式，写到 leader，leader 通过 log 或者 Stream 同步到 follower，读的时候可以从从库读，也可以从主库读（即读写分离）。 主库到从库的同步可能是同步或异步的，后者会出现读出的数据是 old data 的情况。 故障恢复：如果从库 down 了，重启后通过日志重新同步即可；但是如果主库 down 了，就需要重新选举一个 leader，否则整个服务就不可用了。选举的过程包括： 认定 leader down，一般使用 timeout 选举新的 leader；一般使用具有最新数据的副本当leader（共识问题） 使用选举出来的新 leader 需要解决的问题： 如果 follower 与 leader 之间的数据同步是异步进行的，old leader down 之前可能还没来得及将数据同步给其他 follower，那么新的 leader 就有丢失一部分数据。old leader 恢复后，需要成为 follower，并丢弃这部分未同步的内容；这种丢弃是很危险的，有可能出现各种问题； 可能会出现两个节点都以为自己是 leader 的问题，即所谓的脑裂问题； 判定服务 down 的 timeout 确定； 原来的主库重新上线后，可能有冲突要解决； 副本 log 的实现原理对于关系型数据库而言，一种显而易见的实现方式是将所有写语句(CREATE, UPDATE, DELETE, ALTER)都记录到日志里，follower 依序重复执行这些语句。但是这里可能有一些问题： 有些函数是不可能重复执行的，如 RAND(), NOW()之类的； 如果依赖已经存在的数据，必须保证执行顺序，这意味着不能并发执行 log 中的语句； 有副作用的语句在各个副本集中造成的副作用可能不一致； 这些问题可以通过将非确定性的语句修改为确定性的（即将 NOW()的结果记录）来解决，MySQL 则直接使用了 ROW-BASED 将行数据覆盖的方法（又称为 logic log）来解决。还可以使用 WAL 这种直接修改磁盘字节的方法来进行，这种方法最大的问题是要求所有的 follower 必须和 leader 保持同样的二进制结构（如存储引擎），这会导致无法平滑升级服务。最后还有一种基于触发器实现的同步，一般是在应用层同步数据时当作工具来使用。 副本 log 的问题 读写一致性问题。用户写完以后立刻读，必须保证读到的是刚写的数据，但是由于从库的同步是异步的，所以可能会出问题；主从异步同步模式仅仅能保证最终一致性，而不是实时强一致； 数据时序性问题。如果用户使用了一系列的读（落到不同的 follower 上），可能由于同步进度的问题，导致部分读到的是新数据，部分是旧数据； 解决方案： 如果能明确区分数据属于用户自己，则直接从主库读取； 最简单的方案是用户总是从同一个副本中读取（即所谓的单调读）；不过这样还要考虑副本down了的HA；然而除了这种顺序以外，还有一种：假设用户A和用户B在对话，二者读的是不同的从库。那么用户C在旁观这种对话过程中，可能观察到错误的对话顺序。在IM群聊中这种场景比较常见，对应这样的场景，需要保证一个群总是对应唯一的服务器节点，保证这种因果关系的顺序性。 换句话来说，这两个问题都没有完美的解决方案，只能根据业务的实际情况来区别对待。 多 leader 模式单主模式情况下，如果服务器和主库的网络发生故障，服务就不再可用。在局域网中这种情况基本不太可能，但是如果存在多个数据中心（异地），这时候各个 data center 各有一个 leader 是更合适的，所有的写发往 local 的 leader，然后由 leader 之间相互同步。显然，多 leader 之间的数据同步会引发各种问题。而且新加入的节点需要同步全量数据，开销很大。 还有一种特殊的多 leader 模式：如果应用需要能够离线工作（如日历），但是设备没有连接上英特网，那么此时设备本地的 db 就是 leader. 多主模式下，两个不同节点的事务可能都提交成功，但是db之间合并数据时可能会出现冲突。解决方案： 避免这种情况，根据用户的 ip 地址就近选择数据中心，游戏分服就是这样解决的。但是如果用户换了地方，原来账号的体验就会比较差了。 自动解决冲突：数据加入时间戳（自增 ID），使用最新的值解决冲突（即LWW，会丢数据）；或者允许用户自定义冲突解决代码，当发现冲突时自动调用这段代码； 手动解决冲突：数据库记录下所有冲突，当该值被阅读时，返回所有值，提示用户手动解决冲突，CouchDB 使用该方案； 多 leader 之间同步拓扑： 环形拓扑：每个 leader 只同步给另外一个 leader，这里要注意单节点挂掉的问题； 星形拓扑：使用一个 root 节点，其他所有节点与该节点进行同步，root 节点可能挂掉； all to all，每个节点和其他所有节点拓扑，这时要注意时序问题； 总的来说，目前多主模式在实际运行中的冲突问题还没有完美的自动化解决方案，需要根据业务场景确定策略。 leaderless 模式这种模式没有主从，客户端的读写同时发送给所有的结点。如果有节点 down 掉，写请求会忽略挂掉的结点；当结点恢复后，会出现数据不一致的问题，客户端从多份节点数据中选取时，选取 version number 较大的数据，作为准确的数据返回。 上面这种宕机情况，数据修复方案： 客户端修复，客户端发现某个节点的数据版本落后于其他节点，那么就将最新版本的数据写入其他节点；这个的问题就是有些数据可能不怎么会被读到，数据长时间存在不一致的问题； 多节点之间自动同步，异步，无特定拓扑顺序，所以可能滞后很多； 多节点同时读取还有读取/写入数量，以及可信度的问题。一般而言，一共有 n 个结点，至少写入 w 个节点保证写成功，至少读取 r 个节点保证读成功，则必须有w+r&gt;n才能保证系统的可靠性。一般情况下，n 是一个奇数，w=r=(n+1)/2. 当然可以根据实际需要调整 w 和 r，以协调自己所需的性能和可靠性。 显然 leaderless 模式会遇到和 multi-leader 类似的问题：时序问题、冲突问题，解决方案也类似。 版本向量一种多客户端写入时解决冲突的方案，即对客户端的每个请求创建的数据都生成一个版本号。在返回客户端时，除了原始数据外也将数据的版本号返回客户端，客户端请求的时候带着本地的最新版本号，这样就可以根据数据的版本进行自动的数据合并。 分片数据分片与副本集不同，是将数据进行垂直切分，也就是所谓的 sharding 技术，经常与副本技术配合使用。对于 KV 型数据库，常见的分区策略包括： 按 key 值范围，缺点是分区可能不均匀； 按 key 值的 hash 值范围，解决不均匀问题。此时要注意 hash 值必须唯一，如 md5。这会引入一个新问题：无法范围查询 key 值，因为他们不再毗邻。Cassandra 的解决方案是用联合主键，如果第一位确认，后面的还能保证都在一个 partition 上，如(user_id, timestamp)； 即使使用了 hash，有时候也会遇到单点过热问题，如社交网络上某个名人的行为总会引起大的数据波动，这个只能在应用层解决了； 次级索引对于 RDBMS，除了主键，一般还有其他索引，如果访问需要通过多个索引字段进行，分片的方式就需要斟酌了。次级索引包括： 分区本地索引；此时范围查询的请求只能发给所有分片，然后再归并查询结果(scatter/gather); 全局索引；即对全局数据进行规约后的索引，但是全局索引也要分片，只是分片的方案需要根据业务来取舍； 再平衡在运行一段时间后，数据在各个分片中可能不太均衡，或者需要增加/减少节点，需要将数据在节点之中进行数据搬运。这被称为再平衡。 一个简单的方案是为每个节点预先分配多个分区，当新的节点加入时将其他节点的部分分区数据迁移到该节点即可；删除节点执行反向操作；这个方案的问题是，预分配的分区数量可能难以确定； 使用动态分区。数据库会根据数据量的大小动态增加或者缩减分区个数；当然初始数据量很小的时候，可能只需要一个分区，此时可以预分区； 每个节点的分区数保持不变；当加入新节点时，增加对应数量的分区。这样可以更好的平衡各个节点； 使用一致性哈希算法，可以有效减少再平衡时需要移动的数据数量。 再平衡后的服务发现问题：服务器需要知道从哪个节点取数据。一般来说有3个解决方案： 服务器自己知道：将分区依据写成配置。手动再平衡完毕后修改配置； 使用代理的路由层，代理知道如何寻址；注意路由层本身也应该是个分布式的组件（例如zookeeper）； 随便发给任意一个节点，节点自己转发； 除了方案1的静态配置，其他两个方案需要动态发现正确的路由。这涉及到分布式环境的共识问题， 事务关系型数据库一般都有 ACID 特性，其中 A 指的是原子性，即一件事要么发生，要么不发生，即使这件事里面包含多个动作；I 指的是隔离性，不同事务之间不相互影响，不会出现脏读等问题；D 指的是持久化能力；而 C 指的是一致性，这个其实无法由数据库来保证，在分布式系统里，最终一致性需要很多条件才能保证。 原子性一般数据库都能保证单对象写入的原子性，但是只有少部分数据库能保证多对象写入的原子性（即支持事务）。 隔离性那么根据不同的隔离级别，有以下几种弱隔离性实现：脏读-&gt;不可重复读-&gt;可重复读（幻读）-&gt;串行化. 数据库一般默认使用 MVCC 技术实现隔离。不可重复读一般情况下没啥影响，但是如果数据库同时在进行备份，可能中间状态就丢了，大部分db的默认隔离级别是这个。 使用 MVCC 将隔离级别上升为可重复读，或者说叫快照隔离（mysql默认该级别）。此时当事务开始时，会获得一个事务全局递增的唯一事务编号，而更新将会被拆分成删除+创建。这样，一个更新操作实际上产生了两个版本的数据。当一个事务开始时，做如下判定： 首先确定当前正在进行但还未提交的事务，使用这些事务开始前的数据版本； 已经 rollback 的事务，其数据修改被直接废弃； 事务 ID 号大于当前事务的提交，不管事务有没有提交，忽略其提交结果； 除了上诉情况以外，其他的写入可以被当前事务感知到； 这种实现对索引的使用：多个版本同个字段使用索引，使用 B 树时，update 不是直接修改 page，而是产生一个新 page，也就是copy-on-write。 写丢失两个事务同时写，一个的写入可能会丢失。解决方案： 原子写入，包括使用CAS。但是用ORM的时候有时候会很难写出k=k+1这种语句，因为k会被直接解释为变量当前的值； 使用悲观锁，即select ... for update，不过在数据不存在时，不能用这个方案；而是要使用类似数据库的upsert语义方言。如mysql的ON DUPLICATE UPDATE，oracle的merge； 部分 db（不含 mysql）实现了 lost update detection，可以自动侦测到该问题； 幻读问题可重复读会导致幻读，如果想要解决这个问题，只能使用串行化，这种隔离的实现方案包括： 单线程执行所有事务，这样就自动串行化了。如 Redis、VoltDB（使用存储过程，将读写都写在一起，优化方案）； 2PL，即两阶段锁。类似读写锁，如果事务对对象没有写入，就允许共享同一个对象。但是一旦开始写入，则使用排他锁进行独占；这比单独的写锁性能更好（这是显然的）； 序列化算法 共享锁、排他锁、读写锁； 谓词锁。即对某个条件产生锁，即使该条件下尚不存在数据。显然谓词锁可能会大幅度降低数据库的性能（创建太多），他的替代品是： 间隙锁。即对搜索条件使用的某个字段的索引进行加锁；但是如果无法命中索引的话，会退化成表锁，大幅度影响性能； 将最后两个隔离方案结合起来，就是所谓的serializable snapshot isolation，即 SSI，这是一个新算法（2008 年提出），在 PostgreSQL 9.1 以后使用，较有潜力。 分布式系统的问题局部失败分布式系统某个节点挂掉引起的一系列问题。 如果是单主集群，需要重新选举； 需要考虑节点恢复后如何重新纳入集群； 需要考虑如何判定节点挂掉，一般是用网络超时，但是这个值比较难以假定； 考虑单节点阻塞导致的丢包问题； 时序问题分布式系统不同节点之间的时钟同步。 依赖时序策略的影响，如 LWW（可以使用逻辑时钟代替墙上时钟）； NTP 同步的精确度，NTP 本身的延迟，NTP 服务本身的不可靠性； Google spanner 的时钟策略，返回一个[least, most]的时钟范围，保证准确的时间落在该范围之内； 系统阻塞 GC 引起的 stop the world 单线程阻塞 其他原因造成的系统结点卡顿，以至于其他结点访问超时，误以为该节点挂了。 一致性线性一致性(Linearizability)所谓线性一致性，指的是对于一个分布式系统的多个副本集，读出的结果永远都是一致的（就好像从唯一一个副本集中读出的一样）。该一致性模型是我们能实现的最强一致性模型，所以又被称为 strong consistency.这种模型假设操作具有一个全局有效时钟的时间戳，但是这个时钟仅具有有限的精确度。要求时间戳在前的进程先执行，换句话说，所有的操作都不是并发的，而是有严格的顺序的（全序）。 单 leader 的副本集群，理论上可以做到线性一致，但是在节点故障的时候可能出现脑裂等问题，此时就会违反线性一致性；而多 leader 节点一定不会是线性一致的，无 leader 集群则不一定，取决于配置（只有 read repair 策略下或许可行，但是这个效率很低，故一般认为不保证。）。另外 LWW 策略必然是非线性的（依赖时钟）。 在某些场景下，只允许线性一致性，比如 leader 选举等。显然该一致性的性能是最差的。 因果一致性(causal consistency)当一个读操作后面跟着一个写操作时，这两个事件就具有潜在的因果关系，同样，读操作也与为读操作提供数据的写操作因果相关。没有因果关系的操作被称为并发的。 所有进程必须以相同的顺序看到具有潜在因果关系的写操作，不同机器上的进程可以以不同的顺序被看到并发的写操作。 实现因果一致性要求跟踪哪些进程看到了哪些写操作。这就意味着必须构建和维护一张记录哪些操作依赖于哪些操作的依赖关系图。一种实现方法是版本（向量）时间戳。 几乎所有的分布式系统都支持因果一致性。前面讨论的事务追踪数据过期抛出失败，也就是保证了因果一致性。 使用 Lamport 时间戳可以保证因果一致性，其实现原理如下： 不同的结点各有自己的编号 n； 每个结点使用自己的计数器 c； 使用(c, n)表示 lamport 时间戳； 客户端/node 跟踪 c 值，当 node 发现客户端请求的 c 值大于自身 c 值时，立刻将自身 c 值设为请求的 c 值（对客户端亦然）； 定义当 n 相等时 c 值较小的逻辑时间较小；否则 n 值较小的逻辑时间较小； 显然 lamport 时间戳定义了一个全序的操作序列。问题在于这个顺序必须在动作执行完成后（即 node 返回后）才能确定下来，这对于某些场合不够用（比如唯一约束）。 弱一致性(weak consistency)引入同步变量 S，其仅有一个关联操作 synchronize(S)，该操作同步数据存储的所有本地拷贝。 使用同步变量来部分地定义一致性就得到称为弱一致性模型，其具有三个属性： 对数据存储所关联的同步变量的访问是顺序一致的； 每个拷贝完成所有先前执行的写操作之前，不允许对同步变量进行任何操作； 所有先前对同步变量执行的操作都执行完毕之前，不允许对数据项进行任何读或写操作。 CAP 理论在网络分区的情况下，一致性和高可用性只能取其一，即所谓 CAP 理论。CAP 理论在最开始时(2000 年)对分布式系统的设计起到了很重要的指导作用，但是现在要考虑的情况要复杂的多，因此一般不再提起该理论。 全序广播通过单 Leader 多 Follower 机制，在 Leader 节点上对所有操作进行排序，从而决定了整个操作顺序，并将操作顺序进行广播。 全序广播要求满足如下两个属性总是被满足： 可靠的交付,没有消息丢失： 如果消息被传递到一个节点，它将被传递给所有节点。完全有序传递，消息以相同的顺序传递给每个节点。 全序广播是异步的：消息保证以固定的顺序可靠地传递，但不能保证何时传递消息（因此存在节点可能落后于其他节点）。而线性化一致性能够保证：每次读操作能够读到最新值的写入。我们可以依托于全序广播，在存储上实现线性化一致性。全序广播需要一个序列生成器，然而这又是一个共识问题。 共识所谓共识，指的就是最终一致性。在理论上，如果节点可能崩溃，则共识不可能达成（FLP）。不过在现实中，节点崩溃是可以探测的，所以共识还是可以达成的。 二阶段提交当客户端准备提交事务时，协调者（事务管理器）开始阶段 1：所有参与者进行预提交，根据响应，分为两种情况： 所有节点准备完毕（使用 transaction id，完成相关写入）。进入阶段 2，开始真正的 commit； 任一节点未正确响应，进入 abort; 显然，各节点即使准备完毕，也可能因为异常导致并未正确提交，所以该节点在未做出正确答复之前，协调者会持续询问。 但是如果协调者也挂了，2PC就会卡住，必须等待协调者恢复，此时的状态称为存疑事务。 三阶段提交改进的二阶段提交，加入了询问机制。该协议假设网络延迟有界，这不符合正常的场景，所以一般还是用2PC. 异构系统的分布式事务方案：XA事务这是一种协议，由数据库自己实现。具体来说就是应用程序自己充当协调者发起异构系统之间的二阶段提交。 paxos 算法paxos 算法是分布式系统实现最终共识的当前唯一正确算法，raft 等算法只是其变种。他解决的是最终一致性（共识）问题，这个前面提的一致性不是一个概念。其流程如下： 阶段一： (a) Proposer选择一个提案编号N，然后向半数以上的Acceptor发送编号为N的Prepare请求。 (b) 如果一个Acceptor收到一个编号为N的Prepare请求，且N大于该Acceptor已经响应过的所有Prepare请求的编号，那么它就会将它已经接受过的编号最大的提案（如果有的话）作为响应反馈给Proposer，同时该Acceptor承诺不再接受任何编号小于N的提案。 阶段二： (a) 如果Proposer收到半数以上Acceptor对其发出的编号为N的Prepare请求的响应，那么它就会发送一个针对[N,V]提案的Accept请求给半数以上的Acceptor。注意：V就是收到的响应中编号最大的提案的value，如果响应中不包含任何提案，那么V就由Proposer自己决定。 (b) 如果Acceptor收到一个针对编号为N的提案的Accept请求，只要该Acceptor没有对编号大于N的Prepare请求做出过响应，它就接受该提案。 批处理这一章介绍了一些常用的处理工具，包括unix上常见的sed、awk等小工具和map-reduce. 后续还介绍了流式数据处理需要注意的问题。","tags":[{"name":"database","slug":"database","permalink":"http://yiuterran.github.io/tags/database/"},{"name":"note","slug":"note","permalink":"http://yiuterran.github.io/tags/note/"}]},{"title":"redis知识点总结","date":"2018-01-28T05:14:37.000Z","path":"2018/01/28/redis知识点总结/","text":"redis是现在web开发中用的最广泛的组件之一了，用了很多年，是时候总结一下用法和经验了。 持久化两个方案：DUMP和LOG。前者就是直接生成快照（SAVE），或者主进程fork一个进程（BGSAVE，内存使用要加倍）然后将内存里面的数据全部存入文件；后一个方案类似LSM-TREE的思路，将操作生成日志，并定期重写。 SAVE会导致其他命令被阻塞，BGSAVE同样也会（数据量过大时，复制内存本身也很消耗时间），而且系统如果down掉，save之后的数据就会丢失。 AOF的方案有两个问题：1是生成日志体积可能过大，2是恢复数据的速度比较慢。好在这两个都可以通过重写日志来改进。一般情况下，这两个方案是同时使用的。 事务redis并不支持传统意义上的事务，想要原子提交，最简单的办法是：使用lua脚本。注意lua脚本逻辑如果太过复杂，可能会使redis阻塞较长时间。 另一种方案是用WATCH配合MULTI和EXEC这两个命令，watch会生成一个乐观锁，当监控的变量改变时，后面的pipeline就会中断执行并在程序中抛出异常。事务在收到EXEC的时候才开始执行，前面的命令只是入列，而WATCH恰好持续到EXEC为止。注意如果pipeline中有命令出错，redis事务并不会终止，而是会接着把所有命令跑完，而且redis事务本身也不支持回滚，有需要的话你只能手动回滚。 HA简单的是一主一从，用SYNC（新版是PSYNC）同步到从库。 稍微复杂的是一主多从的哨兵模式，主down了以后会在从库中选出新的主。 集群本质仍然是sharding. redis集群节点之间相互通信，知道需要处理的命令在哪个分片，如果客户端查询到错误的节点，该节点会返回一个MOVED错误，redirect客户端到正确的节点。当然，如果使用redis驱动的话，对客户端是透明的。 由于每个节点负责多个分区（在这里称为slot），再平衡过程很简单，就是将其他节点的分区转移到新节点即可（移除节点也类似）。 集群和副本集配合使用，节点的副本即所谓“从节点”。 底层数据结构字符串 -&gt; 作者自己实现的简单动态字符串（SDS）；zset -&gt; skiplist（类似红黑树，但是更简单）list -&gt; 就是链表set/hset -&gt; hash表 优化：如果set都是数值，且数量较少，会使用intset节省内存；如果array和hset都是小整数或者短字符串，会使用ziplist节省内存。 GC：自己实现的引用计数。 过期策略redis将所有key的过期时间保存在一个公用的过期字典里，用来计算ttl. 过期删除使用惰性策略+定期删除。 save的时候会忽略掉已经过期的key，aof只有在显式删除key后才会追加DEL命令。不过aof重写日志的时候也会判断键是不是过期，类似save.","tags":[{"name":"redis","slug":"redis","permalink":"http://yiuterran.github.io/tags/redis/"}]},{"title":"面试复习纪要.md","date":"2018-01-25T04:21:36.000Z","path":"2018/01/25/面试复习/","text":"到 30 岁了，突然发现自己还是对编程理解的很浅，在此梳理一下技术栈，并准备新年的面试。 作为一个服务器开发工程师，涉及的技术相当之多，部分角度的深入理解需要花费大量时间，因此到最后一般是精通某个/几个方向，并对其他方向也有涉猎。 必备知识 基本数学知识。包括：数据结构、算法； web 相关技术。对于一般以业务为主的公司，这个就是吃饭的本事。细分如下： 通信相关基础知识，如Http，TCP，UDP，Socket编程等； 一门编程语言，一个或多个 web 框架。如 PHP + Laraval, Python + Flask, Ruby On Rails, Java + Spring 等； 理解框架底层原理，如select，epoll或者Java的NIO等设计机制；理解CSP和Actor并发模型；理解大并发下常见的优化策略； RDMS，不管是 oracle、mysql 或者 postgresql，除了基本的使用增删改查以外，还要了解常见的优化措施。随着 NewSQL 的兴起，大量分布式云数据库开始出现，如 TiDB, RedShift 和 HyriaDB 等. NoSQL，如 Redis，MongoDB 或者 cassandra； 此外还有内存数据库，其使用和 rdms 基本一致，如 Apache ignite； 以上数据库针对不同场景和数据量级，做不同的技术选型； Linux 的常见使用，运维方向的一些基础知识（Python 和 shell 是必备技能）； 常见应用层协议：http, https, websocket，rpc 分布式相关技术。随着业务的扩展，后端架构的复杂度会指数级上升，单机的性能无法满足业务需求，必须引入分布式系统。 基本理论。分布式系统非常复杂，必须熟读相关理论，如 CAP，Paxos 等，知道常见的问题和解决方案； 常见组件，如 docker, etcd等，各自的使用场景和原理； 常见框架，如 Spring Cloud 以及最新的 Service Mesh 的实现; 测试/运维相关技术。如果在小公司，一个后端开发一般同时担任部分运维和测试的职责。 版本控制相关，严格来说正确使用 git/svn 是所有开发的基本能力； 自动构建，快速部署。Docker 相关技术； 线上监控，告警系统； 自动化测试系统； 大数据相关技术。所谓大数据，其实本质上就是 OLAP，由于数据量过大，rdms 已经无法承载对应的数据量和性能需求。 数据收集：如 flame 等； 数据存储，如 HBASE，hive 等； 数据分析：如 spark、Hadoop 等； 扯淡的人工智能。 对于大部分公司而言，人工智能是不应被涉足的领域。 深入领域 整体架构 并发模型目前web架构，单体应用的并发模型，perfork是典型的多进程思路，一个master进程用于接受并分配请求，fork出的worker进程用于处理实际的请求；而Java的BIO是典型的多线程思路；Go对每个连接启用一个goroutine，是典型的多协程思路。 perfork的worker进程可以用epoll等同时处理多个请求，这是I/O多路复用。Java的NIO也是类似的思路，本质是用事件机制达到更好的cpu利用率，同时加大负载能力。Nginx，uwsgi都是perfork架构的，由于python的GIL问题，uwsgi的worker一般只有一个线程。当然python还有tornado这种框架，也是用event loop的方式实现i/o多路复用。或者说，协程的方式。 对于异步编程，业界最流行的是async/await其实就是协程模型，协程本质是用户态下的线程，用户可以自己手动切换上下文进行让渡(await即可）；相比之下，goroutine的调度更加简单，因为他是有栈协程，一旦发生IO阻塞，调度器会自行切换协程，用户在编写代码的时候无需关心这一点（当然也可以自己手动切换，用channel阻塞即可）。在和已有第三方组件的对接上，有栈协程可以吊打promise，因为它就是正常的写阻塞代码就行，而async/await会污染所有相关代码，比较麻烦。 对于Java，默认的BIO就是传统的多线程模型，比如web服务器就是简单的一个请求一个线程，发生IO事件的时候线程也要阻塞等待，浪费cpu；NIO就是收到事件通知（数据就绪）才开始IO（阻塞），也就是io多路复用；AIO就更牛逼了，系统直接告诉你读完了，调你的回调就行。可惜AIO需要操作系统支持，目前只有Windows上的IOCP可以满足这个条件，所以一般不讨论。 此外，linux2.6以前i/o多路复用使用select，之后使用epoll. 2.6以前accept存在惊群问题，之后内核只会唤醒等待队列上任一个进程。但是epoll也存在惊群问题，多个worker在事件抵达的时候会被同时唤醒。直到linux3.9加入SO_REUSEPORT特性，允许多个进程监听同一端口，将listen从master进程移入worker进程，这个问题才得到解决。 单体架构经典的MVC结构。旧时代里，asp/jsp/php以及集大成者的ror都是mvc结构，前后端不分离，直接由服务器渲染出页面。ror之所以流行，是因为其约定大于配置的设计大幅度简化了开发流程，SpringBoot相对于SpringMVC其实只是引入了这一思想进行简化。 自从前端工程化以来，前后端基本分离，后端仅仅提供API接口，这时候的单体应用更加简单。随着服务规模的越发庞大，单体后端承担的职能越来越多，需要对服务进行拆分以减少体积和维护难度。 SOA和微服务微服务其实只是对SOA做了更细粒度的优化。拆分服务引来的问题包括：服务间通信和分布式事务。服务间通信可以通过一个集中的渠道，即所谓的通信总线（API网关）；也可以直接相互通信。使用HTTP的话，直接用DNS和Nginx就可以做API网关了；使用rpc的话，比如grpc也提供了生成API网关的方法。 微服务还引入了服务熔断、配置分发、服务发现等组件，这些也是需要关注的。 Spring Cloud和Service Mesh这是两种不同的微服务思路，前者是一个框架，由各种组件构成，应用代码里明确知道这些组件的存在并需要进行处理；后者是外挂式的组件，代码对组件是无感知的，比如连接集群和连接单点都是通过proxy，代码不关心自己连的是什么。一个简单的例子，mysql分库分片可以用proxy来完成，也可以在代码里写死。显然service mesh更符合低耦合的思路，也是微服务真正的未来。 编程语言 虽然理论上来说，通用设计语言可以完成的事情都是一致的，不过各语言的特性和历史的沉淀导致了如今的情况是这样的： * 前端领域js独占鳌头，es6以后js语言基本完善了；当然强类型的TS也有它的优势； * 后端领域Java占了半壁江山，这不是因为Java多么牛逼，完全是历史的沉淀导致。Java至今没有协程支持（project loom遥遥无期），编写繁琐，很多人讨厌。Go是冉冉上升的另一个明星，简单的语法、快速的开发速度、强有力的并发模型；当然缺点是不支持泛型和繁琐的错误处理。Go2会解决这些问题，希望早点来到。除了这两个以外，其他的语言在服务端领域基本上都会被淘汰，比如Python其实更适合做快速原型，所以更适合非工程人士，当然拿来写个脚本也是极好的； * 大数据领域基本还是Java/Scala的天下，当然基本也支持python了。个人感觉Scala过于复杂了，还是尽量灭了吧； * 高性能领域仍然是C/C++的天下，Rust也开始逐渐普及。不过Rust还是有很多坑，且门槛太高，短时间内个人不再看好； * 客户端领域语言就比较复杂了。Windows还是C#的天下，Android则是Java和Kotlin，苹果的是swift和oc；新兴框架中，flutter的dart也是很重要的； 总结来说，当前后端开发应该掌握的语言包括：Bash/C/C++/Java/Python和Go，可以学习的语言包括Rust. php/nodejs/ruby的存在完全是历史意义上的，基本没有存在价值。在通信协议上，HTTP1/2/3都会逐渐流行，websocket的效率则更高。grpc是over http2的，这个设计很蛋疼，很多时候不如自己rpc over websocket实用。 常用框架源码 python的常用框架：django/flask/tornado/greenlet/celery/sqlalchemy java的常用框架：spring/springMVC/springBoot/springCloud/Netty go的常用框架：gin/fasthttp 常用组件源码 db级别的估计只能看看sqlite了 mq可以研究一下zeromq、kafka和rabbitmq 各类分布式相关组件 数据库优化 mysql通过执行计划、慢查询日志进行优化，各类索引添加等 redis使用优化，事务粒度，数据结构，pipeline等 es优化，JVM参数，分词，shard设置等","tags":[{"name":"算法","slug":"算法","permalink":"http://yiuterran.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数学","slug":"数学","permalink":"http://yiuterran.github.io/tags/%E6%95%B0%E5%AD%A6/"}]},{"title":"SpringMvc4 Rest Api最佳实践","date":"2017-07-16T02:33:34.000Z","path":"2017/07/16/SpringMvc4-Rest-Api最佳实践/","text":"因为项目的需求更改，部分API与JSP之间的交互方式由直接渲染改成ajax，所以需要调研SpringMVC在Rest上最佳实践。下面是汇总的内容，参考了网上的一些文章。 所谓IOCSpring最常提起的是AOP和IOC两大作用，他们主要解决了……Emmm，Java语言设计的问题。由于Java是Pure OO语言，很多时候写起来非常繁琐。Spring IOC一个大工厂，在配置文件或者代码里把类注册成Bean（可以指定构造函数的参数和bean的id等），然后框架再把这些Bean注入到@Autowired(按类型注入)，@Resource(按名称)等注解的变量（也可以使用XML配置的方式注入）。 默认情况下，注册的都是一个单例，spring每次创建新对象时都使用同一个对象。也可以在xml中配置为prototype，这时候就是每次new一个新的对象了。另外spring mvc另外加了两个生命周期：session和request，分别表示为单次请求和session有效期内的对象。使用@Scope修改生命周期（作用域）。 可以使用@PostConstruct和@PreDestroy注册两个回调方法，在spring实例化Bean（并装配）后回调对象对应的方法。 一般使用@Component注册bean，@Service, @Controller和@Repository都是其别名。 此外，还可以使用配置类(@Configuration)代替xml注册bean(@Bean)，在其注解的方法内进行恰当的初始化，并返回一个对象注册为Bean. @Configuration具有@Component的作用，在类里面也可以直接注入。但是如果想要引用其他配置类的Bean，需要使用@import. 所谓AOP可以简单理解为python中的装饰器…由于Java语法不支持装饰器，想要完成类似装饰器的用法，只能通过反射。比如，先声明一个类，完成主要的工作，称为target. 再通过一个类实现org.springframework.aop.MethodBeforeAdvice，其参数中捕获target的参数完成前置工作。最后通过spring的ProxyFactory生成代理工厂，设置target并添加advice，最后用代理工厂生成实例。 需要注意的是，Java本身的动态代理是基于接口的。对于没有实现任何接口的类，只能通过CGLIB通过继承进行代理，但是后者显然不支持final类。spring在生成对象时会优先选择JDK代理，不行再尝试CGLIB代理。 当然，除了在代码中使用，也可以用xml配置（实际上Java很多代码都可以通过xml实现，这也是非常惹人生厌的地方）。 最后，还可以用一种特殊的声明方式：AspectJ。这种方式的好处是，对方法的调用者而言，这种增强是透明的。也就是说，他可以直接用getBean(target)来获取bean实例，然后在调用方法的时候，实际上调用的是代理增强后的方法。也就是说，更加解耦。 分层顾名思义，就是传统的MVC。model层就是一般的POJO(DO)，DAO层一般用mybatis，service层用@Service注册，view层用@RestController注册rest api，用@RequestMapping绑定路由。使用@PathVaribale取url中的参数，用@RequestHeader取header中的数据，用@CookieValue取cookie中的数据，用@RequestBody将json转为object，用@ResponseBody将返回值转为json. 参数有效性检测一般用JSR-303，使用@NotNull、@Max, @Min, @Length等注解，使用@Valid配合上面的@RequestBody一次性完成检测和转换。","tags":[{"name":"Java","slug":"Java","permalink":"http://yiuterran.github.io/tags/Java/"},{"name":"SpringMVC","slug":"SpringMVC","permalink":"http://yiuterran.github.io/tags/SpringMVC/"},{"name":"Web","slug":"Web","permalink":"http://yiuterran.github.io/tags/Web/"}]},{"title":"报表打印(pdf)技术选型","date":"2017-07-06T16:21:00.000Z","path":"2017/07/07/报表打印-pdf-技术选型/","text":"做的外包项目有这个需求：输出PDF格式的单据，稍微调研了一下实现方式，做个汇总。 首先吐槽一下…做外包还是尽量用成熟技术，下次再做管理平台的需求，还是flask-admin配上JQuery上吧。这次用vue+elementUI，写的倒是挺爽，关键时候找不到组件还要自己造轮子，效率堪忧_(:зゝ∠)_ 服务端实现Python这边用ReportLab比较多，稍微研究了一下发现过于复杂。利用xml定义了一套新的语法，叫RML，如果要写的话，先要学习一遍这个东西，成本太高。而且像这种学完基本不怎么用的东西，很快就忘了…不建议使用。 使用pdfkit，这玩意儿底层调用了wkhtmltopdf，看名字也知道使用html转pdf. Sphinx本质上是调用$\\TeX$来渲染成PDF，依赖项比较复杂，但是控制粒度非常好（毕竟是标准）。 客户端实现 使用HTML做普通排版，然后调用print.js. 结果：效果很差，样式丢失严重。 使用jsPDF，不支持中文。 使用pdfmake，嵌入中文字体后，生成要求的内容，然后就可以直接调用接口，很爽…生成内容直接用JS内置的数据结构就可以完成。使用起来最简单，但是：嵌入字体后资源文件太大（至少2M+），除非使用TTF裁剪，不然浏览影响很大；其次：浏览器兼容性不好，用起来很受限。我本来尝试了一番，最后还是放弃了。不过不得不说的是，如果使用nodejs作为服务器的话，选这个方案很好。 pdfkit最终选型使用pdfkit方案。 安装依赖主要依赖wkhtmltopdf这个二进制文件。注意，如果使用的是ubuntu16.04，请不要直接使用ubuntu源里面的该文件，源里面是without qt patched的，需要自己下载安装，具体步骤是： 123456sudo apt-get updatesudo apt-get install libxrender1 fontconfig xvfbwget https://github.com/wkhtmltopdf/wkhtmltopdf/releases/download/0.12.4/wkhtmltox-0.12.4_linux-generic-amd64.tar.xz -P /tmp/cd /opt/sudo tar xf /tmp/wkhtmltox-0.12.4_linux-generic-amd64.tar.xzsudo ln -s /opt/wkhtmltox/bin/wkhtmltopdf /usr/local/bin/wkhtmltopdf 然后使用pip install pdfkit安装Python这边的依赖即可。 如果是Linux服务器，记得安装中文字体，使用文泉驿正黑即可(wqy). 具体使用几个要点： 报表的HTML文件最好不要依赖外部css，全部直接内嵌在文件中比较方便； HTML需要声明为utf8编码； 不要对文件使用中文名称； 渲染的时候有些参数需要设置，如下： 1234567891011pdfkit.from_string(page, outfile, options=&#123; &#x27;page-size&#x27;: &#x27;A4&#x27;, &#x27;margin-top&#x27;: &#x27;0.75in&#x27;, &#x27;margin-right&#x27;: &#x27;0.75in&#x27;, &#x27;margin-left&#x27;: &#x27;0.75in&#x27;, &#x27;margin-bottom&#x27;: &#x27;0.75in&#x27;, &#x27;encoding&#x27;: &quot;UTF-8&quot;, &#x27;no-outline&#x27;: None, # &#x27;zoom&#x27;: 1.5, # when run on mac # &#x27;dpi&#x27;: 250&#125;) 其中0.12.4版本mac上运行的时候，需要设置最后两个参数才能保证字体大小看起来比较正常. pdfkit渲染速度超快，非常👍","tags":[{"name":"python","slug":"python","permalink":"http://yiuterran.github.io/tags/python/"},{"name":"js","slug":"js","permalink":"http://yiuterran.github.io/tags/js/"}]},{"title":"oracle学习笔记","date":"2017-07-03T06:21:18.000Z","path":"2017/07/03/oracle学习笔记/","text":"工作以后只用过MySQL，互联网公司也基本都是MySQL了。现在来到了金融公司，不得不进行Oracle的逆入门（毕竟一般人都是Oracle到MySQL）。 安装Mac下可以使用docker安装，可以参考这篇博客. 概念OLTP：在线事务处理系统，强调数据库的内存效率，强调内存各种指标的命中率，强调绑定变量，强调并发操作。用户并发数都很多，但他们只对数据库做很小的操作，数据库侧重于对用户操作的快速响应。OLAP：在线分析系统，强调数据分析，强调SQL 执行时长，强调磁盘I/O，强调分区等。主要用户数据分析，对于性能要求没那么高。 索引oracle的索引分为B-tree, Bitmap，Hash等，其中位图索引不能被声明为唯一索引，适合候选值很少，且不频繁改动的列。对于高并发系统，不要使用位图索引。 函数索引：如果查询的时候总是使用某个函数，使用函数索引较多。例如，对于搜索大小写不敏感的字段，查询的时候总会使用Upper函数将其转为大写，但是存放的时候还是用户的原始数据，就可以建立一个函数索引。 分区表类似MySQL中的shard，不同的是Oracle自带了这个功能。现在基于MySQL的TiDB，以及各类开源的Proxy功能也可以实现透明分区。注意：含有LONG、LONGRAW数据类型的表不能进行分区。 分区方法： 1. 范围分区：以某个字段的range为标准进行分区，适合以日期分割的历史数据，如交易记录 1. 哈希分区：以某个字段的hash为标准进行分区，分区 1. 列表分区：以某个字段的值为标准进行分区，适合列为有限枚举值的情况 1. 组合分区：以Range分区作为根分区方法，其他分区作为子分区 Oracle可以自动根据时间建立分区表。 锁整体和MySQL类似。使用LOCK TABLE tablename的格式加表锁。 使用SELECT..FOR UPDATE方式加行级锁。 当COMMIT或者ROLLBACK后，释放锁。但是ROLLBACK不能释放行级锁。其他的锁主要是供系统使用，是DBA需要掌握的内容，包括如何解决死锁等。 体系结构MySQL的体系结构非常简单：database ——&gt; table，可以随意创建用户，然后我们通过grant命令赋予用户对库、表的访问权利。 Oracle的体系稍微麻烦一些，database（数据库实例，又称为SID）还存在，但是下一级不是table，而是tablespace（表空间，一个实例可以有N个表空间。表空间创建时可以指定大小），再下一层是具体的数据文件。如果想要建表，必须创建用户(user)，并为用户指定表空间。这个是物理存储角度下oracle的结构。 在逻辑概念上，SID下面一层是用户，存储过程、函数、表、序列等等，则是隶属于这个用户的对象(object)。用户创建任意object后，会默认生成一个方案(schema，与用户对应)，在逻辑上，这个用户创建的所有object属于这个schema，即使这些object属于不同的tablespace. 在权限管理上，user默认有自己schema的所有权限，如果用户想要访问其他schema的object，必须赋权。 一般流程：创建database -&gt; 创建tablespace -&gt; 创建user（指定默认的tablespace） -&gt; 用户建表。 有关表的元数据被存放在数据字典中。 权限默认情况下，oracle会自动创建若干个用户，如sys, system和scott(Tiger)，并提示输入默认密码. 使用sqlplus登入后，使用命令select username,account_status from dba_users;获取所有账户状态，有需要的话可以使用password命令修改密码。 创建用户：类似MySQL，使用create user root identified by &#39;123456&#39;;，然后使用alter user root account unlock解锁用户。 权限：分为系统权限（如建表、建库等）和具体的数据权限（增删改查等）。用户可以将自己schema下的object授权给其他用户，或者使用管理员账户进行授权。语句格式大致为grant select on emp to root with grant option. 收回权限：revoke select on emp from root. 删除用户： drop user root cascade，删除用户会导致用户名下所有的数据都被删除，谨慎使用。 可以使用profile进行安全策略的限制（输错密码次数、密码过期时间、密码强度限制等等）。 使用我们先通过sys等系统dba账户登入，创建项目需要的管理员账户，然后赋予connect, resource和dba的权利。然后使用这个账户登入，创建项目需要的表。 注意：oracle命令默认是区分大小写的，但是如果不加双引号的话，所有的字段、命令都会被转化为大写。一般情况下，使用单引号来引用字符串，如果字符串里面有单引号，需要使用两个单引号转义。如果用了系统关键字（或者空格等符号），则使用双引号包围字符串。 使用上和MySQL有很多细节的不同，主要包括： 自增。需要先create sequence myseq increment by 1 start with 1000创建一个自增序列，然后在插入的时候使用myseq.nextval来取得自增的值（有点类似mongo）； 外部脚本。使用@ xxx.sql导入； 表达式。使用select 3 * 2 from dual; 系统时间。使用select sysdate from dual，具体格式可以使用select to_char(sysdate,&#39;yyyy-mm-dd&#39;) from dual;; 修改表名。 rename xx to yy; 分页。Oracle的分页做的很挫…最好使用id分页，如果要用数据库自身的分页，需要使用嵌套子查询。oracle对每一列有rownum和rowid两个虚列，前者是结果集的序列（从1开始），后者是物理上每一行的id。 1234567SELECT * FROM(SELECT A.*, ROWNUM RNFROM (SELECT * FROM TABLE_NAME ORDER BY x) AWHERE ROWNUM &lt;= 40) TWHERE RN &gt;= 21 这里最里面那一层是真正的SQL语句，进行全表搜索。然后ROWNUM&lt;=40表示只要前四十行，最外层表示在这前40行里面只要第二页（假设每页20个）的.需要注意： rownum是自动生成的，所以内层的rownum只能用&lt;=，而绝对不能用&gt;=10这种，因为生成的列永远从1开始； 如果有order by字段，必须有三层查询，最内层做排序，次外层选择前N条，最外层做偏移量 建表oracle建表有很多可选参数，其中： pctfree：用于指定BLOCK中必需保留的最小空间的比例。 pctused：为一个百分比数值，当BLOCK中已经使用的空间降低到该数值以下时，该BLOCK才是可用的，达到或是超过这个数值的BLOCK是不可用的。 一般在控制具有独立segment结构的对象时，使用这两个参数来控制BLOCK的存储管理。 initrans：指定可以并发操作该表的事务的数目。 如果你预计只有很少的更新操作会增加行的大小，则可将PCTFREE设置为较低的值（如5或者10），使得ORACLE填满每个块的更多的空间。但是，如果你预计更新操作将会经常增加行的大小，则将PCTFREE设置为较高的值（如20或30），使得ORACLE为已有行的更新操作保留更多的块空间；否则，将出现行链。 如果你预计很少有删除操作，则可设置PCTUSED为较高的值（如60），当偶然的删除操作发生时，使数据块弹出可用清单。但是，如果你预计将PCTUSED 设置为较低的值（如40），使ORACLE不常产生块在表的可用空间中移进或移出的开销。 PL/SQLPL/SQL是针对Oracle特有的SQL语句，不可移植。 基本单位：块(block). 语句：声明(declare)，执行(begin…end)，异常处理(exception..end) 运算符：注意||是字符串连接，其他和MySQL差不多 变量命名：DECLARE test VARCHAR(20)，命名规范： 至多有30个字符 不能是保留字 必须以字母开头 不允许和数据库中表的列名相同 不可包括$,_和数字以外的字符 变量定义（类似go语言）： v_number NUMBER(2) NOT NULL := 20，常量使用CONSTANT. 可以在声明时指定其他变量的类型作为其类型（类似泛型），格式是var%TYPE 基本数据类型就是JDBC中的那些，常用的是Number和varchar2, boolean, date这几个。数组类型使用VARRAY(size) OF element_type [NOT NULL]的形式，使用(n)进行下标访问 复合数据类型: 1234TYPE type_name IS RECORD( fieldname fieldtype, fieldname fieldtype); 显然这玩意儿类似C语言中的struct. 也可以直接用table%RAWTYPE声明一个同表结构的记录。甚至可以直接声明表类型，类似一个数据，格式为： 1234 declare type ename_table_type is table of emp.ename%type index by binary_integer;ename_table ename_table_type; 可以使用ename_table(-1)进行下标访问，使用.FIRST和.LAST访问第一行和最后一行。 除了普通变量外，还有替换变量。主要用于人机交互，&amp;前缀表示提示用户输入，且仅此次有效，&amp;&amp;前缀则表示永久有效，仅需要输入一次。 变量的可见范围，在DECLARE中声明的变量，在后面的BEGIN块中可见。 游标游标是查询结果集的指针。显式使用语法： 1234CURSOR cursor_name[(parameter[, parameter]…)] [RETURN datatype]IS select_statement; 游标里面显然不能用SELECT..INTO..，而是要手动遍历。使用OPEN cursor_name打开游标，执行语句。使用FETCH cursor_name INTO xxx取出游标对应的行，FETCH以后，游标会自动指向下一行。游标不能回退，使用完毕后要记得CLOSE掉。 可以通过参数类型sys_refcursor传递游标。接受的函数/存储过程必须使用OPEN xxx FOR SELECT打开游标进行赋值。 游标属性包括： Cursor_name%FOUND 布尔型属性，当最近一次提取游标操作FETCH成功则为 TRUE,否则为FALSE； Cursor_name%NOTFOUND 布尔型属性，与%FOUND相反； Cursor_name%ISOPEN 布尔型属性，当游标已打开时返回 TRUE； Cursor_name%ROWCOUNT 数字型属性，返回已从游标中读取的记录数。 可以直接使用FOR var IN CURSOR LOOP进行循环取值。 除了显式使用以外，普通的update、insert和delete语句也会自动生成隐式游标，可以用SQL查询上面的属性。 使用SELECT FOR UPDATE [NOWAIT]加悲观锁，如果使用 FOR UPDATE 声明游标，则可在DELETE和UPDATE 语句中使用WHERE CURRENT OF cursor_name子句，修改或删除游标结果集合当前行对应的数据库表中的数据行。 除了静态游标外，还可以使用游标变量，形式是： 12TYPE ref_type_name IS REF CURSOR [ RETURN return_type]; 语句条件语句：IF..THEN..ELSIF..ELSE..ENDIF，或者CASE..WHEN..THEN..ELSE..END 循环语句：LOOP..EXIT WHEN..END LOOP, 或者FOR..IN..LOOP..END LOOP, 或者WHILE..LOOP..END LOOP 范围循环使用..连接上下限. 使用GOTO跳转到label, label使用&lt;&lt;&gt;&gt;标示起来 包（package）有点类似C/C++，先声明包头，然后创建包体。包名自动被注册到schema下，可以直接调用。 包是pl/sql实现抽象的主要途径。创建包的语法为： 12345678CREATE [OR REPLACE] PACKAGE package_name &#123;IS | AS&#125; [公有游标定义[公有游标定义]…] [公有函数定义[公有函数定义]…] [公有过程定义[公有过程定义]…]BEGIN 执行部分(初始化部分)END package_name; 上面类似C/C++中的头文件，导出了可供外部调用的函数和过程、游标。 包体则对应具体的实现，其语法为： 12345CREATE OR REPLACE PACKAGE BODY pkg_nameIS[私有内容定义][公有内容定义]END 这样，就可以在其他函数/存储过程里面通过package_name.function_name来调用包内的函数/过程了。 函数(function) &amp; 存储过程(Proceduce)调用函数可以用命名传递方式，即func_name(1, param2 =&gt; 1)，同时声明的函数参数可以用DEFAULT关键字指定默认值。 类似函数，除了无返回值，定义语法： CREATE ［OR REPLACE］PROCEDURE procedure_name [(argument_name [IN | OUT | IN OUT] argument_type [DEFAULT value])] AS | IS BEGIN procedure_body; END [procedure_name]; 其中: IN：表示是一个输入参数，可以指定缺省值。如省略参数类型，则缺省为in类型 OUT：表示是一个输出参数 IN OUT：既可以作为一个输入参数，也可以作为一个输出参数来输出结果 调用语法： EXECUTE ｜CALL procedure_name [(argument_list)] 异步IO使用dbms_job.submit可以异步调用存储过程 异常预定义了以下异常： NO_DATA_FOUND SELECT ... INTO ... 时，没有找到数据 DUL_VAL_ON_INDEX 试图在一个有惟一性约束的列上存储重复值 CURSOR_ALREADY_OPEN 试图打开一个已经打开的游标 TOO_MANY_ROWS SELECT ... INTO ... 时，查询的结果是多值 ZERO_DIVIDE 零被整除 当然也可以自己声明EXCEPTION, 在程序中RAISE出来。处理语法是BEGIN..EXCEPTION..WHEN..THEN..WHEN OTHERS THEN...END 使用SQLCODE和SQLERRM分别取得错误码和错误信息，还可以使用RAISE_APPLICATION_ERROR(error_number,error_message,[keep_errors] );将异常传递到客户端","tags":[{"name":"oracle","slug":"oracle","permalink":"http://yiuterran.github.io/tags/oracle/"},{"name":"db","slug":"db","permalink":"http://yiuterran.github.io/tags/db/"}]},{"title":"maven和gradle一些选项","date":"2017-06-26T01:32:23.000Z","path":"2017/06/26/maven和gradle一些选项/","text":"Java的包依赖系统简单粗暴，就是直接下载jar包，经历了Ant -&gt; Maven -&gt; Gradle这几个阶段，目前的项目里面还是Maven比较多，后续我会试着迁到Gradle上。 如果用一句话来表明区别的话：Gradle的配置文件是一种DSL，而Maven则使用XML，表达能力不可同日而语。 冲突Maven在多个模块依赖同一个模块时，需要手动处理版本冲突问题（将公共依赖手动排除），而Gradle会尝试自动解决该问题（使用公共依赖的最新版本）。 scope类似npm中的概念：这个包是啥时候被需要。显然有些包只是编译的时候需求，运行的时候不再被需要，因为Maven中的scope分为以下几种： compile. 默认范围，会被打包。 provided. 这个概念比较模糊，意思是这东西由外部容器提供，不需要自己打包进去。 runtime. 只有运行和测试系统的时候需要，编译的时候不需要。一个典型的例子就是jdbc的接口API在编译时必须要可用，但是具体实现可以只在运行时插入。 test. 只被测试依赖。Maven有标准的测试流程。 system. 系统范围，jar包被放在本地，无须从仓库中寻找。当然一般不推荐使用。 Idea的使用Idea中可以在Project Structure里面直接修改配置，会自动生成/修改对应的Pom文件，主要在modules/dependencies里面改。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"maven","slug":"maven","permalink":"http://yiuterran.github.io/tags/maven/"},{"name":"gradle","slug":"gradle","permalink":"http://yiuterran.github.io/tags/gradle/"}]},{"title":"Bash on Ubuntu on Windows下载过慢问题的简单解决","date":"2017-06-14T14:54:10.000Z","path":"2017/06/14/Bash-on-Ubuntu-on-Windows下载过慢问题的简单解决/","text":"经验证，最有效的方法是修改系统DNS为4.2.2.1，其他什么不用做…","tags":[]},{"title":"jeesite代码解析","date":"2017-06-12T16:46:00.000Z","path":"2017/06/13/jeesite代码解析/","text":"现在某个项目需要用到Java Web来写控制台，考虑到外包人员的能力，这边只能用传统的JSP技术来写了… 技术选项上用了jeesite这个成熟框架。该框架使用了最传统的SpringMVC + MyBatis，然后装了一堆框架，我会根据需求删掉其中大部分内容但是保留其基础框架。 基础知识补充常见Java注解： 四个元注解包括： Target: 标示注解使用的位置； Retention: 标示在什么级别保留注解信息； Documented: 标示要讲注解记录在JavaDoc中； Inherited: 允许子类继承父类的注解； 基本架构Java Web有一套成熟的抽象体系，自上到下分别是Controller(接入层) -&gt; Service(服务层) -&gt; Entity(数据实体层) -&gt; DAO(数据操作层)。 DAO这里DAO底层是一个泛型接口CrudDao&lt;T&gt;，这里定义了一些常见的接口（增删改查）。 对于每个具体的表，定义了接口，并使用MyBatisDao注解，通过查看代码可以知道，这是一个自定义注解，且是一个Component元注解。在spring-context.xml中有： 123&lt;context:component-scan base-package=&quot;com.thinkgem.jeesite&quot;&gt; &lt;context:exclude-filter type=&quot;annotation&quot; expression=&quot;org.springframework.stereotype.Controller&quot;/&gt;&lt;/context:component-scan&gt; 这里表示扫描除了Controller层以外的其他组件。MyBatis的配置为： 1234567 &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;org.mybatis.spring.SqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt; &lt;property name=&quot;typeAliasesPackage&quot; value=&quot;com.thinkgem.jeesite&quot;/&gt; &lt;property name=&quot;typeAliasesSuperType&quot; value=&quot;com.thinkgem.jeesite.common.persistence.BaseEntity&quot;/&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:/mappings/**/*.xml&quot;/&gt;&lt;property name=&quot;configLocation&quot; value=&quot;classpath:/mybatis-config.xml&quot;/&gt; &lt;/bean&gt; dataSource是数据源，这里配置为MySQL的连接池，用的是Druid这个阿里的开源库（这里是单库）。typeAliasesPackage是映射的起始路径包，typeAliasesSuperType是实体类的父类，mapper的注释在mappings下面，组件自身的配置在mybatis-config.xml里。 在resources/mappings下面，定义了对应路径映射的model，这里的数据可能是代码生成器生成的（手动写的话工作量有点大啊…），以及各种DAO中定义接口的具体实现。这里的语法本质上是拼装sql… 这里有个问题，idea对MyBatis的支持不太好，需要自己找插件（但是收费），也有一些免费但是不太好用的。 MyBatis的SQL语法官方教程在此 用例子说明： 1234//`User` is Entityinterface UserDao extends CurdDao&lt;User&gt; &#123; public User get(String id);&#125; 1234567891011121314151617181920212223242526272829&lt;sql id=&quot;userColumns&quot;&gt; # sql片段 a.id, a.company_id AS &quot;company.id&quot;, # compony是`User`的一个成员 a.office_id AS &quot;office.id&quot;, a.login_name, a.password, a.create_by AS &quot;createBy.id&quot;, a.create_date, a.update_by AS &quot;updateBy.id&quot;, a.update_date, a.del_flag, c.name AS &quot;company.name&quot;, c.parent_id AS &quot;company.parent.id&quot;, c.parent_ids AS &quot;company.parentIds&quot;,&lt;/sql&gt;&lt;sql id=&quot;userJoins&quot;&gt; # sql片段 LEFT JOIN sys_office c ON c.id = a.company_id&lt;/sql&gt; &lt;select id=&quot;get&quot; resultType=&quot;User&quot; parameterType=&quot;string&quot;&gt; # id对应Dao中方法的名字，resultType是 SELECT &lt;include refid=&quot;userColumns&quot;/&gt; FROM sys_user a &lt;include refid=&quot;userJoins&quot;/&gt; WHERE a.id = #&#123;id&#125; &lt;/select&gt;&lt;select&gt; 熟悉了很快就能上手，一般情况下，自动映射可以处理绝大多数问题，只有特别复杂的结果集需要自定义resultMap. ehcacheJava中常用的cache，支持单机也支持分布式，但是分布式配置较为复杂，一般还是使用Redis居多。 这里ehcache的使用看得我一脸懵逼，好像直接缓存了POJO类，然后取出来后直接强制转换回来就可以了。理论上这不对啊，缓存肯定要序列化的…然后仔细研究了一下Java的序列化（类似Python的pickle）。 结果发现只要标记了Serializable的类都可以被序列化，但是如果类被修改了，就要注意是不是修改serialVersionUID了。必须要修改（一般是递增）该ID的情况有（来自Java官方网站）： 删除了成员 修改了类的继承层次 将一个非静态成员改成静态，或者将一个非忽略成员改成忽略(transient) 修了了原始类型成员的类型声明 修改了writeObject或者readObject方法 将类从Serializable改为Externalizable，或者移除了标记 将类改为枚举类型 但是以下情况无须修改： 增加成员：新增成员会使用默认值 增加类：也是使用默认值 移除类 增加writeObject/readObject方法 移除writeObject/readObject方法 增加java.io.Serializable 修改成员的修饰符 将成员由静态改为非静态，或者忽略改成非忽略 其实这些并不是很好记忆…所以更好的使用经验是，不要试图序列化整个类存在缓存中，而是只缓存一些必须的变量，然后用这些变量构造对象，变量使用Java标准库内置的数据结构，这些数据结构默认都是可序列化的。 Entity这一层本质上是db上对应表的model，但是和Python不一样，这里和表不是一一对应的，而是一个整合的数据集。 换句话说，每个Entity可能对应很多个表，这里的抽象思路和Python不一样。Entity是一个POJO，而不是继承某个类而得来。当然我还是更喜欢Python的抽象思路，Model原子性和Table保持一致，可以自由组合。 项目抽象了BaseEntity，在此基础上又总结了集中常见的数据模型。 事务使用Spring的事务管理，最后只要在方法上使用@Transactional注解就可以使用一个事务式的方法（只能在public方法上使用），这个注解只会在被外部调用时触发。 关于事务方法和非事务方法之间的相互调用，参考stackoverflow @Transactional 默认只对 unchecked exception 异常进行回滚操作，checked、unchecked 异常使用不当造成事务无效，抛出的异常应该是RuntimeException的子类。 Service层Service层处理实际的业务逻辑，这里抽象了基类BaseService里面定义了方法用来鉴权；CurdService层是简单增删改查的服务，这是一个泛型类，泛型参数是Dao和Entity；对于树形数据结构，还特别定义了TreeService对应了TreeDao和TreeEntity； 流程解析 直接运行项目，会自动打开浏览器，跳转到登录页。这个应该是在哪里配置的，暂时不明； 首页会匹配到modules/sys/web/LoginController里面的index方法； 该类继承自BaseController，这里定义了logger, adminPath, frontPath和urlSuffix，这些变量是从bean里面注入的. 同时定义了一些通用的方法； 所以index方法中的RequestMapping, $&#123;adminPath&#125;会被渲染为a，另外这个注释来自SpringMVC； RequiresPermissions是使用Apache shiro进行鉴权，详见鉴权流程； 如果用户没有登陆，会跳转到a/login，后者最终跳转到modules/sys/sysLogin； 如果用户已经登陆，会跳转到modules/sys/sysIndex，即网站的首页； 如果是mobile登陆，这里不再使用服务端渲染，还是返回了一个Json串； 其他的模块也类似，入口都在模块下的web包里面。Controller层调用Service层（一般是Autowired注入的），Controller有个共同基类BaseController，这是一个POJO，里面定义了一些公用的方法，如参数鉴定、view渲染和异常处理。 参数鉴定用的是JSR303里面规定的的一些注解，这些约束被写在Entity中。 Controller与JSP的交互Controller与JSP这一层的联系通过大量注释和隐含条件完成。 由于JSP是很集成化的东西，所以前端表格直接和后端Entity是对应的，前端用JQuery直接修改DOM元素做渲染，用户输入——JQuery修改界面——用户提交——后端从表格中取出模型形成数据——处理完毕返回新数据构成的页面。 后端使用ModelAttribute注入模型，前端可以直接引用模型里面的元素。前端使用的后端模型中的元素作为querystring或者post中的元素，后端也可以声明为对应方法的参数。 鉴权流程使用了组件Apache Shiro，这个东西定义了通用的鉴权模型，参考这篇blog。 几个概念： Authentication，一般指登陆，验证用户名和密码； Authorization，授权，验证权限； Subject，被管理的主体，一般指的是用户； SecurityManager，实际鉴权者，Subject被绑定到SecurityManager； Realm，领域，类似于DAO，最终落地的鉴权者。Realm是Plugable的，开发者主要负责实现这一块； Authenticator，认证器。包含一些常见的、默认的鉴权实现（如密码、SSO等）； Authrizer，授权器。包含一些常见的权限、角色设计（一个用户多个角色，权限是以:分割的字符串）； SessionManager，可配置的Session管理器，可以通过简单的配置放在Redis中； CacheManager，系统缓存管理器，也可以简单的配置到Redis中； Principal，身份，一般是用户名、邮箱； Credential，凭证，一般是密码； 使用流程如下： 定义配置文件，本项目中与spring结合，为spring-context-shiro.xml； 大部分都是标准配置，注释掉的部分可以用redis作为sessionManager和CacheManager。在SecurityManager里面配置了realm，即为自己实现的SystemAuthorizingRealm； 该类继承自AuthorizingRealm。doGetAuthenticationInfo是登陆验证，验证账号密码；doGetAuthorizationInfo是权限验证，这里也是用了自带的SimpleAuthorizationInfo； 权限这里，根据用户角色，获取其前端菜单列表，每个菜单元素对应着一个权限字符串（如sys:role:view对应查看角色列表，sys:role:create对应创建新角色等）； 由于用户角色、权限等信息需要在所有页面使用，所以这里注册了一个单例SystemService，来随时获取这些信息； 在需要验证权限的地方，调用hasRole或者isPermitted等函数来验证权利（或者使用注解）.JSP里面也有相关的语法。 数据字典这里采用了一个设计，所有常量被存放在数据库中，而不是在代码中使用枚举。sys_dict表中根据type存放了所有枚举值，所以枚举的value类型被统一为String。 问题 分页。这里分页有明显的性能问题，直接查找了所有数据，然后在内存中分页（以及排序），在数据集非常大的时候这是不可取的。应该在BaseEntity里面存入limit, offset和orderBy，然后在sql里面根据这些参数来写sql； id. ID应该用自增主键，主要是出于性能考虑。MySQL的uuid主键性能很差，这是由innoDB底层实现决定的。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"web","slug":"web","permalink":"http://yiuterran.github.io/tags/web/"},{"name":"jeesite","slug":"jeesite","permalink":"http://yiuterran.github.io/tags/jeesite/"}]},{"title":"hello-world","date":"2017-06-12T16:43:56.000Z","path":"2017/06/13/hello-world/","text":"最后再折腾一次，把所有的blog迁移到GitHub Pages，以后再也不折腾了ORZ","tags":[]},{"title":"java web基础学习","date":"2017-06-12T15:50:02.000Z","path":"2017/06/12/java web基础学习/","text":"做java项目有两个月了，一直忙着修复业务上的东西，java的web基础这块没怎么看。最近在coding时涉及底层较多，必须抽时间看看底层的一些东西了。 Servlet结构概览java的web底层主要是指servlet和filter，前者替代了普通的CGI（for C/C++，perl），相当于python中的wsgi。这一块主要的类： 这是servlet相关的类，这是一个请求——应答模型，不涉及具体协议。和http相关的主要是下面这些：和Servlet关系很大的是web.xml文件，所有的servlet必须在web.xml中声明、配置初始化参数，做url映射。url映射采用最大前缀匹配，如果两个完全一样，用靠前声明的那个匹配。类似django中的settings.py. ServletFilter是Servlet的一种extension，用于在Servlet被调用之前检查Request对象，并修改Request Header和Request内容；以及在Servlet被调用之后检查Response对象，修改Response Header和Response的内容（一种中间件）。Filter也需要配置url mapping，其调用顺序是其在web.xml中声明的顺序，习惯上filter被声明在所有servlet之前。 Servlet异常处理，可以配置&lt;error-page&gt;将status-code导向不同的html页面，或者干脆导向一个自定义类，然后在该错误处理类中使用Integer status_code=(Integer)req.getAttribute(&quot;javax.servlet.error.status_code&quot;);得到错误码，然后根据错误码做处理；而java程序中的异常可以通过try…catch捕获，然后forword一个专门的处理类中。 session id应该只对当前servlet有效，虽然确实有方法使其跨servlet共享，但是不推荐使用。 代码书写首先实现一个servlet（继承HttpServlet），实现init和service方法，在后者中实现web服务的逻辑处理。然后在web.xml中注册该servlet的类，将之与url相关联。 处理流程外层web服务器（Tomcat等）在收到http请求后，根据url路径找到对应的servlet，实例化（如果不存在）。 实例化的servlet对象处理请求，并返回响应（或者转发给其他servlet）. 请求全部处理完毕后，Tomcat会根据需求销毁servlet（正常运行的服务不会销毁）。Java是多线程模型，并发的请求会使用新的线程来处理。 JSP类似其他语言中的模板，不过模板一般是获得结果，然后进行渲染。JSP本质是一种特殊的Servlet，所以在接收到请求后，JSP文件会被编译为Java的字节码。 语法： &lt;%...%&gt;：Java代码片段，用于定义0~N条Java语句，方法中能够写什么，这里面就能放什么； &lt;%= %&gt;：Java 表达式，用于输出一条表达式或变量的结果。response.getWriter().print() 方法中能够写什么，这里面就能够写什么； &lt;%! … %&gt; ：声明，用来创建类的成员变量和成员方法，Java类中能够写什么，这里面就能够写什么，要注意的是，里面的内容不在_jspService() 方法之内，直接被JSP转化后的类体包含。 在&lt;% %&gt; 和 &lt;%= %&gt; 脚本中定义的Java 代码都会放在JSP 的 _jspService() 方法中（实际上就是Servlet中的service 方法），而&lt;%! %&gt; 脚本中定义的却会放到生成类的成员位置的。 Spring3spring存在的意义是因为Java不够灵活。 Spring通过xml来增强Java的灵活性，减少因配置更改导致的重新编译需求； Spring支持面向切面编程（也就是Python中的装饰器），方便进行拦截； 同样，通过AOP，可以管理数据库连接，以及事务回滚等等； 此外，Spring还提供了一系列工具包，如果JDBC连接；SpringMVC的web框架； 良好的可扩展性，可以方便的与其他JavaEE框架结合使用； 简单来说，Spring通过XML定义了一套新的语言，该语言能被无缝整合到Java程序中。 IoC所谓的依赖反转。 按着HTTP的请求应答模型，正常情况下，Tomcat等web服务器就请求直接塞给servlet，获得应答返回给客户端。但是Spring为了增强灵活性，在这里加了一层，也即是所谓的“容器”。 这个容器（BeanFactory）本质上就是对象的托管工厂，根据请求容器创建对象（Bean），并进行一系列的注入等操作，并进行对象的生命周期管理。对于web而言显然Servlet被包含在这些Bean中。 初始化的流程是可配置化的，默认在一系列xml配置文件中。 一般流程Spring是按着接口进行类的管理的，一般情况下，需要有一个接口类（假设叫HelloApi）。 一个实现了个该接口的普通类（假设就叫HelloImpl）。 在spring对应的xml中配置bean，大致如下： 1&lt;bean id=&quot;hello&quot; class=&quot;cn.javass.spring.chapter2.helloworld.HelloImpl&quot;&gt;&lt;/bean&gt; id是组件的名字，最后： 12345678910111213import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class HelloTest &#123; @Test public void testHelloWorld() &#123; //1、读取配置文件实例化一个IoC容器 ApplicationContext context = new ClassPathXmlApplicationContext(&quot;helloworld.xml&quot;); //2、从容器中获取Bean，注意此处完全“面向接口编程，而不是面向实现” HelloApi helloApi = context.getBean(&quot;hello&quot;, HelloApi.class); //3、执行业务逻辑 helloApi.sayHello(); &#125;&#125; 使用容器读取xml配置文件，然后通过名字查找Bean，利用反射创建对应的实例（生成的是接口的实例）。 上文中的ApplicationContext是BeanFactory的子类，Spring针对不同的场景内置了大量不同的Bean工厂，以适应不同的场景。 如果构造器有参数，可以在xml的bean的结点中放入constructor结点，进行参数注入。 除了普通类以外，Bean还可以作用于静态/普通工厂类。只是xml中的配置文件项略有不同而已。 在初始化（生成对象）后，还可以通过property结点注入属性（setter）. 如果想要使用Bean技术，必须遵从其命名规范，不然找不到对应的方法/对象。如下： 该类必须是一个普通Java类（POJO），不受Java规范外其他规范约束； 该类必须要有公共的无参构造器，如public HelloImpl4() {}； 属性为private访问级别，不建议public，如private String message; 属性必要时通过一组setter（修改器）和getter（访问器）方法来访问； setter方法，以“set” 开头，后跟首字母大写的属性名，如setMesssage,简单属性一般只有一个方法参数，方法返回值通常为void; getter方法，一般属性以“get”开头，对于boolean类型一般以“is”开头，后跟首字母大写的属性名，如getMesssage，isOk； 还有一些其他特殊情况，比如属性有连续两个大写字母开头，如“URL”,则setter/getter方法为：setURL和getURL，其他一些特殊情况请参看“Java Bean”命名规范。 得益于xml的强大，可以注入的数据类型，除了基本类型外， 还有list、set和map等集合类，甚至可以引用其他Bean. bean xml语法 首先使用&lt;bean&gt;构建一个bean，指定id（全局唯一）和class。如果该bean对应的类需要使用静态工厂方法，使用factory-method=&quot;xxxx&quot;属性；如果需要实例工厂方法，则必须在前面先声明工厂类的bean，然后在这里指定factory-bean；bean的scope分为两类：prototype和singleton。显然单例的bean全局只有一个，原型的则每次产生新的。 使用&lt;constructor-arg&gt;调用构造器进行初始化，可以使用index属性指定构造器参数次序，或者直接用type按参数类型进行匹配（就像正常调用重载方法时那样），或者用name指定参数的名字。使用value注入需要的值。 使用&lt;property&gt;调用对应的setter来注入各种属性。如果注入的是常量，直接用value赋值就行；如果注入的是其他bean的名字，使用idref bean=&#39;xxx&#39;；如果注入的是其他bean对应类的实例，需要使用ref bean=&#39;xxx&#39;;还可以注入list,set, array和map，甚至prop(java.util.Properties) ；如果想要注入null，必须使用&lt;null/&gt;标签，直接写当然是字符串。 使用lazy-init可以对bean进行延迟初始化； 使用depends-on指定依赖的bean来影响初始化/销毁的顺序； 自动装配：为了减少配置文件的长度，spring支持自动装配。简单来说可以根据参数的名称自动找到对应bean的名称； 此外，spring还支持method注入。这个主要是为了解决单例bean调用原型bean导致的一系列问题； Resource接口spring为外部资源抽象了一系列的接口 Spring表达式为Java语言提供了eval功能，类型动态语言的功能在bean中可以使用SpEL，格式为#&#123;&#125;，表达式放在大括号中可以在Java语言中使用@Value(#&#123;&#125;)注释进行注入 AOPSpring是面向接口编程的，这是装饰器模式的基础。 所谓装饰器模式，指的是对于一个HelloApi接口，定义一个装饰器也实现HelloApi接口，其构造器也是需要一个HelloApi对象。这样，我们将需要装饰的对象传入装饰器对象，通过调用装饰器的接口方法来实现装饰。 Spring通过注解/xml的方式完成装饰器的注入，就是所谓的AOP. 使用流程： 写一个切面类； 定义连接点（具体什么场景下在哪里被调用），切入点表达式形如execution(* com.spring.service.*.*(..))，匹配语法：*表示一级上的任意字符，..表示任意级的任意字符，+指定类型的子类型；这里的语法很复杂，可以参见这里； 定义通知的回调方法 通知顺序：前置通知→环绕通知连接点之前→连接点执行→环绕通知连接点之后→返回通知→后通知；如果发生异常：异常通知→后通知 JDBC支持Spring扩展了原生的jdbc支持，但是一般情况下我们在生产环境会和ORM结合使用 简化配置一般使用注释来简化配置文件，常见注释包括： Required：必须注入的属性，修饰setter； Autowired： 自动装配，可以后面跟上(required=true)，自动装配有点坑爹，谨慎使用 Spring MVCSpring MVC是一套常见的MVC web框架，主要涉及了几个层次…… Apache Shiro一个权限认证系统 SiteMeth一个服务端渲染的页面装饰框架","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"web","slug":"web","permalink":"http://yiuterran.github.io/tags/web/"}]},{"title":"lua5.1要点笔记","date":"2017-06-12T15:49:06.000Z","path":"2017/06/12/lua5.1要点笔记/","text":"安装sudo apt-get install lua5.1 lua的各个版本之间不兼容问题很严重，5.1-5.2-5.3之间都有一些不兼容的问题，5.1是最经典的版本，适用范围广泛。luajit与lua的关系相当于pypy与cpython的关系，luajit采用lua5.1语法，作者已经另起炉灶了，永远不和lua5.2兼容。Heka的lua扩展也是使用5.1版本的lua。 lua是一门嵌入式语言，也就是程序的入口点必定在别处，这是和python等脚本语言的最大区别。lua的性能很好，虽然比不上v8的js。 语法 作为一门动态语言，可以从lua身上看出许多动态语言的影子。lua与js，python都有一定的相似性，可以说是综合了二者之所长。但是有个坑，就是unicode问题，lua5.3解决了这个问题。不过对于heka，一般情况下我们不太需要处理utf8，毕竟日志数据track一般都是编号和数据。 与python不同而与js类似，lua是动态类型语言。字符串会在适当时候自动转成数字， 当然也可以使用string.format自己进行转换； 所有的变量默认是全局的（与js一致），需要使用local修饰符来创建局部变量；全局变量被存放在一个table中，被称为环境，可以通过getfenv和setfenv来对环境进行操作； 只有一种数据结构：table. 赋值语句比较奇怪:123a = &#123;x=3, [2]=2&#125;a[1] == 2a[&quot;x&quot;] == 3 注意table里面值不能是nil，否则会有各种奇怪的问题，比如#返回的是nil值之前的长度；所以可以用a[x] == nil或者if a[x]来判断exists；将a[x]=nil则相当于删除了x元素。但是不能这样删除数组里面的元素，因为会导致#操作符的结果错误，需要使用table.remove(x); 连接操作符：..; 取长度操作符（相当于len)#，但是#返回的是字节数，所以更像是sizeof 函数与js中的很像，支持闭包。：可以用来定义方法，本质上是一种语法糖； metatable类似与python的内置方法，各种重载操作符。 lua支持coroutine. 库 由于lua中table不支持nil，这与json中的null产生了矛盾，需要使用cjson.null来表示","tags":[{"name":"heka","slug":"heka","permalink":"http://yiuterran.github.io/tags/heka/"},{"name":"lua","slug":"lua","permalink":"http://yiuterran.github.io/tags/lua/"}]},{"title":"Go语言学习","date":"2017-06-12T15:48:42.000Z","path":"2017/06/12/Go语言学习/","text":"update(2019/03/31): 移除了一些过时信息。 准备工作 安装 GoLang，直接用官网的安装指南就行； 设置环境变量GOPATH，这个是用默认包的存放位置，用go get安装的包会存放在这个位置。在~/.zshrc或~/.bashrc里面加入export GOPATH=~/.go，然后在PATH里面加入GOPATH/bin即可；go1.10之后，已经不用手动设置GOPATH； 如果是项目的依赖，最好不要放入全局系统。使用1.11后加入的go mod； 设置代理。go get命令下载必定被墙，使用git config --global http.proxy &quot;xxxx:oooo&quot;设置代理方可使用，也可以使用http_proxy=xxxx:oooo go get这个格式，或者在 bashrc 里面加个alias；在项目里的go.mod中使用replace也可以； IDE：推荐vscode+go，或者 gogland，后者付费； 官方教程，建议下载到本地运行，速度更快； 交互式命令行：gore(go get -u github.com/motemen/gore)； 可以使用https://play.golang.org/跑一些短小的程序测试； 基础部分基本语法关键字 打头的package xxx，类似 java，import可以用括号打包； 类型在变量名后，这种奇特的声明方式虽然有篇 blog 来解释，但总而言之是扯淡的； 连续多个变量同类型可省略前面的只保留最后一个； 类似 python 的多值返回（但是 python 本质是一个 tuple)，如果给返回值命名了，就不必在函数体中声明这些变量； var name int是典型的声明变量格式，自动推导类型的语法是name := 0（但是这个语法只能在函数体里面用，外面必须用var声明）。可以在一行给多个变量赋值（类似 python 的解包）； 基本类型，和 c++类似，包括bool, int, uint, byte(uint8),rune(int32), float32, float64, uintptr, complex64, complex128, string，注意么有double，类似其他 GC 语言，所有类型会被自动化初始化； Go 没有隐式类型转换，所有类型之间必须显式转换。注意int和string之间不能互转，可以用strconv中的Itoa和Atoi来完成（非常烦躁的设定）； 常量使用const关键字声明，常量只能是基础类型，且不能用:=声明。常量的实际类型由上下文决定，数值常量本身是高精度的； 和 C 语言一样，单引号表示字符(byte)，双引号表示字符串。string可以转换成一个rune数组，或者byte数组，取决于你对字符串的解释（字节流还是文本）。 语句 循环只有for语句，且不需要括号（其他语句也都不需要），基本格式还是类似 c 的for i := 0; i &lt; 10; ++i，这种，后面必须跟大括号，且大括号必须和for在同一行… 如果省略前后前后的分号，for就成了while；如果全部省略，裸的for代表死循环； if 类似，不要括号，花括号必须；而且 if 也可以在分号前声明一个变量，作用域仅限于花括号以及后面跟着的else里面； switch语句，好吧，和上面也类似。有个有趣的地方是，默认自动终止，除非使用fallthrough，和 C 中的默认自动向下，除非手动break相反；switch也可以直接用空语句，条件比较复杂时使用可以让代码看起来更加整洁； defer语句，这是 Go 的特色语句了。defer是在函数返回后再执行，其本质是压栈，所以弹出顺序与defer的顺序相反； 指针 虽然 Go 是一门 GC 语言，但是仍然拥有指针。*T表示指向类型T的指针，取地址仍然使用&amp;。不过与 C 不一样的是，不允许指针运算； 和 C 一样，拥有struct，而且蛋疼的是，也只能拥有字段（和 C 一样，POD）。结构体通过指针访问字段也是使用.符号（没有了-&gt;符号）； 使用&#123;&#125;进行结构体初始化，如 12345678910type Point struct &#123; X, Y float32&#125;var ( a = Point&#123;X: 10&#125; b = Point&#123;1, 1&#125; c = Point&#123;&#125; p = &amp;Point&#123;1, 2&#125;)fmt.Println(p.X) 虽然感觉有点奇怪，不过和 C++11 后的初始化列表其实挺像的。 数组 声明方式： var a [10]int，这语法也是醉了。和 C 一样，数组不能动态扩张； 使用slice代替数组，声明方式： a = make([]int, 0, 5)，第二个参数表示长度(len)，第三个参数表示容量(cap)。类似 python 中的list，可以切片；注意，如果仅仅声明var []a那么a==nil是成立的； make关键字只能用来生成系统内置的一些对象，如 slice, map, chan；由于go不支持泛型，只有内置的这几个结构可以用泛型（很奇葩）。 go 的切片有一些匪夷所思的问题，因为切片得到的并不是新的对象，而是原来对象的指针； 可以通过append往 slice 中添加元素，类似 C++中的vector可以自动扩展长度。注意append会返回slice的指针，这个值和原来的不一定一致； range关键字（注意这货不是函数。。）用来对slice进行循环，格式是for i, v := range a; 字典 map现在也是新兴语言的标配了，map和slice一样，必须通过make创建，语法是m := make(map[string]int),[]中的是键的类型，后面跟着的是值的类型。初始化语法神马的和 struct 类似； 删除元素使用delete关键字；检测存在使用双赋值：a, ok = m[&#39;test&#39;]，如果存在则 ok 为true，否则为false； 函数 函数被提到第一公民的位置，和 javascript 里面的语法很像，当然，除了强类型声明很麻烦以外； 函数的闭包与 js 类似，内嵌函数引用的是各自的闭包（其实有点像 C 中的static局部变量）； 方法 虽然 Go 里面没有类，但是可以声明 struct 关联的方法，虽然语法非常别扭…例如（接着上面的Point） 123func (p1 *Point) distance(p2 *Point) int&#123; //...&#125; 方法接受者位置在func关键字和函数名之间，呃，其实和 C++的外置方法声明还是有点像的… 值得注意的是，不仅仅是 struct，可以通过这种声明向本包内任意非内置类型注入方法，甚至可以通过type声明别称后向别称的内置类型进行注入； 方法接受者可以是指针，也可以不是，当然只有指针才能改变元素的实际值； 结构体 struct从语法上来讲和 C 基本是一样的； 可以在字段后面添加字符串，表示tag，在反射的时候用； 可以在结构体内塞入另一个结构体（或其指针），组合优先于继承； 接口 虽然没有类，但是由接口。关键字interface声明一种接口： 123type Flyable interface&#123; Fly();&#125; 上面Flyable声明了一个接口，拥有Fly方法. 这样后面假设我给pig加上fly方法，那么变量var item Flyable就可以被赋值为item = &amp;pig&#123;&#125;这里值得注意的是，这里的接口实现本质是隐式的（非侵入式的），或者可以说是duckable的，pythoner 对此应该深有理解：） Stringers是一个常见的接口，类似 python 中的__str__或者 java 中的toString，它只需要实现String方法； Go 里面没有异常，仍然使用错误。error是一个接口，只有一个方法Error() string，通常函数会返回一个error，放在第二个位置，如果其不为nil则说明出了错误； 其他常见接口包括io.Reader，表示从数据流结尾读取；http.Handler表示处理 HTTP 请求的服务器；image.Image表明一个图像的接口； 接口可以通过接口来组合 并发 goroutine是 Go 运行时的轻量级线程（协程），在方法名前加go就在另一个线程中同步执行了； channel是有类型的管道，可以使用&lt;-操作符对其发送或接受值，使用make(chan int， 100)创建一个int的channel，第二个参数表示缓冲区长度，也可以不带，表示完全无缓冲； &lt;-chan和chan&lt;-分别表示只读和只写的 chan，后面跟着管道中的数据类型，如a &lt;-chan *int表示只读的整数指针通道； close一个channel表示不再发送数据（只有发送者可以关闭），向已经close的channel发送数据会引起panic。使用range则表示从channel中源源不断的接受数据直到被关闭； select语句使得一个 goroutine 在多个通讯操作上等待，阻塞直到某个分支可行，例如： 123456789// var a, b chan intselect&#123; case x &lt;- a: //... case &lt;- b: //... default: //...&#125; 当所有分支都不可行时，执行default语句； sync.Mutex提供了互斥锁，包括Lock和Unlock两个方法，可以使用defer语句保证锁一定会被释放； Go 与 Erlang 的并发模型分别是 CPS 和 Actor，但是 Go 的 channel 里面可以传递指针，这和 Erlang 的变量不可更改有着根本性质的区别。 至此，基础部分结束。 进阶部分环境搭建 前面导出了GOPATH环境变量，这个路径就是实际的工作空间。从结论来看，Go 提倡将所有 Go 语言项目放入同一个工作路径，这是很不好的； 如果使用过go get命令，那么GOPATH下会自动创建bin, pkg和src三个文件夹，源码存放在src之下，import本地包时，就是从这一层开始的。go get无法控制依赖的版本（垃圾）； go install会生成输出文件（可执行或者库），go build则仅编译； 使用技巧 Go 自带了一个工具go fmt用来对代码进行格式化； 注释的格式和 C++一致。使用godoc生成文档，类似 python 的 docstring，但是约定更加简单：对类型、变量、常量、函数或者包的注释，在其定义前编写普通的注释即可，不要插入空行。Godoc 将会把这些注释识别为对其后的内容的文档。 与顶级定义不相邻的注释，会被 godoc 的输出忽略，但有一个意外。以“BUG(who)”开头的顶级注释会被识别为已知的 bug，会被包含在包文档的“Bugs”部分。 getter没有必要用Get开头，直接大写首字母就行，setter还可以留着Set； Go 习惯使用驼峰式写法，而不是下划线； Go 其实是需要分号的，但是分号是自动插入的。这造成了一些非常奇怪的约定。例如左大括号必须放在一行末尾… new用来分配内存，并且填 0，返回指向对象的指针，程序可以利用这些指针进行手动初始化；make则只能用来创建内置类型(slice, map 和 channel)，返回的是对象本身，而不是指针； array是一种对象，和它的大小相关；array 名并不是指针（和 C 不同）； print语系和 C 中基本一致, %v可以拿到值，%T可以拿到类型； interface &#123;&#125;相当于 C 中的void *可以被转化为任意类型，一种常见的反射方式是使用v.(type)，这被称作type assertion. 比如str, ok = v.(string)，返回的就是 string 类型；另外可以在switch语句里面用x.(type)，然后再case里面判断类型； import后必须使用，否则会报错（傻逼设定。。），可以用import _ &quot;fmt&quot;的方法导入但不使用，或者用_赋值；另外就是可以直接导入包内全部方法，使用import * &quot;fmt&quot;； 可以通过往struct里面塞匿名字段（另一个 struct，或其指针）来达到继承的目的，虽然看起来很奇怪就是了。注意的是，这本质上只是一种语法糖。外围的同名元素会覆盖继承（内嵌）的；同样，也可以往interface里面塞一个别的interface达到继承接口的目的； panic和recover是最后手段； 反射 使用reflect包来进行反射； golang 里面每个值都有Type和Value，这是因为所有值都是interface&#123;&#125;的实现者，而后者实际上是一个空类型，所以需要Type和Value用于反射。这也就对应着reflect.Type和reflect.Value，也对应着%T和%v，也对应着reflect.TypeOf()和reflect.ValueOf； reflect.Type和reflect.Value并不是并列的（并不能顾名思义）；而是一种包含关系，reflect.Value是一个&lt;Type, Value&gt;的二元组，reflect.ValueOf(x).Type与reflect.TypeOf(x)是一致的，返回的是静态类型；reflect.ValueOf(x).Kind可以返回一个常量定义的类型（如reflect.Float64)，这是一个底层类型。 可以从reflect.ValueOf(x).Interface()还原接口值，后续跟随类型断言等；输出reflect.Value的正确方法是将其先转为interface&#123;&#125;； reflect.ValueOf(x).SetXXX的前提是 x 是可修改的(CanSet)，借助指针来修改的方法是： 1234var x float64 = 1.1p := reflect.ValueOf(&amp;x)v := p.Elem()v.CanSet() == true 陷阱 在循环中创建goroutine需要注意变量的传递。如: 12345for i:=0; i&lt;10; i++&#123; go func()&#123; fmt.Println(i) &#125;();&#125; 这里实际上可能输出了10个9，这是由于go创建的协程不会马上运行，当启动的时候i已经迭代到9了。正确的做法是不要直接使用闭包外的变量，而要进行传值。即： 12345for i:=0; i&lt;10; i++&#123; go func(x)&#123; fmt.Println(x) &#125;;&#125;(i) nil与interface 如果一个函数如下: 123456789101112131415161718192021222324type IAdder interface&#123; func Add(x int)int&#125;type Ex struct&#123; X int&#125;func (e Ex) Add (x int)int &#123; return e.X + x&#125;func test(x int)Ex&#123; var y Ex if x &gt; 10&#123; y = nil &#125;else&#123; y = &amp;Ex&#123;x&#125; &#125; return y&#125;func main()&#123; var IAdder ia ia = test(100) fmt.Printf(ia == nil) //这里输出是false&#125; 这里的原因是interface本质上是一个值，他有两个部分Type和Value，只有两者都是nil的时候，这个值才是nil。所以interface不能直接与nil做比较。一个方法是直接在test中返回IAdder，还有个方法是先拿到值，判断nil后再复制给接口。或者，在test中加入error返回值，通过那个做判断也行。每当拿interface和nil值作比较的时候，心里都要警惕。 深浅拷贝 这个其实是和C语言中一样的，如果我们令A := B，B是一个指针，那么A只是做了浅拷贝，但是如果B是一个struct，那么A就做了深拷贝（但是B中的指针仍然还是指针）。 另外需要注意的是，go中内置的slice, map和chan本质上都是指针。","tags":[{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"}]},{"title":"Heka插件开发","date":"2017-06-12T15:48:37.000Z","path":"2017/06/12/Heka插件开发/","text":"学习Go主要是为了开发heka的插件，heka和logstash不一样，插件多半还是靠自己开发。而logstash大部分情况下只需要使用自带的插件，简单的自定义处理只需用自带的ruby插件，复杂的才需要自己写插件来处理。 概述Heka是一个基于插件的日志处理系统，其基本结构如下（图片来自网络）： 显然这是一个流式处理系统，从输入流到输出流之间经过一系列的处理。其流程被抽象成几个类似与logstash的步骤，包括分割；解码；过滤；编码；输出。 编译步骤 使用go get github.com/mozilla-services/heka(自备梯子)下载heka项目； 到$GOPATH/github.com/mozilla-services/heka下，先用git checkout v0.10.0切换到最新的0.10.0稳定版，然后再source build.sh进行编译，系统依赖参见官方文档。编译过程中会去线上下载一些go的依赖，所以仍然注意要备好梯子… 第一次编译时间较长，尤其是网速不给力的时候，你可以去喝杯咖啡…编译完成后可以使用ctest来测试一下。令人尴尬的是使用go1.5测试失败…貌似有些bug； 官方给出了一个插件的example，就在heka/examples文件夹下。使用方法：在heka/下新建externals/host_filter文件夹，然后将examples/host_filter.go复制到该文件夹下，最后在heka/cmake/plugin_loader.cmake中添加add_external_plugin(git http://xxx/host_filter :local)，最后重新编译项目，就会得到包含插件host_filter的二进制文件hekad； 使用Go1.5编译v0.10.0自带的example host_filter.go会提示enough arguments in call to pack.Recycle。\u0001查看提示的79行代码，发现pack.Recycle()少了个参数，传入nil重新编译即可。重新编译前在build文件夹中运行make clean-heka进行一次清理。 项目应用手头的项目需求如下： 输出json形式的按行分割的log； json中有type字段，根据type的不同生成不同的map，但最后被送到同一个output插件中； output到mongo中，每个数据需要存在两个表中，分别是按日统计的累加表和总的累加表，以便统计按日数据和总体趋势数据； 根据上述描述，应该使用LogstreamerInput引入输入，spliter使用默认的token_spliter按行进行分割即可，decoder使用json decoder，参考配置： 12345678910111213[LogstreamerInput]log_directory = &quot;/var/log/lucky&quot;file_match = &#x27;track\\.json&#x27;decoder = &quot;JsonDecoder&quot;[JsonDecoder]type = &quot;SandboxDecoder&quot;filename = &quot;lua_decoders/json.lua&quot; [JsonDecoder.config] Type = &quot;type&quot; payload_keep = true Timestamp = &quot;@timestamp&quot; timestamp_format = &quot;%Y-%m-%dT%H:%M:%S.%f&quot; 我现在需要编写一个自定义的filter和一个output插件。filter的格式可以参考host_filter里面的例子， output则可以参考plugin里面的elasticserach.go。 实际在编写过程中发现，如果log的格式是json，使用go做解析非常费劲。Json比较适合动态语言，对于静态的Go，只能通过map[string]interface&#123;&#125;这种做映射和强制转换。而Message.Fields是一个*[]Field，这意味着Json被映射成了一个数组，由于这里是业务日志分析，有很多数据结构不同的日志输出，如果使用默认的这种数组遍历的filter方式，写起来非常麻烦。所以我把payload仍然保留，然后使用encoding/json将payload解析成一个map[string]interface&#123;&#125;，这样虽然仍然很麻烦，但是工作量已经减轻不少。 mongo和redis在go中已经有成熟的库，直接引用即可。个人的工作量就是自定义解析过程，其实不难，就是动态语言写久了再写静态语言感觉有点繁琐。官方有插件开发指导，仔细阅读一遍，然后再参考里面已有的plugin，就可以动手写了。注意现在（刚发布）example的host_filter和0.10.0有些标准不和，可能随后才会更新。 lua开发使用lua解析json显然更加得心应手。最后我自己写了一个decoder，将数据解析为 12345&#123; &quot;UserId&quot;: 1, &quot;Set&quot;: &#123;&#125;, &quot;Inc&quot;: &#123;&#125;&#125; 这样，在Go文件中仅仅需要把对应的数据直接更新到mongo中，而无需一层层的分析数据。大大减轻了工作量。","tags":[{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"},{"name":"heka","slug":"heka","permalink":"http://yiuterran.github.io/tags/heka/"}]},{"title":"java CMS GC调优步骤","date":"2017-06-12T15:48:32.000Z","path":"2017/06/12/jvm调优指南/","text":"0.增加GC相关选项： 12345678910-verbose:gc-XX:+UseGCLogFileRotation-XX:NumberOfGCLogFiles&#x3D;5-XX:GCLogFileSize&#x3D;512K-XX:+PrintGCDetails-XX:+PrintGCTimeStamps-XX:+PrintGCDateStamps-XX:+PrintTenuringDistribution-XX:+PrintGCApplicationStoppedTime-Xloggc:&#x2F;var&#x2F;app&#x2F;log&#x2F;Push-server&#x2F;gc.log 如果不能确定所需内存，使用自动jvm自动调优； 大致确定所需内存后，使用-Xmx -Xms设置堆大小； 观察GC log确定FullGC后剩余堆大小（即为活跃数据大小）； 整个堆大小宜为老年代活跃数据大小的3-4倍； 永久带大小应该比永久带活跃数据大1.2~1.5倍； 新生代空间应该为老年代空间活跃数据的1~1.5倍； 通过top命令观察栈占用空间、直接内存占用空间，决定所需机器内存大小； 新生代大小决定了Minor GC的周期和时长，缩短新生代大小可以减少停顿时长，但是增加了GC频率；在调整新生代大小时，尽量保持老年代大小不变； 老年代大小不应该小于活跃数据的1.5倍；新生代空间至少为java堆大小的10%；增加堆大小时，注意不要超过可用物理内存数； 从throughput收集器迁移到CMS时，需要将老年代空间增加20%~30%； 新生代分为Eden和Survivor两部分，Survivor可以通过-XX:SurvivorRatio=xx来控制，对应的大小为-Xmn&lt;value&gt;/(ratio+2)； 通过-XX:MaxTenuringThreshold=&lt;n&gt;来指定晋升阈值（年龄），n为0~15之间； 期望Survivor空间为剩余总存活对象大小的2倍(age=1； 注意调节Survivor大小时，保持Eden大小不变； 如果Survivor空间足够大，且对象大部分并未到达老年代，那么就可以将晋升年纪指定的足够大（15）。在Eden与Survivor之间复制和CMS老年代空间压缩之间，我们宁愿选择前者； CMS必须能以对象从新生代提升到老年代的同等速度对老年代中的对象进行收集，否则，就会失速； 如果观察到’concurrent mode failures’，意味着失速已经发生，必须减少-XX:CMSInitiatingOccupancyFraction=&lt;percent&gt;的值； 使用上述选项的同时，最好同时使用-XX:+UseCMSInitiatingOccupancyOnly，强制使用该比例,该比例的大小应该大于老年代占用空间和活跃数据大小之比，一般而言老年代大小*该比例&gt;1.5*老年代活跃数据大小； 使用-XX:+ExplicitGCInvokesConcurrentAndUnloadsCloasses可以使用CMS进行显式垃圾回收（System.gc())；通过-XX:+DisableExplicitGC关闭显示垃圾回收（慎用）； 使用-XX:+CMSClassUnloadingEnabled打开永久带垃圾回收，使用-XX:+CMSPermGenSweepingEnabled打开CMS对永久带的扫描；使用-XX:CMSInitiatingPermOccupancyFraction=&lt;perscent&gt;激活回收比例阈值； 使用-XX:ParallelGCThreads=&lt;n&gt;控制扫描线程数；使用-XX:+CMSScavengeBeforeRemark强制重新标记前进行一次MinorGC；如果由大量的引用对象或可终结对象要处理，使用-XX:+ParallelRefProcEnabled； CMS包括Minor GC所带来的开销应该小于10%； 如果缺少长时间调优的条件，安全起见，可以使用G1，1.8以后G1已经稳定，仅设置如下参数即可：12345678-d64-Xmx5g-Xms5g-XX:PermSize&#x3D;100m-XX:MaxPermSize&#x3D;100m-XX:MaxDirectMemorySize&#x3D;1g-XX:+UseG1GC-XX:MaxGCPauseMillis&#x3D;80 G1不必明确设置新生代大小，其自动调优也十分可靠，对于停顿时间往往在长时间运行后可以达到预期效果；对吞吐量优先的应用，可能不是那么明显。 实际上除了Java以外，其他语言很少考虑虚拟机优化问题，这也不应该是普通程序员需要关心的问题，只能说明Java本身不够成熟。从Java9开始，大部分程序员已经无需关心JVM优化的问题。如果面试遇到了，基本属于面试官自己造火箭的原因。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"gc","slug":"gc","permalink":"http://yiuterran.github.io/tags/gc/"},{"name":"jvm","slug":"jvm","permalink":"http://yiuterran.github.io/tags/jvm/"}]},{"title":"web前端开发进阶","date":"2017-06-12T15:48:23.000Z","path":"2017/06/12/web开发进阶/","text":"目前的项目还是用backbone写控制台，说实话，快写吐了…前段时间看了一下ES6，ES7的变化，发现javascript正在变得越来越好，加上V8的给力性能，在web开发这块，js取代python指日可待。当然python丰富的第三方库决定了它在运维/科学计算/爬虫等方面的可靠性，仍然是值得推荐的第一入门语言（当然，学院派最好从lisp入手）。 要我说，现在创业公司就应该从js全栈起步，后台前端都用js，小活用meteor这种神器快速搭建，确定方向后再前后端分离认真设计。后端用react，再到naive，桌面段由node-webkit，大全栈一统天下。性能跟不上的模块再重构就可以直接用go/C++之类的，或者用jvm系的东西。时至今日，java的速度已经不慢（至少比一堆脚本语言快），组件多，好招人，适合迅速起步。 10个人的创业团队，5个js全栈（back/front/react-naive/node-webkit），3个jvm系(android/spark/storm等)，1个object-C系（apple），1个python系（运维），感觉就够了。js必将一统天下，这也是大势所趋。虽然说没有银弹，但是有一门能解决大部分场景问题的语言，还是非常了不起的。 我之前一直讨厌用js的原因无非是因为这门语言实在太糟蹋了，到了ES6，js越来越python，也可以愉悦的使用了。 推荐使用nesh作为交互程序进行测试，或者使用nodejs kernel for ipython 学习步骤：ES6-&gt;React/vue-&gt;redux/vuex-&gt;meteor，目的是熟练使用meteor搭建一些小网站满足需求。然后是react native -&gt; app开发，目的是了解一下客户端技术。 ES6要点 参考 阮一峰的书，测试推荐使用nesh -b 使用let声明变量，而不是var，主要引入原因是var有性能问题，且作用域自动提升；使用let声明的变量，其表现行为与其他语言中的变量一致（如c++）； 使用const声明常量； 使用...进行解构。这个是FP中常用的语法，python中也有(*和**)；不同的是，js的解构允许默认值，如果解构失败，变量就是undefined，如果有默认值，这里就会使用默认值；默认值是惰性求值的； 12var [a, b=3] = [1, 2]var [head, ...tail] = [1, 2, 3, 4] //这个解构只能放在最后，不如haskell中那么高级 对象也可以解构，当然对象本身是无序的，所以解构的变量名必须和key名字一致，否则必须重新映射： 1let &#123;foo: baz&#125; = &#123;foo: 1, bar: 2&#125;; 这个功能经常用在传递函数参数上，调用方传入一个Object，接受函数可以用(&#123;param1, param2&#125;)直接解包，将key对应的value赋给变量；5. 字符串也可以解构成字符，因为字符串本来就是字符数组（只是不可变）6. Unicode支持增强，允许使用\\u&#123;20BB7&#125;来进行UTF-16表示；使用新的String.fromCharCode来转换Unicode；使用新的at方法来取出字符；7. 提供了类似python的includes, startsWith,endsWith方法；提供repeat方法快速生成字符串；提供padStart,padEnd方法填充字符串；8. 终于，有官方支持的字符串模板了（泪流满面）。格式类似shell： 1`User $&#123;user.name&#125; is not authorized to do $&#123;action&#125;.` $&#123;&#125;内部可以进行各种运算，包括直接调用函数，这个看起来有点像bash中的引用变量；9. 标签模板，允许使用函数后紧跟模板，相当于把模板中的常量和变量当做参数传入该函数；使用String.raw后跟模板，输出的就是别的语言中的原生字符串；10. 正则表达式也有所增强，使用的时候再看吧；11. Number.isFinite和Number.isNaN用来检测特殊值，和内置的区别是非数字直接返回false；12. 同样，将内置的parseInt, parseFloat也变成了Number的方法；13. isInteger用来检测是否整数，但是由于js只有浮点数，所以15.0就是15；14. 用Number.EPSILON表示一个极小的误差范围；15. 引入常量表示精度上下限；16. 新增了17个Math方法；17. 使用**表示指数运算，同python；18. Array.from将类数组或可迭代对象转为数组；Array.of将一组值转换为数组；使用includes查找是否在数组中；19. ES6会明确把数组中的空洞转为undefined；20. ES7将引入列表推导，pythoner的最爱之一；21. 函数允许默认参数；引入lambda表达式=&gt;，lambda表达式的this就是外界的this；ES7引入作用域绑定符号::用来绑定lambda的作用域；22. 尾递归优化；23. 可以使用Object.assign进行深拷贝；24. Symbol用来生成独一无二的标识，可以用来当key；25. Proxy可以用来给对象做代理，做一些限制；26. 引入二进制数组；27. 引入Set和Map，注意不能使用[]进行操作；28. 引入for..of..循环，代替原来一些循环方式；注意的是在object中for..of..返回的是value，key仍然用for..in..，但是Map则返回的是[k, v]的一个数组；29. 引入yield作为生成器；30. 引入Promise解决异步编程问题；31. 引入Async，作为生成器的语法糖。使用async将过程转为异步，使用await表示同步阻塞；这个东西是ES6最精华的部分；32. 引入Class语法糖，更加OO. 构造函数是constructor，成员函数无需function关键字；使用extends进行继承；使用super关键字表示父类；可以扩充原生对象；方法前加星号表示生成器函数；static关键字表示静态函数；静态属性只能写在外面，ES7可能可以写在里面；33. 装饰器。34. 导入命令，格式是： 123456import &#123; stat, exists &#125; from &#x27;fs&#x27;;import * from &#x27;./test&#x27;; //overide namespaceimport &#123; long as l &#125; from &#x27;xx&#x27;;export default xxx;import x from xxx; // import defaultexport let firstName = &quot;xxx&quot;; vue要点见vue学习笔记","tags":[{"name":"web","slug":"web","permalink":"http://yiuterran.github.io/tags/web/"},{"name":"javascript","slug":"javascript","permalink":"http://yiuterran.github.io/tags/javascript/"},{"name":"es6","slug":"es6","permalink":"http://yiuterran.github.io/tags/es6/"}]},{"title":"erlang速记","date":"2017-06-12T15:48:18.000Z","path":"2017/06/12/erlang速记/","text":"对于学习过Haskell的人来说，学习Erlang并没有太大的难度。 语法结构 首字母小写或者用单引号括起来的表示原子；首字母大写表示变量；原子等于原子本身。 tuple用{}表示，列表用[]表示； 用=作模式匹配，用|做头尾区分，用双引号表示字符串（本质是一串数字，可以用$取得字符对应的数字）; .表示模式终结，,用来分割参数，函数；;用来分割子句； 函数的参数个数，称为函数的目；func关键字用来定义匿名函数； 1func(X, Y) -&gt; math:sqrt(X*X + Y*Y) end. 可以把返回值放到括号里面。6. 标准库lists里面含有很多常见的函数，如map, reduce， filter等；7. 没有for循环，和haskell一样，使用尾递归；8. 使用import, export, module来导入/导出/声明模块；9. 列表解析，格式是[X *2 || X &lt;- L]. 12345qsort([]) -&gt; [];qsort([H|T]) -&gt; qsort([X || X &lt;- T, X &lt; H]) ++ [H] ++ qsort([X || X &lt;- T, X &gt;= H]). 断言，关键字when。使用,表示andalso语义， 使用orelse而不是or因为后者不是短路求值； 使用record表示字典，声明方式： 1-record(todo, &#123;stats=reminder, who=joe, text&#125;) 需要将其存放在.hrl后缀的文件中，然后使用rr读取。 1234X=#todo&#123;&#125;.Y=#todo&#123;status=urgent, text=&quot;Fix errata in book&quot;&#125;.Z=Y#todo&#123;status=done&#125;.#todo&#123;who=W, text=Txt&#125; = Z %模式匹配 可以使用is_record做模式匹配； case xxx of Pattern1 [when Guard1] -&gt; xxx end 1234567891011odds_and_evens_acc(L) -&gt; odds_and_evens_acc(L, [], []).odds_and_evens_acc([H|T], Odds, Evens) -&gt; case (H rem 2) of 1 -&gt; odds_and_evens_acc(T, [H|Odds], Evens); 0 -&gt; odds_and_evens_acc(T, Odds, [H|Evens]) end;odds_and_evens_acc([], Odds, Evens) -&gt; &#123;Odds, Evens&#125;. 异常的捕捉采用try...catch..after...end格式，非常类似java； 数字格式包括2#01011其中#前面是进制，浮点数可以用科学计数法，即-2.3e+6等； 每个进程都有一个私有数据存储，称为进程字典，可以用put,get, get_keys, erase等函数进行操作；但是如果使用进程字典，代码就不再是没有副作用的，因此要避免使用； 引用是全局唯一的Erlang值，使用erlang:make_ref()来创建引用； 奇怪的操作符： ==, /=, =:=全等，=/=不全等；数值比较会有隐式转换；==仅限于浮点数和整数的比较，大部分情况下，应该使用=:=； 奇怪的排序：number&lt;atom&lt;reference&lt;fun&lt;port&lt;pid&lt;tuple&lt;list&lt;binary； 下划线变量：仅用来声明不准备使用的变量（占位符）；或者用来调试； 对于大的程序，还是要使用makefile的，然而直到今天我还是不会写makefile，不过我决定抽个时间学习以下cmake的使用；使用code:get_path()查看搜索路径，code:add_patha, code:add_pathz用来增加新目录； 可以在~/.erlang下增加一些命令，当启动erlshell时，会先执行这里的初始化语句；当前目录下的.erlang会覆盖home下的执行优先级。可以使用init:get_argument(home)确定home的路径（for windows）； erlang需要在运行前编译，或者用escript命令执行而无需编译（解释器）。escript的语法与erlang本身略有不同。当然我想不到在什么情况下要写erlang脚本。。。因为erlang并不是一门好的脚本语言。python才是现在的最优选择：） 并发编程 和go一样，很简单的创建进程：Pid=spawn(Fun)； 发送消息： Pid ! Message，异步发送。返回值是消息本身，这意味着使用Pid1 ! Pid2 ! M会将M发送到所有的Pid中； receive ... end， 接收一个发送到当前进程的消息；格式是：12345678receive Pattern1 [When Guard1] -&gt; Expression1; Pattern2 [When Guard2] -&gt; Expression2;after Time -&gt; %超时 Expressionsend 消息发送到进程的邮箱中，receive说白了是检查邮箱，如果消息不能匹配任何模式，则会被放到保存队列里；如果有一条消息能成功匹配，则放入保存队列里的旧消息会按着到达的先后顺序重新取出放入邮箱；如果有after设置，计时器到达后也会触发上述规则； 除了Pid机制外，可以采用注册进程的方式公开进程。1234register(Name, Pid) %将Pid注册为Nameunregister(Name)whereis(Name) -&gt; Pid | undefined %检测是否注册成功registered() %已注册进程list 如果想要热更新代码，最好使用MFA（即带着模块名）的调用方式创建进程； 使用link(Pid)在两个进程之间建立联系。二者之中任意一个挂掉，另一个都会收到系统通知； 小结Erlang并不难，但是OTP很难。Erlang设计很用心，目标很明确，对于分布式大型系统的构建提供了很多基础支撑。缺点是生态系统略显封闭，社区不活跃，各种第三方库支持不全。相比之下，个人更看好Go的发展，虽然后者并不是为构建大规模系统而生，但是CPS模型的并发写起来也很舒服，加上简单的语法，快速的编译过程，完善的生态链，杰出的性能，是一个很不错的工具。 目前来看，Skynet+Lua就是仿制了Erlang的思想。","tags":[{"name":"erlang","slug":"erlang","permalink":"http://yiuterran.github.io/tags/erlang/"},{"name":"FP","slug":"FP","permalink":"http://yiuterran.github.io/tags/FP/"}]},{"title":"java Proxy模式","date":"2017-06-12T15:48:04.000Z","path":"2017/06/12/java Proxy模式/","text":"java也可以使用反射生成动态代理，从而完成面向切面编程，这是spring框架的基础。由于java的第一元素只有object，所以函数处于第二阶梯，这导致在其他语言中很容易(函数是第一类的语言中）实现的动态代理，在java中就必须以对象的形式实现。 在Python中使用getattr(object, method)可以轻易完成反射；最简单的可以这么做： 123456789101112import inspectclass Proxy(object): def __init__(self): self._real = Real() for method in inspect.getmembers(_real, predicate=inspect.ismethod): setattr(self, method[0], self._call_real(m[0]) def _call_real(self, method): def _real_proxy(*args, **kargs): return getattr(self._real, method)(*args, **kargs) return _real_proxy java生成动态代理的主要使用了java.lang.reflect.Proxy类的newProxyInstance()方法，其原型如下： 123public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvacationHandler h)throws IllegalArgumentException; 参数：loader - 定义代理类的类加载器interfaces - 代理类要实现的接口列表h - 指派方法调用的调用处理程序返回：一个带有代理类的指定调用处理程序的代理实例，它由指定的类加载器定义，并实现指定的接口抛出：IllegalArgumentException - 如果违反传递到 getProxyClass 的参数上的任何限制NullPointerException - 如果 interfaces 数组参数或其任何元素为 null，或如果调用处理程序 h 为 null 动态代理类：在运行时生成的class，在其生成过程中，你必须提供一组接口给它，然后该class就声称实现了这些接口。可以把该class的实例当做这些接口中的任何一个来用。其实，这个Dynamic Proxy就是一个Proxy，他不会替你做任何实质性的工作。在生成它的实例时，必须提供一个Handler，由它接管实际的工作。在使用动态代理类时，必须实现InvocationHandler接口。 InvaocationHandler接口必须实现的方法是 1234Object invoke(Object proxy, Method method, Object[] args) throws Throwable 此处控制流翻转，该方法被回调，传入用户尝试调用的方法和参数，以及代理本身的实例。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"design_pattern","slug":"design-pattern","permalink":"http://yiuterran.github.io/tags/design-pattern/"},{"name":"proxy","slug":"proxy","permalink":"http://yiuterran.github.io/tags/proxy/"},{"name":"reflect","slug":"reflect","permalink":"http://yiuterran.github.io/tags/reflect/"}]},{"title":"cometd 学习文档","date":"2017-06-12T15:47:35.000Z","path":"2017/06/12/Cometd使用笔记/","text":"cometd client 分为remote client和local client，remote client即是传统的cometd客户端，分为java和javascript两个版本；当remote client与server建立bayeux协议连接后，server session才被创建；而local client则是server侧的client，当server想要创建一个不与remote client直接连接的session时，必须先创建一个local client； local client的作用在于，如果server并非简单的无条件转发信息到其他remote client，而是想要做一些server端的处理（比如仅仅发往特定的客户端），就需要一个local client。service通道都对应一个local client； 通道类型分为meta channel, broadcast channel和service channel，meta channel是禁止订阅的，用来处理协议的基本功能，包括/meta/handshake, /meta/connect, /meta/disconnect, /meta/subscribe, /meta/unsubscribe, /meta/publish, /meta/unsucessful；而broadcast channel类似与聊天室，服务器无条件转发来自broadcast channel的信息到所有的subscribers；service channel则类似于私聊，服务器有条件转发到指定的订阅了该服务的某一个或多个remote client； server端是一个BayeuxServer对象，相关联的对象包括： transport，包括http和websocket，或其他自己实现的接口，这里用来实现bayeux的底层通信方式； channels，通道 extensions，扩展用来与bayeux协议交互，是一种listener，可以用于在消息接收后、发送前等时刻对消息进行自定义处理 authorization，认证机制，一般通过SecurityPolicy来实现；也可以通过Authorizer进行更细粒度（如针对某个channel）的处理； 消息处理，可以通过回调（监听）对客户端发来的消息进行处理； Listener. 客户端对某个channel的listener，用来处理服务器发送（或转发）的message(通过ClientSession.getChannel(String).addListener(ClientSessionChannel.MessageListener)来添加)；此外也可以通过添加extension对消息做最初或最后的处理； Server端的Listener类似，但更加丰富，包括： extension, 对server的或对session的 channel create|destroy listener subscribe|unsubscribe channel session被remove 与server的message queue交互(MaxQueueListener, DeQueueListener等) MessageListener 消息流动的过程： 客户端通过client-side的channel发送消息，这些消息首先通过clientsession extension，做最后的过滤；然后通过底层的transport发往server。transport会将message转换为JSON格式，server transport接受到这些消息后，再将JSON字符串转为普通消息； 消息在server侧首先通过server extension，做最初的处理，此时如果被拒绝，返回给client的错误标示该消息已被删除； 消息随即被送往serversession extension，如果被拒绝，操作同上； 消息被送往security policy和authorizers接受审核，如果被拒绝，返回给客户端说明未通过认证； 消息被送往channel listener，服务器可以在channel listener里面对消息做任意修改；该步骤后，消息被冻结； 如果是nonbroadcast channel，会随即回复一条消息给发送者，表明服务器已收到消息并且该消息不是广播消息（貌似是将消息原样返回）； 如果是broadcast message，消息会通过serversession extension，然后插入server的message queue，准备发出； 如果是lazy message，消息需要等待一段时间，否则消息被立即发送出去；如果消息被发往remote client，会单独开一个线程进行异步发送，后续步骤包括转换为JSON格式，通过底层的transport等，类似客户端发送消息之前的方式；如果是local client，就直接发送过去； 不管是不是广播消息，消息被插入消息队列后，服务器会返回一条信息给发送者，标明发送结束； 客户端接收到消息，底层的tranport将消息转回普通格式，然后依次经过client session extension, channel listener和channel subscriber； server每收到一条bayeux消息，会分配一个单独的线程进行消息处理，所有的listener都在这个单独的线程中被依序唤醒。client与server之间的连接是有限的，如果同一个连接在短时间内收到大量消息，而消息的处理过程过慢，就会导致后续消息被堵塞而无法得到及时处理。因此服务器在处理消息过程中如果有耗时处理，务必要单开线程； 消息类型： 客户端发往server的，主要是meta消息； 客户端发往指定客户端的，需要通过service通道，然后通过clientId deliver过去 服务器发往客户端的，需要服务器本地起一个local client session，与服务器握手，然后在该通道publish一个消息，这个local client充当了消息的sender 即使client没有subscribe一个channel，也可以在这个channel上publish message cometd server无法保证消息被正确送往client，除非client和server都打开message acknowledgment extension，这样二者在handshake时会在ext段增加特殊属性，协商完毕后，客户端会对每一条接受到的消息做出应答；这种机制提供了一种不可靠的失败重传功能； seti是oort集群时用来发送消息的一种工具，如果a想向b发送信息，但是二者连在不同的comet节点上，这时候就需要转发消息、操作clientId等。seti可以将client与其他标识进行关联，这种关联可以是一对一的，也可以是一对多的。比如说，一个userid有多个deviceid，我们可以将userid与该用户的所有device的clientId都关联起来，也可以将其deviceid和对应的clientid对应起来，这样就可以直接转发了。 每个oort节点仅有1个seti对象，当userid第一次与seti关联时，会向所有节点广播此消息，这样其他节点都知道如果需要向某个userid发消息，需要把消息转发给这个seti；用户断开连接或者超时被移除session，这种关联会自动取消。当一个seti中，userid关联的所有session都断开连接时，userid会解除与seti的关联，然后广播此消息。我们可以监听这两种广播消息。 通过seti发送消息很简单，我们只需要指定userid，seti会自动找到其所连接的comet节点，进行发送； comet节点之间的数据共享。OortObject用于解决此问题，这是一个分布式的架构，所有节点拥有此对象，此对象存放所有节点的共享数据，每个节点只能修改属于自己的那一部分，其他的是只读的，每次修改会广播给其他节点，其他节点可以监听这种广播，并做一些自定义修改。 服务转发功能，如果集群各个节点提供的服务不一致，可能需要此功能用于转发服务。","tags":[{"name":"cometd","slug":"cometd","permalink":"http://yiuterran.github.io/tags/cometd/"},{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"push","slug":"push","permalink":"http://yiuterran.github.io/tags/push/"}]},{"title":"cometd使用haproxy做负载均衡的配置指南","date":"2017-06-12T15:47:30.000Z","path":"2017/06/12/cometd使用haproxy做负载均衡的配置指南/","text":"下载安装Ubuntu14.04直接用apt安装就是最新的稳定版，其他旧版本Ubuntu需要使用ppa获得： 1sudo add-apt-repository ppa:vbernat&#x2F;haproxy-1.5 然后update，install即可。(PS: 如果连add-apt-repository都不能用，先执行sudo apt-get install python-software-properties） 使用理论上直接用sudo service haproxy start|stop|restart|status|reload就可以，不过ubuntu直接安装后这个命令是没法用的…需要编辑/etc/init.d/haproxy，然后把ENABLED=0改成ENABLED=1，然后删除 123if [ -e &#x2F;etc&#x2F;default&#x2F;haproxy ]; then . &#x2F;etc&#x2F;default&#x2F;haproxyfi 这几行。当然，也可以直接使用sudo haproxy -f /etc/haproxy/haproxy.conf 来启动，加上-d参数可以在前台运行调试。 配置如果同时使用两种transport(websocket和http)，需要注意long-polling的session保持问题。如果只使用websocket，需要注意的只有timeout的设置问题。 典型配置如下^1，默认路径为/etc/haproxy/haproxy.conf: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051global log 127.0.0.1 local0 #see &#x2F;etc&#x2F;rsyslog.d&#x2F;haproxy.conf chroot &#x2F;var&#x2F;lib&#x2F;haproxy pidfile &#x2F;var&#x2F;run&#x2F;haproxy.pid uid 99 gid 99 daemon #run as service nbproc 1 #only one instance allowed maxconn 120000defaults mode http log global option httplog #log http info option http-server-close #Don&#39;t keepalive between haproxy and server option redispatch #if health check failed, dispath new server option forwardfor #for server get Ip of client retries 3 #connect to server fail max times before redispatch timeout connect 10s #timeout tcp connection between haproxy and backend servers timeout client 50s #timeout client inactivity timeout server 50s #timeout for server to process the request timeout queue 30s #timeout for request in queue when server reach max connection timeout http-keep-alive 2s timeout http-request 15s default-server inter 5s rise 2 fall 3 stats uri &#x2F;stats stats refresh 10s stats auth baina:P@55wordfrontend ft_web bind *:80 timeout client 10m timeout client-fin 5s maxconn 120000 option http-pretend-keepalive #without this, handshake can&#39;t be established default_backend cometdbackend cometd timeout server 10m timeout tunnel 10m balance roundrobin# balance source option httpchk GET &#x2F;cometd HTTP&#x2F;1.1\\r\\nHost:\\ \\r\\nConnection:\\ upgrade\\r\\nUpgrade:\\ websocket http-check expect status 101 cookie SERVERID insert appsession SERVERID len 25 timeout 15m #for Long-polling keep sessionserver bayuex-srv1 10.232.2.118:80 maxconn 40000 weight 10 cookie bayuex-srv1 checkserver bayeux-srv2 10.235.30.6:80 maxconn 40000 weight 10 cookie bayeux-srv2 checkserver bayeux-srv3 10.45.160.213:80 maxconn 40000 weight 10 cookie bayexu-srv3 check 存活检测通过httpchk选项来完成，cometd要求必须使用http1.1，因此header中必须要有Host，这里留空。 这里通过插入cookie来满足long polling的session保持需求，这要求client每次post都必须携带server发给client的cookie。当然这个问题也可以通过balance source hash ip来解决，但是后者可能会导致负载均衡度不高。 注意，如果使用long polling，切记加上option http-pretend-keepalive，不然server会把Connection: close发给client，握手直接被终结. rsyslog上述配置中，log 127.0.0.1 local0这句是用来配置log的，如果使用syslog，在/etc/syslog.conf中添加 1local0.* &#x2F;var&#x2F;log&#x2F;haproxy&#x2F;haproxy.log 即可指定到具体文件。 ubuntu使用rsyslog，因此对应的配置方法如下^2，默认路径/etc/rsyslog.d/haproxy.conf： 12345$ModLoad imudp$UDPServerRun 514$template Haproxy,&quot;%msg%\\n&quot;local0.* -&#x2F;var&#x2F;log&#x2F;haproxy.log;Haproxy&amp; ~ 为使配置生效，请将文件名改为49-haproxy.conf日志的格式^3可以通过配置$template参数来完成，这里写了最简单的一种输出格式。 日志滚动通过配置/etc/logrotate.d/haproxy来实现，默认有一个按日滚动的策略，一般够用了。其格式如下： 1234567891011&#x2F;var&#x2F;log&#x2F;haproxy.log &#123; daily #按日滚动 rotate 10 #保留10个 missingok notifempty compress delaycompress postrotate invoke-rc.d rsyslog rotate &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 || true endscript&#125; ##DDOS防范haproxy可以用来做ddos防范，具体可参见：http://blog.sina.com.cn/s/blog_704836f40101f4qh.html","tags":[{"name":"cometd","slug":"cometd","permalink":"http://yiuterran.github.io/tags/cometd/"},{"name":"haproxy","slug":"haproxy","permalink":"http://yiuterran.github.io/tags/haproxy/"},{"name":"websocket","slug":"websocket","permalink":"http://yiuterran.github.io/tags/websocket/"}]},{"title":"CometD源码学习[0]","date":"2017-06-12T15:47:25.000Z","path":"2017/06/12/CometD源码学习_1/","text":"jetty生命周期Jetty的核心组件是Server和Connector，Server基于Handler容器工作，里面包括ServletHandler，SessionHandler等处理器，Server本身也继承自Handler类。Connector类用于监听连接请求；此外还有Container用来管理MBean。Jetty的Server扩展是通过实现Handler并将至注册到Server中来实现的。整个Jetty的组件的生命周期管理是基于观察者模板设计的，每个组件都有个Listener，用来监听Jetty启动/停止过程中的事件。 HandlerJetty本身提供了两类HandlerWrapper和ScopeHandler两种Handler，前者是一个装饰器修饰的Handler，用来做委托(Proxy模式)，后者是一个拦截器——在调用Handler之前或之后做某些事情。 prestartJetty在启动之前会先初始化jetty的相关配置(start.ini)，然后通过自己的IOC(XmlConfiguration)将这些服务组装在一起，最后调用start启动这些组件。其中最重要的配置文件包括jetty.xml, jetty-deploy.xml以及contexts/*.xml。然后根据配置文件中的参数新建一个进程应用JVM参数（如果有--exec，没有的话不会再起新的进程，start.ini中的JVM参数就不可能重新得到应用)。 启动Jetty的启动入口是Server类或者其子类。下图是Jetty启动过程：在创建线程池后，Server开始依次调用已注册Handler组件的Start方法，直至整个调用链结束（调用链的末尾应该是用户自定义的service），这一步是初始化各组件（filter, servlet，包括用户的服务）的配置；然后启动Container中已注册的MBean（for JMX），最后启动Connector开始接受请求。 Jetty作为一个轻量级web容器，不仅可以接受http协议作为web服务器，还可以与其他web应用服务器集成（如Jboss或Apache），这时候Jetty工作于AJP协议。 web服务器对于http协议，按着传统的划分方式，分为BIO（阻塞式）和NIO（非阻塞式），以及AIO（异步式），windows的IOCP是AIO。 BIO是一个连接一个线程。NIO是一个请求一个线程。AIO是一个有效请求一个线程。 BIO如果jetty工作在BIO模式（选用org.eclipse.jetty.server.bi.SocketConnector作为Connector），建立连接的步骤分为： 创建队列线程池，用于处理请求； 创建ServerSocket用于准备接受请求； 创建一个或多个监听线程（Accptor)，开始监听。 对于每个连接，BIO从线程池中分配一个线程进行处理；时序图如下： Accptor对每个请求创建ConnectorEndPoint，后者对实际消息做出具体解析并应答。Jetty9 移除了BIO的Connecter（现在是异步的世界了…）如果工作在AJP协议下，与 HTTP 方式唯一不同的地方的就是将 SocketConnector 类替换成了 Ajp13SocketConnector，即监听的协议不同而已。 NIONIO是非阻塞的，类似于linux中的select系统接口： 创建N个Acceptor对象，每个对应一个SelectSet对象，用于存放已注册的socket集合； 创建N个Selector线程用于轮询SelectSet(select)或监听SelectSet中的事件(epoll)，线程数同Acceptor的个数(jetty.xml中指定）； Connector接受(accept)到请求，得到Socket，将之设为非阻塞，然后以轮询机制分发给Acceptor并返回（异步)； Acceptor将之放入自己的SelectSet，并返回； Selector检测到新的Socket，开始监听该Socket的read事件（select）； 一旦有新事件到来，立刻新建ConnectorEndPoint，调用schedule方法并返回继续监听该Socket（异步）； schedule方法调用线程池中的线程，进行实际的逻辑处理(worker)，该线程会调用Server的handle方法，这里形成handle的调用链（这是在server启动前注册到server中的）。 NIO的一般工作原理用代码描述如下： 123456789Selector selector = Selector.open(); //实例化selectorServerSocketChannel ssc = ServerSocketChannel.open(); //实例化socketssc.configureBlocking( false ); //非阻塞SelectionKey key = ssc.register( selector, SelectionKey.OP_ACCEPT ); //注册事件ServerSocketChannel ss = (ServerSocketChannel)key.channel();SocketChannel sc = ss.accept();sc.configureBlocking( false );SelectionKey newKey = sc.register( selector, SelectionKey.OP_READ );Set selectedKeys = selector.selectedKeys(); AIOjava7开始支持AIO，而jetty则从jetty9开始支持这一特性。AIO在linux上使用epoll完成，在windows上则使用IOCP（IO完成端口）完成。 一般而言，AIO对应Proactor模式，NIO对应Reactor模式，两者最大的区别在于IO是由谁来完成：AIO中，由内核完成IO，然后将结果通知给用户（信号/回调函数）；NIO中，内核只是将准备好进行IO的描述符通知给用户（信号/回调函数），然后由用户自己处理IO。 需要了解的预备知识到此结束，下一篇开始正式分析CometD源码。","tags":[{"name":"cometd","slug":"cometd","permalink":"http://yiuterran.github.io/tags/cometd/"},{"name":"jetty","slug":"jetty","permalink":"http://yiuterran.github.io/tags/jetty/"},{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"}]},{"title":"CometD源码学习[1]","date":"2017-06-12T15:47:20.000Z","path":"2017/06/12/CometD源码学习_2/","text":"首先学习server部分，主要包括cometd-java-server这个package，同时涉及到cometd-java-common和bayeux-api这两个package。 org.cometd.server.CometDServlet在web.xml中，服务的配置顺序一般是CometDServlet，oort，seti和用户自定义应用的Servlet，我们也按这个顺序来看。显然，这个类主要用于Long-Polling模式。init中主要就是新建（如果未导出）并启动一个bayeuxServer;service中，”OPTION”请求，用于允许CORS访问，直接返回200；否则转发给transport；destroy用于生命周期中stop过程调用，依次cancelSchedule, stop bayeuxServer, remove导出的bayeuxServer. org.cometd.server.BayeuxServer这个接口规定了bayeux服务器需要实现的接口。值得关注的地方： 可监听事件： a. ChannelListener用于监听add/remove Channel的事件； b. SessionListener用于监听add/remove Session的事件，这个比较重要。可以通过Session建立事件来给client push 欢迎消息，通过Session removed事件来确认client断开连接。 c. SubscriptionListener用于监听订阅事件； extension接口: extension本质是一个消息钩子，可以在rcv之初/send之末对消息做一些修改（主要是操作bayeux协议的ext字段），所以参数中ServerMessage都是Mutable的.这里normal message和meta message被区分开来。 org.cometd.server.BayeuxServerImpl顾名思义，bayeuxServer的实现类。VALID用了一个技巧，即字符本质上是一个short的ASCII码；System.identityHashCode用于获取对象的原始hashcode码；SecureRandom是一个强加密的随机数类；listeners, extension都被存放在线程安全的CopyOnWriteArrayList里面；client_id与ServerSessionImpl、channel_name与ServerChannelImpl的映射也被存放在线程安全的ConcurrentHashMap里面；Server支持的transport被存入LinkedHashMap里面，因为transport的顺序很重要，优先使用迭代中最前的，不可行时才使用后续者；currentTransport是一个ThreadLocal变量，因为每个线程（连接）当前的Transport肯定不一样。 _scheduler是一个周期性定时器，此外是一个policy、一个JSON的server，这三个变量。 dostart 首先初始化Meta Channel：创建Channel并增加相关的Listener； 初始化JSON服务器，这里有一个缺省的实现（JettyJSONContextServer），但是用户也可以通过option自定义一个实现类（通过反射，使用isAssignableFrom判断是否是JSONContext.Server的子类）； 初始化transport.如果没有设置，初始化为websocket接口，否则依序初始化配置文件中指定的端口并添加到容器中；如果allowedTransports没有设置，默认允许所有transport，否则依序初始化配置文件中允许的且存在于transport列表中的transport；上述所有数据都被添加到公用的容器中了。 启动_scheduler，执行周期性扫除(sweep)任务（每次计时任务结束后需要手动再启动定时任务），该任务会扫描所有Channel和端口以及session，扫描周期默认是997ms，可以自己设置。session扫描即服务端超时机制，如果now&gt;一定时间间隔，则从服务端移除session；Channel扫描就是检测Channel的订阅数量，如果没有活动的（即已握手的session的）订阅，那么就从BayeuxServer中清除（除非设置为persistent）； 最后是2.9新增的validateMessageFields用于校验消息格式。 createChannelIfAbsent创建通道，传入channel名和初始化器。如果Channel name尚不存在： 根据channel name创建ChannelId，然后创建一个新的ServerChannelImpl，后者是一个ServerChannel接口的实现类。注意在ServerChannelImpl的构造函数中，如果非broadcast channel，会被设置为persistent的； 存放channel，会再次检测channel是不是已经存在（多线程检测），确认无误后，开始配置channel；使用传入的initializers和已注册的listener配置channel； 初始化完毕，触发ChannelListener的Channel added事件；如果Channel name已存在：什么都不做，简单的给将channel的存活评估值（_sweeperPasses)重置。会再次check channel（putIfAbsent）是不是已存在于容器中。 PushServlet先跳过Oort和Seti，直接看PushServlet（我们的应用程序）。由于在CometDServlet里面已经导出了bayeuxServer，这里可以通过getServletContext()直接拿到Server了.现在可以创建SecurityPolicy和PushService了。 AbstractService顾名思义，这个类是abstract的，注意构造函数里面会先create一个LocalSession，然后自己和自己握手。这个LocalSession本子上是用于服务端主动publish消息的.初始化的时候可以指定线程池的大小，否则使用同步访问。显然，如果不使用线程池，那么在处理消息时如果有费时间的操作，必须新建线程。这里用了一个技术，使用反射技术查看自己所处的类的Modifier是不是public的。 addService创建Channel后，正常流程走到这里。传入channel name和callback func name，利用反射技术进行映射。getClass拿到类，然后从当前开始逐层向上遍历直到AbstractService，执行以下操作：getDeclaredMethods拿到方法集合，遍历方法集合，判定名称相等且有public描述符，那么找到候选Method。候选Method的参数必须符合固定的签名类型，这里用isAssignableFrom配合getParameterTypes()来进行判断；注意：这里会主动调用createChannelIfAbsent创建服务（这里就没机会做配置了）； 创建一个Invoker，在并行队列里放入messageName和Invoker的映射。该Invoker被增加为Channel的Listener. handle所有消息首先经过该函数进行分发。首先验证消息，创建回复并关联。调用接受的extension对消息进行扩展；从消息中取出channel，对消息进行认证(Authorizer)；然后依据是否是Meta消息进行不同的分发，无论是接受消息还是发送消息，最终都是调用了doPublish方法。 AbstractService.InvokerServerChannel.MessageListener接口的实现类。 OnMessage消息的观察者。Server可以通过isSeeOwnPublish相关参数的配置控制是否接收自己publish的消息，然后调用(invoke）回到函数。如果初始化的时候传递了最大线程数，那么这里就从线程池里面拿线程然后处理消息；否则直接在当前线程里面处理消息(doInvoke)；如果回调函数的签名中有返回值，这个值会被立刻返回(send)给client端。 现在再次回到BayeuxServerImpl类中，doStart会给所有的Meta Channel增加Listener，这是预置的Meta handler；按着Bayeux协议约定的过程，client会首先handshake。 BayeuxServerImpl.HandshakeHandler先看父类，HandlerListener是ServerChannel.ServerChannelListener的实现类。isSessionUnknown没啥好说的；toChannelList有个有趣的地方，可以用Collections.singletonList生成单元素列表），对某些需要传一个集合，但是实际上只要传一个元素的API很有用； OnMessagehandshake的时候session理论上还不存在，于是新建一个ServerSession，并且将HTTP的相关报头转移过来（UA），然后得到关联(getAssociated)的消息实体（消息可能是捎带回去的）。这时候先判断SecurityPolicy有没有设置，如果设置了，就先判断canHandshake是不是成立，如果不成立，就要reply.setSuccessful(false)，并设置错误原因。 这里有个问题，reply并没有传给canHandshake，但是message被传进去了。根据ServerMessageImpl的实现，canHandshake也可以用message.getAssociated里面拿到reply，然后增加想要的字段（ext）。代码显示，这里并没有往advice里面添加重连间隔（interval)字段。【这里显示了nest class如何得到outer class的实例，直接用BayeuxServerImpl.this.】 一切正常，ServerSession首先和自己握手，增加ServerSession（在此处通知回调，即应用程序注册的监听Session添加的方法），定义reply中的某些字段；如果canHandshake返回false，则返回403（handshake denied）错误；注意：如果应用程序的监听器没有设置advice中的reconnect字段，这里默认会填入none。 reconnect字段分为3种，正常是retry；handshake一般是402错误，要求重新握手；none就是禁止自动重连了。^1 BayeuxServerImpl.ConnectHandler心跳信息处理。 OnMessage如果session未知，那就需要重新握手，返回402错误。否则对session进行续期，并返回advice，内容包括timeout和interval字段（如果没有设置，默认是不过期的） BayeuxServerImpl.SubscribeHandler订阅Channel处理。 OnMessage402同上。如果没有subscription字段或者字段不符合格式，403；如果Channel不存在，尝试创建Channel(policy的canCreate，以及内部Channel格式约束)，失败则403。 BayeuxServerImpl.UnsubscribeHandler退订处理。 OnMessage退订只要session存在，消息格式正确，没有理由不让你退XD BayeuxServerImpl.DisconnectHandler断开连接处理。 OnMessagesession存在即可断开。会激活移除session的回调（timeout=false）刷新session=&gt; ServerSessionImplflush刷新session会取消上一次的lazyTask； LazyTaskRunnable子类，其scheduler方法最终调用BayeuxServerImpl中的同名方法，作为一个计划任务执行（Scheduler是jetty的基础工具类）。 Setxxx可以设置的包括：Intervaltimeout ServerSessionListener可以监听的事件包括：RemoveListener=&gt;移除Session时通知MessageListener=&gt;有消息时通知QueueListener=&gt;消息被加入队列时通知DeQueueListener=&gt;消息出列时通知MaxQueueListener=&gt;队列满时通知","tags":[{"name":"cometd","slug":"cometd","permalink":"http://yiuterran.github.io/tags/cometd/"},{"name":"jetty","slug":"jetty","permalink":"http://yiuterran.github.io/tags/jetty/"},{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"}]},{"title":"cmake实践","date":"2017-06-12T15:47:11.000Z","path":"2017/06/12/cmake实践/","text":"heka使用了cmake进行构建，cmake是目前最好的大型项目构建工具（比autoconf之类的都要好），有很强的学习价值。另外JetBrain的CLion也是用cmake进行构建的。 初级学习材料是CMake Practice这本书. 例子12345PROJECT(HELLO)SET(SRC_LIST main.c)MESSAGE(STATUS &quot;This is BINARY dir&quot; $&#123;PROJECT_BINARY_DIR&#125;)MESSAGE(STATUS &quot;This is SOURCE dir&quot; $&#123;PROJECT_SOURCE_DIR&#125;)ADD_EXECUTABLE(hello $&#123;SRC_LIST&#125;) 上面是一个最简单的CMakeLists.txt示例，也很容易理解。使用SET命令设置变量，使用MESSAGE命令显示信息： 1MESSAGE([SEND_ERROR | STATUS | FATAL_ERROR] &quot;message to display&quot;) 使用空格键分割参数。 ADD_EXECUTABLE添加生成的可执行文件，第一个参数是可执行文件的名字（与项目没什么关系）。 一般情况下，使用$&#123;&#125;引用变量，但是如果在IF中，则默认就是一个变量名，这时候就不要再解引用了。 指令是大小写无关的，参数和变量是大小写敏感的，但是一般情况下推荐使用全大写的指令。 由于参数使用空格做分隔符，因此若某些参数中间含有空格（如文件名），则需要用引号包围。另外就是文件后缀可以省略，如果确定不会重复的话（推荐保留）。 另外就是参数也可以用分号分割，注意前后保持一致就行。 外部构建上面的例子是内部构建，生成了一大堆中间文件，cmake官方更推荐使用外部构建。 删除除了CMakeLists.txt和main.c之外的所有文件，建立一个build目录。然后运行cmake &lt;项目路径&gt;，构建的中间文件和输出的MakeFile都会出现在这个目录里，对原来的项目没有影响。唯一不同的是PROJECT_BINARY_DIR指向build目录了。 进一步复杂化添加src子文件夹，将main.c移入。然后在其中再新建一个CMakeLists.txt。外部改成： 12PROJECT(HELLO)ADD_SUBDIRECTORY(src bin) 内部的写入： 1ADD_EXECUTABLE(hello main.c) 再在build文件夹下cmake，就可以build/bin/文件夹下生成科执行文件。 可以通过修改EXECUTABLE_OUTPUT_PATH和LIBRARY_OUTPUT_PATH来修改最终输出的可执行文件或者链接库的路径。一般写在ADD_EXECUTABLE后面。 安装安装使用cmake -DCMAKE_INSTALL_PREFIX=&lt;dir&gt;来指定安装目录。在根目录的CmakeLists.txt里面写入 123INSTALL(FILES COPYRIGHT README DESTINATION share&#x2F;doc&#x2F;cmake&#x2F;t2)INSTALL(PROGRAMS runhello.sh DESTINATION bin)INSTALL(DIRECTORY doc&#x2F; DESTINATION share&#x2F;doc&#x2F;cmake&#x2F;t2) 这里用了INSTALL指令，第一个参数表示写入文件类型，DESTINATION后面是写入的目标位置。 INSTALL指令参数较多，使用时可以参考文档。 静态库与动态库除了目录名外，与构建可执行文件的主要区别是lib文件夹中的CMakeLists.txt中加入了命令： 123456789101112SET(LIBHELLO_SRC hello.c)ADD_LIBRARY(hello SHARED $&#123;LIBHELLO_SRC&#125;)ADD_LIBRARY(hello_static STATIC $&#123;LIBHELLO_SRC&#125;)SET_TARGET_PROPERTIES(hello_static PROPERTIES OUT_NAME &quot;hello&quot;)SET_TARGET_PROPERTIES(hello PROPERTIES CLEAN_DIRECT_OUPUT 1)SET_TARGET_PROPERTIES(hello_static PROPERTIES CLEAN_DIRECT_OUPUT 1)SET_TARGET_PROPERTIES(hello PROPERTIES VERSION 1.2 SOVERSION 1)INSTALL(TARGETS hello hello_static LIBRARY DESTINATION lib ARCHIVE DESTINATION lib)INSTALL(FILES hello.h DESTINATION include&#x2F;hello) ADD_LIBRARY第二个参数指出了库的类型，可以用STATIC参数构建静态库，SHARD构建动态库。 由于ADD_LIBRARY第一个参数不能重复，所以同时生成静态库需要 SET_TARGET_PROPERTIES. 该命令用来设置很多目标属性，包括版本信息等。这里设置了防止同名删除库，以及版本信息。 使用外部共享库如果依赖外部库，且该库并不存在于系统搜索路径里， 需要使用INCLUDE_DIRECTORIES。 1INCLUDE_DIRECTORIES([AFTER|BEFORE] [SYSTEM] dir1 dir2 ...) 仅仅是这样还不够，上面只是指出了头文件的位置。链接库的位置需要使用LINK_DIRECTORIES或TARGET_LINK_DIRECTORIES。假设上面我们已经把库安装到/usr文件下，在CMakeLists.txt中加入： 12INCLUDE_DIRECTORIES(&#x2F;usr&#x2F;include&#x2F;hello)TARGET_LINK_LIBRARIES(main libhello.so) 即可正常编译链接通过了。 也可使用CMAKE_INCLUDE_PATH和CMAKE_LIBRARY_PATH这两个特殊的环境变量为编译添加额外搜索路径。比如上面我们也可以先在bash里面export CMAKE_INCLUDE_PATH=/usr/include/hello，然后将上面的INCLUDE_DIRECTORIES变为 1234FIND_PATH(myHeader hello.h)IF(myHeader)INCLUDE_DIRECTORIES($&#123;myHeader&#125;)ENDIF(myHeader) 常用变量/环境变量使用SET定义的是显式定义，除此之外，一些指令可以定义隐式变量。当然还有一些内置变量。 使用$ENV&#123;NAME&#125;来调用环境变量，设置环境变量则是SET(ENV&#123;变量名&#125; 值)","tags":[{"name":"cmake","slug":"cmake","permalink":"http://yiuterran.github.io/tags/cmake/"}]},{"title":"python celery组件使用","date":"2017-06-12T15:47:06.000Z","path":"2017/06/12/python celery组件使用/","text":"Prepareinstall: 1pip install celery 选择broker，安装，这里假设使用Redis： 1apt-get install redis-server Configure首先认真阅读官方celery文档的get start部分，如果有时间的话，最好全部看一边… 然后参考阅读别人的best practices，基本就可以干活了。 几个要点 task相关的文件，最好都是用绝对导入；否则，应该在task function上面指定name； 如果需要root权限执行，需要在相关文件中加入platforms.C_FORCE_ROOT=True，但是最好别用root； 可以根据需要消除pickle的警告，设置CELERY_ACCEPT_CONTENT=[&#39;pickle&#39;,]； 默认不发心跳，需要加上BROKER_HEARTBEAT=10，来消除心跳相关警告； Routerrouter是不支持通配符的，如果需要，可以自己写一个自定义Router类。下面是一个celery.py的例子：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950from __future__ import absolute_importfrom celery import Celery, platformsfrom settings import CELERY_BROKERfrom kombu import Queue, Exchangeclass MyRouter(object): &#x27;&#x27;&#x27;router for tasks using wildcard&#x27;&#x27;&#x27; def route_for_task(self, task, *args, **kwargs): if task.startswith(&#x27;writer&#x27;): return &#123;&#x27;queue&#x27;: &#x27;async_writer&#x27;, &#x27;routing_key&#x27;: &#x27;async_writer&#x27;&#125; elif task.startswith(&#x27;caller&#x27;): return &#123;&#x27;queue&#x27;: &#x27;async_caller&#x27;, &#x27;routing_key&#x27;: &#x27;async_caller&#x27;&#125; else: return &#123;&#x27;queue&#x27;: &#x27;default&#x27;, &#x27;routing_key&#x27;: &#x27;default&#x27;&#125;QUEUES = ( Queue(&#x27;default&#x27;, Exchange(&#x27;default&#x27;), routing_key=&#x27;default&#x27;), Queue(&#x27;async_writer&#x27;, Exchange(&#x27;async_writer&#x27;), routing_key=&#x27;async_writer&#x27;), Queue(&#x27;async_caller&#x27;, Exchange(&#x27;async_caller&#x27;), routing_key=&#x27;async_caller&#x27;),)platforms.C_FORCE_ROOT = Trueapp = Celery(&#x27;async&#x27;, broker=CELERY_BROKER, include=[&#x27;async.writer&#x27;, &#x27;async.caller&#x27;, &#x27;async.checker&#x27;, ])app.conf.update(CELERY_ACCEPT_CONTENT=[&#x27;pickle&#x27;, ], CELERY_IGNORE_RESULT=True, CELERY_DISABLE_RATE_LIMITS=True, CELERY_DEFAULT_EXCHANGE=&#x27;default&#x27;, CELERY_DEFAULT_QUEUE=&#x27;default&#x27;, CELERY_DEFAULT_ROUTING_KEY=&#x27;default&#x27;, CELERY_DEFAULT_EXCHANGE_TYPE=&#x27;topic&#x27;, CELERY_TASK_SERIALIZER=&#x27;pickle&#x27;, CELERY_RESULT_SERIALIZER=&#x27;pickle&#x27;, BROKER_HEARTBEAT=10, CELERY_QUEUES=QUEUES, CELERY_ROUTES=(MyRouter(),), )if __name__ == &quot;__main__&quot;: app.start() Start官方给出的init.d脚本不是很好用，下面是一个自己写的参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#!/bin/bash## PushserverCore uWSGI Web Server init script#### BEGIN INIT INFO# Provides: PushserverCore# Required-Start: $remote_fs $remote_fs $network $syslog# Required-Stop: $remote_fs $remote_fs $network $syslog# Default-Start: 2 3 4 5# Default-Stop: 0 1 6# Short-Description: Start PushserverCore Service for generic init daemon# Description: PushserverCore Service thrift Server backend.### END INIT INFONAME=&quot;Core Thrift Server&quot;PROJECT=PushserverCorePATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/var/app/enabled/$PROJECTDESC=&quot;PushserverCore&quot;APP_DIR=/var/app/enabled/$PROJECT/CoreAPP_PATH=$APP_DIR/CoreServer.pyCELERY_LOG_PATH=/var/app/log/PushserverCore/celery.logprint_succ()&#123; echo &quot;$(tput setaf 2)$(tput bold)DONE$(tput sgr0)&quot;&#125;print_fail()&#123; echo &quot;$(tput setaf 1)$(tput bold)FAILED$(tput sgr0)&quot;&#125;stop_service()&#123; echo &quot;stoping $NAME...&quot; if pgrep -f $APP_PATH &gt; /dev/null 2&gt;&amp;1; then pkill -f $APP_PATH fi print_succ&#125;start_service()&#123; if pgrep -f $APP_PATH &gt; /dev/null 2&gt;&amp;1; then echo &quot;$NAME service is already running.&quot; return else echo &quot;starting $NAME service...&quot; nohup python $APP_PATH &gt;/dev/null 2&gt;&amp;1 &amp; fi sleep 3 if pgrep -f $APP_PATH &gt; /dev/null 2&gt;&amp;1; then print_succ else print_fail fi&#125;stop_worker()&#123; echo &quot;stoping celery worker...&quot; if pgrep -f celery &gt; /dev/null 2&gt;&amp;1;then pkill -f celery fi print_succ&#125;start_worker()&#123; if pgrep -f celery &gt; /dev/null 2&gt;&amp;1; then echo &quot;celery is already running&quot; return else echo &quot;starting celery worker...&quot; celery -A async multi start writer caller default -Q:writer async_writer -Q:caller async_caller -Q:default default -c 7 -l INFO --workdir=$APP_DIR --logfile=$CELERY_LOG_PATH fi sleep 3 if pgrep -f celery &gt; /dev/null 2&gt;&amp;1; then print_succ else print_fail fi&#125;check_status()&#123; if pgrep -f $APP_PATH &gt; /dev/null 2&gt;&amp;1; then echo &quot;$NAME is running&quot; else echo &quot;$NAME is not running&quot; fi if pgrep -f celery &gt; /dev/null 2&gt;&amp;1; then echo &quot;celery worker is running&quot; else echo &quot;celery worker is not running&quot; fi&#125;set -e. /lib/lsb/init-functionscase &quot;$1&quot; in start) echo &quot;Starting $DESC...&quot; start_service start_worker ;; stop) echo &quot;Stopping $DESC...&quot; stop_service stop_worker ;; restart) echo &quot;Restarting $DESC...&quot; stop_service stop_worker sleep 3 start_service start_worker echo &quot;Checking...&quot; check_status ;; status) check_status ;; *) echo &quot;Usage: $NAME &#123;start|stop|restart|status&#125;&quot; &gt;&amp;2 exit 1 ;;esacexit 0 重点需要关注的是celery multi start的用法，注意start后面跟的是worker的名字（取数据的worker），也可以简单的写3，然后-Q:worker_name queue_name，最后-c是实际的worker（干活的worker）的数目，-Q是给队列指定worker。例子中的语句，意思是启动3个worker，分别命名为writer, caller和default，然后启动3个队列，名字分别是async_writer, async_caller和default，每个worker分配7个进程用来干活。","tags":[{"name":"python","slug":"python","permalink":"http://yiuterran.github.io/tags/python/"},{"name":"celery","slug":"celery","permalink":"http://yiuterran.github.io/tags/celery/"},{"name":"redis","slug":"redis","permalink":"http://yiuterran.github.io/tags/redis/"}]},{"title":"effective java 读书笔记","date":"2017-06-12T15:47:02.000Z","path":"2017/06/12/EffectiveJava/","text":"创建和销毁对象 用静态工厂方法代替构造器。这里的静态工厂方法不是factory mode，而是一种构造器的替代方法。本条款鼓励设计者在构建一个类时，优先考虑使用static factory method。后者有多个优势：更清晰，更简洁，在参数相同时不需要使用boolean或者enum来进行区分，可以通过register——get方法提供工厂特性（子类）。不过，这种方法和普通的静态方法没有任何语法形式的区别，且静态方法不能被继承（C++中virtual与static不能共存）； 当构造参数非常多时，使用构建器(builder)。我们通常会使用默认构造函数，然后用set方法一一设置属性，如果让set返回this，就可以连续使用set，这就是builder。对于具有“具名参数”语法的语言（如python，C#）这种模式就不是很必要了，对于有default value（如C++）语法的语言，这种模式的使用频率也要低一些。 用私有构造器或枚举强化单例属性。这里给出了一个创建单例的建议：创建一个仅包含单元素的枚举类型，由于java语言特性，枚举直接免费提供了序列化、防止多次实例化等功能，因此可以简洁的解决很多问题。 如果一个类不可实例化，应该将其构造器私有化，这种类一般只是提供静态函数（类似C++中的函数） 尽量少创建新对象，而应该多复用已有对象。这条尤其对immuable的对象很重要，例如String。每次使用new时，对应该仔细考虑是否需要创建一个新的对象，而不是复用以前的对象。当然，对于小对象，这个不需要考虑。正如C++中的传值和传址的差别，小对象使用传值反而更好一些，可以避免许多不必要的麻烦。另外，由于autoboxing的存在，基本类型与装箱基本类型之间会相互转化。但是需要记住，要优先使用基本类型。 消除过期的对象引用。这条主要针对“程序员自己管理内存/池化”的情景。在C++中，我们习惯在free or delete之后，将其置0(nullptr)，这样可以避免后续一些莫名其妙的Bug。java是GC机制的，因此一般不需要这么做。但是，如果自己池化了对象管理机制（例如创建某些数据结构时），就要注意这些问题了。本条款给出的建议中，要注意缓存（比如建了一个全局list/map）中过期的东西记得删除。可以使用WeakHashMap自动管理(当内存中没有其引用对象时自动清除），或者LinkedHashMap的removeEldestEntry手动管理（每次添加新元素时）。对于更加复杂的场景，必须使用java.lang.ref^1.此外，注册一个回调方法，但是没有显式取消它，会导致其不断被累积。因此在使用addListener创建函数对象时，请记得removeListener. 避免使用终结器(finalizer）。java使用GC来回收内存，因此终结器的用处不大，更重要的是，终结器的优先级很低，不能保证被及时执行，很容易造成性能bug。比较妥当的是提供显示的终结方法（如close），然后在finally中执行。注意终结方法不应该再抛出异常，而是应该捕获并打印日志。但是用户可能忘记调用显示的终结方法，因此终结器还是可以充当最后的安全保证，当然，这其实是程序不得已使用的方法，应该在日志中使用警告。另外需要注意的是，子类终结器必须显式调用父类的，这点和C++中的自动析构并不一样，请注意。可以考虑使用finalize guard来确保这一点。 object通用方法 equals方法。C++中，重载==操作符限定在同类之间， 其他的要通过类型转换来进行比较，因此存在非常复杂的显式/隐式类型转换。java中，equals方法的参数必须是Object类型，这意味着所有的对象之间都可以判断是否相等。equals方法的设计必须非常谨慎，要严格遵守自反性、对称性、一致性和传递性这几个特征。 自反性，意思是x=x恒成立； 对称性，意味着a=b，必须也要b=a. 但是由于参数是Object，很容易无意识的违反这点。一般判断步骤中，首先需要知道这个Object是不是属于这个类（使用instanceof）,严格认为不属于这个类的对象不可能相等（即使是value意义上的相等）。如果需要value意义上的相等，就写一个显式的类型转换方法。 传递性，意味着a=b, b=c则a=c成立。这条在设计类层次结构时很容易被违反。在多层类均可被实例化时，判断这些类之间的相等性往往会出现混乱。 一致性。即相等的永远都相等，不等的永远都不等。这里注意的是判断时不要依赖不可靠的资源； 非空性。这是额外的一个特性，任何对象在任何情况下都不应该与null相等——这是显然的。但是这一步不需要特别写出来，instanceof会替我们做这些的。除了上面的款项以外，还有一些使用技巧： 如果比较流程复杂，可以先用==判断是否是同一个对象； 在比较时注意npt异常； 短路求值与比较顺序； 覆盖hashcode; hashcode方法。如果覆盖了equals，必须同时覆盖hashcode，这是因为相等的对象必须有相同的hash code. 这意味着我们必须为这个类提供一种hash算法，这个活并不简单，不过一般情况下可以这么做： 选一个非0常数记为result，比如17； 对于equals中涉及的每一个域f(成员变量)，计算其hashcode： boolean -&gt; 1 or 0 byte, short, int -&gt; int(f) long -&gt; int(f^(f&gt;&gt;32)) float -&gt; Float.floatToIntBits(f) double -&gt; Double.doubleToLongBits(f) -&gt; 按着long计算 对象引用：null -&gt; 0，其他：递归调用hashcode方法 数组：把每个对象当作一个单独的域计算hashcode result=$31 * result + \\Sigma_{i=1}^{\\propto}f_i$如果一个域的结果可以通过其他域计算出来，可以不必参与上面的计算过程。如果hash计算非常复杂，可以考虑使用延迟初始化技术。定义一个volatile int hashcode，在对应的method里，先if(hashcode==0)，否则直接返回缓存的结果。 toString方法。同C#一样，一般推荐覆盖这个方法，这样print时，会方便很多。 clone方法。很遗憾，java的clone不好用——很不好用，它的约定太弱。即使类implement了Cloneable接口，你也不能指望什么。最好的方法是别管这个东西，自己实现一个拷贝构造器，或者拷贝工厂。 考虑实现Comparable接口。这个接口唯一声明了compareTo方法，这是一个泛型方法。如果你需要排序，最好事先这个方法——正如C++中的重载&lt;操作符一样，这是泛型容器排序的基础。显然compareTo需要和equals在判断相等时保持一致。比equals简单的是，compareTo的参数只能和自身类型一样，因为在implements泛型类时，填入的具体参数显然就是这个类自身。 类和接口 使类和成员的可访问性最小化。本条和语言无关，所有面向对象设计中，信息隐藏的重要性都是一致的。切记尽量少暴露实现细节，保持对外开放性最小。这可以有效减少软件工程的复杂度。有个细节的技巧：数组不可能是public final的， 因为数组本身是可变的。C++中有个蛋疼的const int* const p的问题，指的就是指针的可变性和内容的可变性问题。此外，java默认访问类型是package private的，这和其他语言有区别。 使用getter,setter代替公有成员变量。这条其实并不是那么严格，至少C++中经常可以看到反例。因为写起来实在太麻烦，所以C#引入了属性这种语法糖。 设计不可变类。省事起见，如果对性能没有特别大的需求尽量设计不可变类，这种类的所有方法都会返回一个new对象，而不是直接修改对象本身。这种类的设计遵从如下原则： 不提供mutator修改对象本身； 保证类不会被继承； 所有域都是不可变的（final）； 所有域都是私有的； 确保对于任何可变组件的互斥访问； 复合优先于继承。这条是面向对象的泛用条款，从略； 要么为继承而设计，要么禁止继承。这条要求在设计一个类时，要明确它是否会被继承。这里强调了一个细节：构造器不可调用可被覆盖的方法。这和C++中构造函数和析构函数不应该调用虚函数本质上是一直的，因为对象是从基类到派生类逐级构造的，如果调用虚函数，动态绑定可能不会生效，从而产生undefined的后果； 接口优先于抽象类。显然，也是泛用条款。对于C++而言，没那么明显（因为没有接口），不过全是纯虚函数的类就是接口… 接口只用于定义类型。是的，只应该有public的method，而不要塞进去一堆常量。后者最好用枚举代替。 类层次优先于标签类。标签类就是在构造函数中传入flag，在方法中switch...case，在C语言中，这是常见的设计。但是在面向对象中，显然更适合使用继承来合理安排类结构。 用函数对象表示策略。由于C++11有了std::function&lt;&gt;和lambda，所以函数对象这种累赘的东西一般是用不上了，但是垂垂老矣的java中，还没有这些东西(java8引入lambda了，谢天谢地），一般是写一个接口，然后用匿名函数实现它。 优先考虑静态成员类。nested class最好设计成静态的，这是为了减少对象的数量——非静态类都必须与一个外围实例关联。nested class可以摆脱友元这种东西的困扰，访问所有的成员方法|变量（某种形式的闭包）。但是静态成员类和对象本身无关，所以就只能访问静态方法和静态成员了。 泛型在C++中，template和oo完全是两种不同的范式，因为C++并没有all is object这种思想，因此没人会觉得vector&lt;basic_string&gt;不是vector&lt;string&gt;的父类有啥问题。java其实也一样，list&lt;string&gt;和list&lt;object&gt;之间也不是继承的关系。泛型使java复杂化，并且失去了优雅。 用泛型，不用原生态类型。java从1.5版本引入泛型，c#从1.2开始，C++则一直都有模板这种东西。没有泛型的语言一般都会引入一些很丑陋的类型转换，比如C中的void *。尽量使用泛型而非原生态的类型，如果需要指代任意类型而不关心具体类型，可以用?比如set&lt;?&gt;；此外，instanceof操作符后面必须跟着原生态类型； 消除unchecked warning，对于编译器的抱怨，要好好检查，如果确定没有问题，就使用@SuppressWarnings(&quot;unchecked&quot;)关闭这个提醒，受检警告仅存在在语言层面，并非是jvm虚拟机的特性； 优先使用List而不是Array。在C++中，array本质上是一个指针，因此效率比std::vector&lt;&gt;要高上不少；java中Array也比list&lt;&gt;要快一些，但是却更推荐使用后者。java的泛型在运行时其元素类型是被擦除(erase^2)的，这点和C++完全不同（为了历史兼容性做出的妥协）。因此数组是运行时安全但编译时不安全的，泛型则相反。最后，最好不要同时使用泛型和数组，这会让你蛋疼无比——如果真的需要泛型数组，必须同时使用强制类型转换和SuppressWarnings技术。 优先考虑泛型和泛型方法。 使用set&lt;? extends Object&gt; or set&lt;? super String&gt;这种技巧来完成某些动作。助记符是__PECS__,就是说，把这个对象当生产者使用时，用extends，反之，用super。在返回的时候，仍然使用普通类型，而不是通配符。本条对于类库编写者比较重要。 优先使用类型安全的异构容器。本条通过一些奇技淫巧完成一个容器里面同时存放多种类型(异构，通过class&lt;?&gt;实现)，但是又能保证类型安全(通过type.cast实现)这一目标。 枚举与注解java的枚举有点难用，不如C#那么强大，也不如C/C++那么简洁。简单来说，每一个枚举值都是该类（枚举）的一个实例，相当于一种工厂方法，因此枚举对象可以直接调用枚举类的方法。 枚举的所有域都应该是私有final的（需要的时候提供公有的访问函数）；可以通过values方法访问所有的枚举值（依照声明顺序）。对于每一个枚举值在后面加上&#123;&#125;，里面是特定于常量的方法实现，可以通过在枚举类中声明一个抽象方法，在常量中再进行覆盖来实现对不同枚举值的特殊操作（switch(this)这种方法更适用于控制外部传入的不可控的变量的方法中）。如果在枚举值后面加上初始化表达式，调用该常量时会自动使用该表达式调用构造函数（但是显然我们不能直接调用构造器），比如MONDAY(&quot;mon&quot;)这种.PS: 这里给了一个有趣的技巧：使用%n保证换行符的跨平台性，有些类似python中的os.linesep. 如果不给枚举赋值，默认使用序列（0，1，2…），可以使用ordinal方法取得该序列的int值。当然，最好别依赖于这种自动生成的东西，而是明确赋值… 用EnumSet代替位域，主要使用EnumSet.of创建枚举set，用来取代依靠位运算得出的集合特性。不过，这种方法只是可读性好一些，如果需要做存储或者与提供API，还是希望使用int。 用EnumMap代替序数索引。可以将一个enum直接传入EnumMap&lt;enum,Object&gt;中，enum的所有常量值都会转化为EnumMap的key，这其实就是普通的map，但是做了优化。 枚举不是可扩展的，但是我们可以使用接口来变相实现这种可扩展性。简单来说，就是枚举实现接口，然后在需要的时候，使用接口来声明枚举而不是相反。 注解优先于命名模式。注解的声明需要导入java.lang.annotation.*，然后使用元注解来标明该注解的属性。例如@Retention, @Target，注解类的必须是@interface类型。如:123public @interface Test&#123; Class&lt;? extend Exception&gt;[] value();&#125; 使用时：1234@Test(&#123;IndexOutOfBoundException.class, NullPointerException.class&#125;)public static void example()&#123;&#x2F;&#x2F;...&#125; 测试时:12345678910if(m.isAnnotationPresent(Test.class)&#123; test++; try&#123; m.invoke(null); &#125;catch(Throwable wrappedExc)&#123; Throwable exc &#x3D; wrappedExc.getCause(); Class&lt;? extends Excetption&gt;[] excTypes&#x3D; m.getAnnotation(Test.class).value(); &#125;... 注解并不会改变代码原本的含义（和python的装饰器完全不同），但是可以使对象经过某些工具的特殊处理（用于反射）。显然一般程序员是不需要自定义注解类型的，除了某些设计工具平台的人以外。 坚持使用Override注解。这是一种良好的变成习惯，不再赘述。 用标记接口定义类型。标记接口很罕见，最常见的是Serializable，它只是一个接口，并没有规定任意方法。换言之，这只是一个空接口。 方法 检查参数的有效性。即防御性编程，对于公有方法，应该在Javadoc中使用@throws标明在违反约定时会抛出什么异常；对于非导出方法，设计者自己知道会传入什么参数，因此应该使用assert来进行错误检测。 必要时使用保护性拷贝。java的对象本质上都是c++中的指针或引用，因此如果对象本身是可变的，即使参数是不可变的，也可能因为某些意外导致对象被修改。比较简单的方法是使用深拷贝（值拷贝）摆脱这种引用的关系，这在C++中是比较明显的：传值还是传址的问题，但是java中如果不留意很容易忘掉这一点。 谨慎设计方法签名。本条款说了一些设计方法的技巧和忌讳，包括： 命名要谨慎 尽量保持接口最小，而不是提供很多快捷方式 避免过长的参数列表（4个以下） 如果上述条款不可避免，使用builder（参见前文） 参数类型优先使用接口 flag尽量使用enum而不是boolean 慎用重载。有个原则是：永远不要导出两个具有相同参数数目的重载方法。如果方法使用可变参数，那么尽量不要重载它。如果违反上述两条规定，干脆给方法起不同的名字（如同在C语言中那样）。 慎用可变参数。和其他语言一样，可变参数为printf而生，但是实际上自己需要写的并不多，大部分情况下传入一个列表或者使用泛型可以解决应用问题。可变参数本身有一定的性能约束：传入可变参数隐式创建并初始化了一个数组。 返回0长度的数组或集合，而不是null。这是一条设计上的经验，在非C语言环境下，返回null往往得不偿失——需要单独写语句进行分析，而不能直接迭代。如果担心性能问题，可以使用Collections.emptyList()等方法返回不可变的空集，如果是数组，可以自己创建一个不可变的static final成员变量。 为所有的导出API写文档注释。尤其是在替别人写类库的时候，这条非常重要。必须明确标注哪些是可能会改变的，哪些是兼容的。 通用程序设计 使局部变量的作用域最小化。这点和C++、C#一致，C语言则是习惯把所有变量声明放在最前面（因为C只有基本数据和结构，且一般更习惯使用指针），python则不需要声明。 for-each优先于for。同所有语言一致，C++11中引入类似语法，C#和python用in关键字. 但是for-each是不能修改容器本身的，因此在必须要的时候还是要使用for。 了解和使用类库。应该熟悉java.lang和java.util中的内容。 不要使用float和double进行精确计算。如果需要精确的小数计算，应该使用BigDecimal，或者自己处理小数点，用int或long。 基本类型优先于装箱类型。由于装箱类型表示对象，因此用==判断两者之间的相等性总是错误的。当混合两者运算时，装箱类型就会自动拆箱。尽可能使用基本类型以避免不停的装箱、拆箱造成的性能损失。在如下场合必须使用装箱类型： 集合的key和value； 泛型的参数； 进行反射方法调用时； 如果其他类型更适合，不要使用字符串。例如，不要用”True”来代替true这种。 字符串连接问题。使用StringBuilder代替String，提高性能。 通过接口引用对象。这样更加灵活，但是必要的时候你可能需要进行类型转换。如果是基于类的框架，则使用基类更加合适。 接口优先于反射。反射的性能实际上是很差的，但是在必要的时候会非常有用。其中Class a=Class.forname(&quot;xxx&quot;)，然后使用a.newInstance()这种方法比较常见。 谨慎的使用native method. JNI允许java调用C/C++来访问特定的基于平台的sdk接口。但是，如果仅仅为了提高性能，并不提倡非要使用这种技术。 谨慎优化。写出好的程序，如果存在性能问题，则使用性能分析工具去分析它，再针对瓶颈进行优化。 遵守命名习惯。java的命名习惯和C#基本一致（而python和C++基本一致），java不喜欢下划线，而C++不喜欢驼峰。当然，一般常量还是都用全大写中间用下划线的表示方式。 异常java的异常分为checked和unchecked两类，后者是RuntimeExcception或者Error的子类，如果程序抛出这种异常，可以不加以捕获而编译通过。通常情况下，应该使用标准异常。且，只在真正的异常情况下使用异常。 并发 synchronized和volatile关键字的使用。前者类似C#中的lock，后者意思同C。C语言中虽然没有线程，但是有中断和信号。 避免过度同步。如果需要并发集合，那就使用语言内置的并发集合，而不要自己使用synchronized关键字加锁。CopyOnWriteArrayList是一种写时复制的并发容器，类似ConcurrentArrayList。如果类库使用者可以外部同步，那么设计类的时候就不要设计成内部同步的（这是C++的设计原则之一——效率最高）。如果修改了静态域，由于外部用户无法自己加锁，因此类的内部必须加锁。尽量不要从同步区域内部调用外来方法。 executor和task优先于线程。这点类似于C#，尽量不要使用抽象程度较低的线程，而是更加漂亮简洁的其他高级类。在java.lang.concurrent里包含了已经封装好的比较通用的线程模型，尽量使用它们而不是自己去写。 并发工具优先于wait和notify。类似上一条，优先使用高级工具。 慎用延迟初始化。本条目给出了几个好的建议： 正常初始化优先于延迟初始化； 使用同步方法； 如果需要性能优化，静态域延迟初始化使用一个static class作为holder，这样在第一次访问这个静态类时，所需要的域才会被初始化； 如果需要性能优化，实例域延迟初始化最好使用双重检查模式。这时候域必须被声明为volatile的，而且习惯上使用一个局部变量来优化对域的检查。 不要使用Thread.yield，直接用Thread.sleep(1)就好。java的线程调度器不可靠，不要使用线程优先级来调度。 不要使用java线程组，这个技术已经过时了… 序列化所谓序列化，指的是将一个对象编码成字节流，一般用来持久化。 谨慎实现Serializable接口。","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"base","slug":"base","permalink":"http://yiuterran.github.io/tags/base/"}]},{"title":"java并发编程实战读书笔记","date":"2017-06-12T15:46:57.000Z","path":"2017/06/12/java并发编程实战读书笔记/","text":"并发编程实际上极其复杂，有很多绝对值得去看的建议。 不要在构造器里面调用可变函数（虚函数），这是所谓的安全构造需求； 最简单的线程安全类是不可变类，不可变类有如下硬性要求： 对象创建以后就不能修改 对象所有域都是final的 对象是安全构造的 所谓可见性指的是a线程修改了变量，b线程可以知道这种修改；所谓原子性指的是a线程在修改变量时，b线程不会干扰这种修改； 所谓安全发布，必须满足以下条件之一： 在静态初始化函数中初始化一个对象引用 将对象的引用保存到volatile类型或者AtomicReferance对象之中 将对象的应用保存到某个正确构造对象的final域中 将对象引用保存到一个由锁保护的域中 volatile变量只能保证可见性，无法保证原子性；加锁则都可以保证（但是会繁琐一些）。 不要在构造器中调用新的线程，这会导致不安全发布；正确的做法是使用静态工厂函数，构造完毕后再启动线程（或者做其他发布）； 最简单维持线程安全的方法是使用局部变量（栈封闭），其次是使用原子类，包括现场本地存储类ThreadLocal&lt;&gt; 大多数情况下，我们无须直接使用Thread这种基础类，java提供了很多适用范围广泛的组件，包括： 并发容器类，使用java.util.concurrent中定义的包括ConcurrentHashMap, CopyOnWriteArrayList，ConcurrentLinkedQueue和BlockingQueue（BlockingDeque),以及ConcurrentSkipListMap和ConcurrentSkipListSet（作为SortedMap和SortedSet的替代品）.BlockingQueue在take和put时，如果没有元素/空间就会阻塞； 如果线程被中断，会抛出InterruptedException如果是Runnable的对象，是不可以直接抛出这个异常的，必须捕获并使用Thread.currentThread().interrupt()恢复中断；其他类型的对象倒是无所谓，可以直接抛出或者捕获清理后重新抛出； 闭锁。CountDownLatch可以用来等待计数，FutureTask是一种Callable，可以通过get来获得结果（或者阻塞），Semaphore用来对资源进行限制计数，可以用来实现资源池，使用acquire获得一个资源，使用release释放一个资源，Barrier用来实现分段任务，当所有任务都到达Barrier时，任务继续，否则抛出BrokenBarrierException异常。本章给出了一个缓存的例子。 Executor框架。Executor是一个接口，只规定了execute一个接口（其参数是一个Runnable class）；Executors包含生产线程池的几个静态方法，如newFixedThreadPool（固定大小），newCachedThreadPool（无限增长）和newSingleThreadExecutor（单线程串行）,和newScheduledThreadPool（定时执行）。如果这些都不能满足需求，可以直接使用ThreadPoolExecutor自己灵活构造线程池 ExecutorService接口在Executor接口的基础上增加了生命周期，可以使用shutdown，shutdownNow，awaitTermination等方法进行生命周期（运行、关闭和已终止）控制和感知。 ExecutorService的submit方法用于提交一个任务并返回一个Future，使用这个结果可以控制任务的生命周期； 线程的超时：一般可以用重载的get，await等方法指定超时时间； 线程的取消：习惯上使用一个volatile变量作为取消标志，但是如果线程阻塞了，这个方法就不好用了。最佳方式是使用中断(Future.cancel)，注意需要处理好相关的异常； 可以通过继承Thread重载interrupt方法来将中断处理封闭在异常类中；可以通过使用ThreadPoolExecutor中的newTaskFor静态方法由Callable生产RunnableFuture","tags":[{"name":"java","slug":"java","permalink":"http://yiuterran.github.io/tags/java/"},{"name":"base","slug":"base","permalink":"http://yiuterran.github.io/tags/base/"},{"name":"concurrent","slug":"concurrent","permalink":"http://yiuterran.github.io/tags/concurrent/"}]},{"title":"重拾Haskell","date":"2017-06-12T15:46:39.000Z","path":"2017/06/12/重拾Haskell/","text":"我打算学习但是最终没能完全理解的语言大概有三门：因为复杂性而放弃的Scala和Rust，因为难以理解而放弃的Haskell. 学习过C++以后，我对太过复杂的语言一项是敬而远之的，这一点暂时不会有变化，以后在工作中如果遇到必须使用Scala的时候我还是会认真学习。但是对于Haskell还是有些不甘心。虽然这是一门号称不看论文很难理解的语言，我还是想尽力学习一下。 Haskell相对于其他语言，变化的速度非常快，现在最新的平台是stack，连Haskell Platform也过时了（有种web前端的感觉），不过其核心理念还是比较稳定的，以前从Haskell趣学指南中学习的东西，现在也大多还能用。 在ubuntu中添加官方PPA, sudo apt-get install stack以后，使用stack setup安装环境，使用stack ghci打开交互式环境，然后就可以愉悦的学习了。目前最的版本是ghc-8.0.1； 优化显示默认的stack使用起来不是很方便，有些地方可以优化一二。首先编辑~/.stack/config.yaml，删掉空白的&#123;&#125;，加入以下内容： 1234567891011templates: params: author-email: yaotairan@gmail.com author-name: tryao category: Personal copyright: &#x27;Copyright (c) TairanYao&#x27; github-username: YiuTerranpackage-indices:- name: Tsinghua download-prefix: http://mirrors.tuna.tsinghua.edu.cn/hackage/package/ http: http://mirrors.tuna.tsinghua.edu.cn/hackage/00-index.tar.gz 上面的email和名字之类的需要换成自己的，后面加了清华的源，加快cabal的下载速度。 编辑~/.ghci加入以下内容： 123456789101112import qualified IPPrintimport qualified Language.Haskell.HsColour as HsColourimport qualified Language.Haskell.HsColour.Colourise as HsColourimport qualified Language.Haskell.HsColour.Output as HsColourlet myColourPrefs = HsColour.defaultColourPrefs &#123; HsColour.conid = [HsColour.Foreground HsColour.Yellow, HsColour.Bold], HsColour.conop = [HsColour.Foreground HsColour.Yellow], HsColour.string = [HsColour.Foreground HsColour.Green], HsColour.char = [HsColour.Foreground HsColour.Cyan], HsColour.number = [HsColour.Foreground HsColour.Red, HsColour.Bold], HsColour.layout = [HsColour.Foreground HsColour.White], HsColour.keyglyph = [HsColour.Foreground HsColour.White] &#125;let myPrint = putStrLn . HsColour.hscolour (HsColour.TTYg HsColour.XTerm256Compatible) myColourPrefs False False &quot;&quot; False . IPPrint.pshow:set -interactive-print=myPrint:set -XNoMonomorphismRestriction:set prompt &quot;λ &quot; 然后在shell里运行： 12sudo apt-get install libbz2-devstack install ipprint hscolour 执行stack安装依赖时，可能会报错，根据提示修正即可.这是给ghci添加语法高亮. 最后，如果用zsh的话， 可以打开stack插件，方便自动完成. 也可以alias ghci=&#39;stack ghci&#39;. 另外，最好把~/.local/bin加到PATH里面去. 基础仍然从《Haskell趣学指南指南》这本书开始是比较合适的，虽然内容有些过时，但是基础部分变动应该不大。上次看这本书的时候我还不会python呢，如今js我也驾轻就熟了，看起来应该简单很多了。完成后开始看《Real World Haskell》，后者相关习题的个人解答：https://github.com/YiuTerran/rwh-exercise 语法基本语法大体和普通语言（C系）相似，除了： 不等于符号是 /=，和数学中的$\\neq$长的很像 not和python里面一样，但是&amp;&amp;, ||和C语言一样 函数调用使用空格，且具有最高优先级 括号用来保持更高的优先级 if..then..else句式中，else是不可省略的，类似python中的单句if..else 函数不允许首字母大写，按规定，所有首字母大写的都是类型或者类型类 由于允许操作符重载（自定义），很多符号的定义在不同的包里有不同的意思。如Data.Ratio里面有一堆分数相关的操作，Data.Bits里面则定义了很多位操作 操作符重载只是一种C++的描述，其实在这里是一种函数（当然在ghci中，使用let定义变量，在脚本中直接赋值即可，变量可以看作是没有参数的函数（名字）。 list list和python中的形式大体一致，除了一点：所有元素的类型必须相同。 将两个列表合并使用++(效率较低）,使用:将元素插入队首，本质上[1, 2, 3]就是1: 2: 3: [] 使用!!取下标，越界会报错 list中的list也必须是同样元素类别（但是不关心长度） head返回头部（car)，tail返回尾部(cdr)，last返回最后一个元素，init返回除了最后一个元素的列表 对空的list，以上函数都会报错 Haskell的string就是[Char] 使用length函数返回list的长度 使用null函数检测是否为空 使用reverse函数进行反转 使用take函数取出队首任意多个元素，超过长度也不会报错，只是返回所有 使用 drop删除队首任意多个元素 使用maximum和minimum求出队列中的极值 使用sum和product求出队列的和,积 使用elem判断是否是元素，一般用中缀形式表达（类似python中的in） range生成使用..，例如[1..20]， step可以在第二个元素中指定，如[10,8..0];字母也可以用；但是不要用浮点数；由于惰性的原因，可以是无限长的range; repeat函数用于生成重复序列，类似python中的* 大名鼎鼎的list comprehesion,和python中类似，不同的是形式更加数学化。比如生成1到10的平方，在python中是[k^2 for k in range(1, 10)]，在hs中则是[k^2 | k &lt;- [1..10]]，感觉有点像高中数学吧，哈。后面的条件用逗号隔开表示&amp;&amp; tuple 仍然类似python中的tuple，但是：不允许有仅含有一个元素的tuple 在模式匹配中被大量使用 tuple的大小是不可改变的，但是类型可以不同 fst, snd分别返回tuple的第一项和第二项，显然仅对pair（二元组）有效； zip用于使list组成tuple对，类似python map也类似python types 类型推导最强的语言，显式类型声明::，如a :: Char 在ghci中使用:t判断类型，使用:info查看具体相关 类型的首字母必须大写 Int是有限的，Integer是无限的 类型无关的时候，使用小写字母代替，比如[a]表示任意元素组成的list typeclass是预定义的类型接口，比如可以相等的类型，必定是Eq的一个实现 类型约束=&gt;，类似于接口中的where，可以是任意类型，但必须满足。例如 (Eq a)=&gt; a -&gt; a function对于Haskell的纯函数而言，其主要书写格式就是大名鼎鼎的模式匹配，Rust也学习了这套语法。模式匹配其实是将数学按照构造函数进行拆分，能够这么干的主要原因是Haskell是纯函数式语言，没有副作用，变量被赋值后不能够再次修改。 最好自己写上函数的签名，方便在编译期查错 对于函数来说，从上到下匹配，允许递归 对于switch...case类型的句子，使用Guard(|)，如果条件需要计算，在后面使用where（允许多个变量，但是要垂直隔开） 也可以使用let..in表示中某个作用域中的变量声明 let是一个表达式，而where是一个语法结构，表达式（类似if..then..else）可以放在各种位置 除了这些以外，case表达式本身也存在，其语法结构是case xx of x -&gt; ...，模式匹配本质上都是这个表达式的语法糖 使用_可以匹配任意情况 除了纯函数外，Haskell也有有副作用的函数比如IO，这种函数的书写格式更类似普通命令式语言。 函数的基本形式是a-&gt;b-&gt;c，箭头连接各个参数，由于函数是柯里化的，所以也可以看做a-&gt;(b-&gt;c)，每个部分是一个偏函数，整个被称为全函数。如果函数不返回任何东西（在某些语言中被称为过程），这个函数肯定是非纯函数，一般返回()【读作unit】，如IO () lambdalambda表达式本来就源自FP(lisp)，所以很自然的：\\xs -&gt; length xs，不过haskell中用lambda比其他语言应该少很多。 常用的一些函数：fold, fold1, foldr, scan家族类似$ 符号同样也可以调用函数，但是与空格不同，他具有最低优先级，主要用来减少括号的数量；.符号表示右结合的函数，即先算最右边的，然后依次应用左边的函数，右边函数的返回值是左边函数的参数；上面两个符号主要用来做函数组合，简化书写。。 模块熟悉的import语句，不过和python的语法不太像，倒是有点像java. import Data.List 会导入该模块下的所有函数； import Data.List (nub, sort)仅导入两个函数 import Data.list hiding (nub) 导入除了nub之外的所有函数 import qualified Data.Map 导入所有函数，但是如果和已加载模块冲突的话，必须使用全引用 可以在后面加上as x做别名 自定义结构关键字： data和其他语言不一样，标准格式很奇怪 12data BookInfo = Book Int String [String] deriving (Show) BookInfo就是类型的名字（类型构造器），Book是值构造器的名字，后面是成员；两者名字可以一致； 这样访问属性还要写专门的函数（模式匹配），很蛋疼，所以有个惯用法（标准称呼是记录）： 12345data BookInfo = BookInfo &#123; price :: Int, author :: String, buyer :: [String]&#125; deriving (show) 这些成员当然也可以是函数。 递归定义也是很常见的，比如一个二叉树： 1data Tree a = Node a (Node a) (Node a) 这里a是类型参数。 关键字type类似C++中的typedef，用于定义类型的别名。 此外newtype也可以自定结构，不过有很多约束。newtype关键字给现有类型一个不同的身份，因此只能有一个值构造器，并且这个构造器只能有一个字段。 由data关键字创建的类型在运行时有一个记录开销，如记录某个值是用哪个构造器创建的。而newtype只有一个构造器，所以不需要这个额外开销。这使得它在运行时更省时间和空间。由newtype的构造器只在编译时使用，运行时甚至不存在。 typeclass就是其他语言中的类型类/接口/模板，语法是 12class BasicEq a where isEqual:: a -&gt; a -&gt; Bool 实例是 1234instance BasicEq bool where isEqual True True = True isEqual False False = True isEqual _ _ = False 常见的Typeclass包括Eq, Ord(可比较), Show(可以转换为字符串), Read可以被String转换(可以用::显式指定类型)，Enum（可以被迭代)，Bounded(有上下限），Num(有数字特征，必须实现Eq和Show)，Integral, Floating fromIntegral可以将整数转换成浮点数（根据后续操作转换） 默认情况下，Haskell不支持模板特化（重载）。可以通过语言扩展FlexibleInstances取消这个限制。 扩展OverlappingInstances可以允许重叠实例。 在文件最前面加上&#123;-# LANGUAGE TypeSynonymInstances, OverlappingInstances #-&#125;即可打开编译器扩展； 在RWH上面提到了单一同态错误问题，经过我的测试，在最新的(8.0.1)的GHC中这个问题已经不存在了； 同C++的模板一样，允许多参数类型类（MultiParamTypeClasses），多参数之间可以定义条件约束表明多个参数之间的关系 多参数类型类比较复杂，谨慎使用 错误使用 error 函数输出错误避免抛出错误，使用Maybe, Just和Nothing 缩进 Haskell 依据缩进来解析代码块。这种用排版来表达逻辑结构的方式通常被称作缩进规则。在源码文件开始的那一行，首个顶级声明或者定义可以从该行的任意一列开始，Haskell 编译器或解释器将记住这个缩进级别，并且随后出现的所有顶级声明也必须使用相同的缩进。let 表达式和 where 从句的规则与此类似。一旦 Haskell 编译器或解释器遇到一个 let 或 where 关键字，就会记住接下来第一个标记（token）的缩进位置。然后如果紧跟着的行是空白行或向右缩进更深，则被视作是前一行的延续。而如果其缩进和前一行相同，则被视作是同一区块内的新的一行。 也可以使用显式语法结构（使用花括弧代替缩进），不过一般不这么做 节节其实是高阶函数的一种形式（语法糖），如 12test = (+2)// test 3 = 5 As模式 模式 xs@(_:xs&#39;) 被称为 as-模式，它的意思是：如果输入值能匹配 @ 符号右边的模式（这里是 (_:xs&#39;) ），那么就将这个值绑定到 @ 符号左边的变量中（这里是 xs ）。 除了增强可读性外，可以简化代码，减少内存分配 折叠 foldl，接受一个初始值，一个步进函数，对一个列表进行迭代求职，显然sum = foldl (+) 0 foldr，格式同上，从右侧开始折叠。 一种思考 foldr 的方式是，将它看成是对输入列表的一种转换（transform）：它的第一个参数决定了该怎么处理列表的 head 和 tail 部分；而它的第二个参数则决定了，当遇到空列表时，该用什么值来代替这个空列表。 千万不要把 foldl 用在实际使用中，这是因为会发生内存泄露（因为惰性求值的关系 真正的情况使用的是foldl&#39;，foldr&#39; (Data.List) foldl的步进函数格式是 step acc x, foldr的则是step x acc，对于list (x:xs)而言，从左折叠第一个元素是x，从右折叠第一个元素是[]； modulemodule的规定类似java，名字必须和文件名一致，首字母必须大写； 123module SimpleJSON( Xxxx, //导出部分，如果省略则全部导出) where 显然入口模块应该是Main.hs build单文件可以用runghc命令运行，相当于脚本；也可以在ghci里面:l外部文件进行测试；编译则需要使用stack ghc命令； IO IO是有副作用的（非幂等的），因此Haskell中的IO和非IO函数一般严格分开。 IO动作可以被创建，赋值和传递到任何地方，但是仅能在另一个IO动作里被执行 &lt;-运算符从I/O中抽出结果并保存到一个变量中 当有多个动作时，使用do引入代码块 在do中，使用命令式语言的语法完成一系列操作（赋值用let） do 代码块中的每一个声明，除了 let ，都要产生一个I/O操作，这个操作在将来被执行（惰性） IO相关函数被定义在System.IO中 return的作用和&lt;-相反，将一个纯值包装进IO，可以把IO想象成一个流。return入流后，将来可以通过-&gt;取出来赋值； 除了普通IO以外，haskell还有自己特色的惰性IO，hGetContents就是惰性的 除了openFile和hClose外，使用readFile也可以，同时可以避免忘记关掉hClose的问题 对于指定的模式，比如打开文件流，做一些变化，再输出到流，可以用interact IO与普通函数的联系通过Monad实现，或者说IO是一种Monad 命名习惯： mapM返回一个IO动作，mapM_完成IO，但是不返回任何值，M的后缀表示Monad map不能执行操作（纯函数），这就是mapM存在的意义 forM意思与mapM相反，第一个参数是列表，第二个是动作，存在的意义是更干净的代码 do代码块实际上是把操作连接在一起的快捷记号，可以用&gt;&gt;和&gt;&gt;=代替 &gt;&gt; 运算符把两个操作串联在一起：第一个操作先运行，然后是第二个，整个计算的结果是最后运算的结果 &gt;&gt;= 运算符运行一个操作，然后把它的结果传递给一个返回操作的函数。类似linux 管道操作 类似地，还有=&lt;&lt;运算符，将右边的动作传递给左边 换句话说，do块的最后一个操作的值就是整个do的值。如果以return结尾，返回一个Monad，比如整个函数的返回值是IO()，最后多半就是以return结尾。这种函数的返回值只能在另一个Monad函数中重新读出，不能直接用于任何操作。 Haskell中的纯代码不能运行那些能触发副作用的命令。纯函数不能修改全局变量，请求I/O，或者运行一条关闭系统的命令 技巧 默认的String类型速度堪忧，可以用bytestring库代替。Data.ByteString和Data.ByteString.Lazy分别代表了惰性和普通模式的情况； 不要在类型定义上加类型约束，在需要它们的函数上加； 数据结构除了List和Tuple, Haskell自带了其他的一些常见的数据结构； 字典 关联列表也可以当作字典用，但是效率比较低。使用lookup可以在关联列表中查询数据； Data.Map，不同于大部分语言，这个Map是用平衡二叉树实现的，而不是哈希表。这和haskell的不可变性有关； 常用函数：fromList(通过关联列表转换)，insert（插入新值返回新的Map） 虽然是二叉树实现的，这个Map仍然是无序的（有点奇怪） 通用序列Data.Sequence提供了比默认list更好的效率 使用fromList创建，或者用empty和singleton函数创建 使用|&gt;, &lt;|和&gt;&lt; 添加元素，箭头指向被添加的元素 使用Foldable.toList将Sequence转回list Functor（函子）对于一个递归的数据结构，对于应用于其上的函数也很可能是同构递归的。书中的例子是将一棵字符串树转变为包含字符串长度的树，也就是说，树的结构不变，但是元素变成长度： 123treeLengths:: Tree -&gt; TreetreeLengths (Leaf s) = Leaf (treeLengths s)treeLengths (Node l r) = Node (treeLengths l) (treeLengths r) 这种能够同构映射的，满足类型类Functor，映射函数即fmap： 12class Functor f where fmap :: (a -&gt; b) -&gt; f a -&gt; f b Functor是非常重要的一类class，有几个基本原则进行约束。首先，fmap id必须返回相同的值，其次，Functor必须是可组合的，换句话说，fmap a . fmap b == fmap (a . b)应该成立。 编译器不会检查这些规则，程序员需要自己保证这些规则成立。这些规则是函子在范畴论中的数学约束。 幺半群在范畴论中，有一类简单的抽象结构被称为幺半群。许多数学结构都是幺半群，因为成为幺半群的要求非常低。 一个结构只要满足两个性质便可称为幺半群： 一个满足结合律的二元操作符。我们称之为 (*)：表达式 a * (b * c) 和 (a * b) * c 结果必须相同。 一个单位元素。我们称之为 e，它必须遵守两条法则：a * e == a 和 e * a == a。 即： 123class Monoid a where mempty :: a -- the identity mappend :: a -&gt; a -&gt; a -- associative binary operator 如果我们真的需要在同一个类型上实现多个 Monoid 实例，我们可以用 newtype 创建不同的类型来达到目的。 MonadsMonad（单子）是Haskell最难理解的东西之一，这个概念和上文中的幺半群有关，这里有一些辅助理解的漫画。 一个Monad由以下几个构造元素： 一个类型构造器 m 一个用于把某个函数的输出串联到另外一个函数输入上的函数，它的类型是 m a -&gt; (a -&gt; m b) -&gt; m b 一个类型为 a -&gt; m a 的函数，它把普通值注入到调用链里面，也就是说，它把类型 a 用类型构造器 m 包装起来。 标准的monad定义为： 12345class Monad m where -- chain (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b -- inject return :: a -&gt; m a 显然&gt;&gt;=就是串联函数，return是注入函数（IO monad就是把普通值放入IO），类型构造器就是m本身。除此之外，还有&gt;&gt;函数用户忽略返回值的过程（即按步骤一步步来），以及fail函数接受一个错误消息让整个调用链失败（默认使用error函数）。 下面是具体的解析： 如漫画里所述，单子、函子、态射都是对普通值一种包装(context)，由于haskell里值是不可变的，所以都可以重新用构造器进行匹配解析。 对于函子，是这样一种类型类（接口），存在fmap函数，可以让让普通函数与该类型类的实例进行运算，最简单的来讲fmap (+3) (Just 5)应该是Just 8；函子的中缀形式是&lt;$&gt;； 对于普通的函子，fmap仅能将函数应用于被包装的数据。对于Applicative这种，则可以将函数应用于被包装的函数。import Control.Applicative以后，可以使用(Just (+3)) &lt;*&gt; (Just (+5))，这将会生成一个Just (+8)的函数；这是因为函数也可以是函子的实例。因为函子的约束只有可以应用fmap这一个而已. 单子与上面的两个函子很类似，单子主要定义了&gt;&gt;=（bind）和return这两个函数，前者用于连接包装值和接受普通值作为参数的函数，该函数返回一个包装值。换句话说，Monad定义了一种行为，如何将包装值分解为普通值行为，最后再返回包装值。也就是M a -&gt; (a -&gt; M b) -&gt; M b. 单子的return其实就是将任意普通值包装起来； 有了上面两个性质，Monad就可以类似管道一样将普通函数串接起来使用了； Monad class里面没有提供任何函数可以使一个monadic的值还原成一个普通值，这需要写代码的人自己定义。 我们经常需要将数据从Monad中取出来，然后使用纯函数进行计算，最后再用原来的类型构造器重新包围这个计算的结果,这种需求被称为lifting.对于Monad而言，已经定义了&gt;&gt;=和return，所以很容易得出： 123liftM :: (Monad m) =&gt; (a -&gt; b) -&gt; m a -&gt; m bliftM f m = m &gt;&gt;= \\i -&gt; return (f i) 该函数被定义在Control.Monad中。比如我们要计算Just (1 + 3)，就可以用 12-- Just 4( 1 + ) `liftM` (Just 3) 这与 Just 3 &gt;&gt;= \\x -&gt; Just (x+1)等价。 另外，从函子的角度，这个也可以写作(1+) &lt;$&gt; (Just 3) 如果函数f有多余一个参数，Control.Monad中也有对应的liftM2~`liftM5` 在Control.Monad中定义ap函数，其签名为：ap :: Monad m =&gt; m (a -&gt; b) -&gt; m a -&gt; m b解读一下：第一个参数是一个被Monad包装的函数，第二个参数是一个普通的Monad值，这个值的类型与第一个参数中被包装的函数的参数相同（很拗口）。我们知道标准库总只定义了几个常见的liftM，如果我们需要大量链式调用，除了&lt;*&gt;外，还可以组合liftM和ap. 举个例子，定义 12fee :: Int -&gt; Int -&gt; Intfee a b = a + b 那么 liftM fee的类型为： 1Monad m =&gt; m Int -&gt; m (Int -&gt; Int) 显然这个函数的返回值满足ap的参数需求， 所以以下两个表达式相等： 123fee &#96;liftM&#96; (Just 1) &#96;ap&#96; (Just 1)fee &#96;liftM&#96; (Just 1) &lt;*&gt; (Just 1)liftM2 fee (Just 1) (Just 1) join函数也很常用： 12join :: Monad m =&gt; m (m a) -&gt; m ajoin x = x &gt;&gt;= id 用来移除一层Monad，join (Just (Just a))就是Just a Monad的三个约束（数学意义上），类似Functor，Monad也有一些潜在的约束： return x &gt;&gt;= f == f x m &gt;&gt;= return == m m &gt;&gt;= (\\x -&gt; f x &gt;&gt;= g) === (m &gt;&gt;= f) &gt;&gt;= g 第三条是结合律，如果我们把一个大的action分解成一系列的子action，只要我们保证子action的顺序，把哪些子action提取出来组合成一个新action对求值结果是没有影响的。 Control.Monad里面定义了MonadPlus，这其实是短路求值。 123456789101112class Monad m =&gt; MonadPlus m where mzero :: m a mplus :: m a -&gt; m a -&gt; m ainstance MonadPlus [] where mzero = [] mplus = (++)instance MonadPlus Maybe where mzero = Nothing Nothing `mplus` ys = ys xs `mplus` _ = xs 在Control.Monad中定义了标准函数guard： 123guard :: (MonadPlus m) =&gt; Bool -&gt; m()guard True = return ()guard False = mzero 在Control.Arrow中定义了函数first和second用于将普通函数应用到Pair中去 Monad变换器Monad变换器主要用来修改已经存在的Monad，以T结尾。大量Monad变换器进行叠加，就可以得到拥有多种功能的Monad. 错误处理讨论一些常用的haskell处理方式：Maybe, Either和Exception，一般都使用Monad配合。 再往后就是一些实际使用的例子了。","tags":[{"name":"FP","slug":"FP","permalink":"http://yiuterran.github.io/tags/FP/"},{"name":"Haskell","slug":"Haskell","permalink":"http://yiuterran.github.io/tags/Haskell/"}]},{"title":"Heka源码解析","date":"2016-05-29T06:29:20.000Z","path":"2016/05/29/Heka源码解析/","text":"Heka是目前我需要在工作中使用的唯一Go语言项目，出于对Golang的好感，我觉得仔细学习以下Heka的源码。如果力所能及的话，也可以为代码做出一些贡献。 先看最外层的文件目录结构(0.11.0dev): 123456789101112131415161718192021222324252627282930313233343536$ tree -L 1 -av --dirsfirst.├── .git├── build # source &#96;build.sh&#96;生成├── client├── cmake├── cmd # 命令行工具├── dasher # 监控的前端文件，使用bootstrap和Backbone构建├── docker # docker相关├── docs # 文档├── examples├── externals # 用户自定义程序放置位置├── logstreamer # 日志流相关├── message # Message相关├── packaging # 打包├── pipeline # 流程├── plugins # 插件├── ringbuf├── rpm # build to rpm├── sandbox # 沙盒系统(lua)├── .dockerignore├── .gitattributes├── .gitignore├── .gitmodules├── .travis.yml # for Travis Ci├── CHANGES.txt├── CMakeLists.txt # cmake root file├── CPackConfig.cmake├── Dockerfile├── LICENSE.txt├── README.md├── build.bat├── build.sh├── coverage.txt # 测试代码覆盖率├── env.bat└── env.sh 这是一个比较大的项目，从这里可以学到一些大型工程的基础知识，这是我所欠缺的。 .gitattributes里面是控制git对换行符的处理的；.gitmodules比较有意思，是用来在项目中引用其他git项目的。仔细查找了一些资料，得出的结论是：submodule用起来并不友好，尽量小心使用。 .travis.yml是Travis Ci的配置文件，这个东西是用来做持续集成的。可以看到很多github repo的ReadMe中有一个图标表示build|passing之类的信息，一般就是来自于Travis Ci的反馈信息。 项目使用cmake构建，所以根目录有一个CMakeLists.txt文件。 Dockerfile用来搭建一个纯净的docker环境，方便各种构建。使用sudo docker build .来根据该文件创造docker镜像。 入口从examples/host_filter.go中可以看出，插件的入口在init函数中的pipeline.RegisterPlugin中。那么就从这里开始看起。 这个函数位于pipeline/config.go中，它的作用仅仅是把注册的组件放入一个pipeline包的全局变量中。 通过搜索这个变量，可以看到在plugin_maker.go的NewPluginMaker中被使用，而这个函数是用来通过toml产生新插件的。继续反向搜索使用这个函数的文件，迭代此过程，可以找到整个程序的入口文件heka/cmd/hekad/main.go文件。 自上而下从main函数开始读代码，逻辑是很清晰的。首先是命令行解析，使用了标准库中的flag库。 Heka的命令行参数很少，除了打印版本号以外，只剩下加载配置文件一个功能。 加载配置文件后，首先进行全局配置，然后如果pid文件存在，就检测进程是否仍然存活。 (这里defer的顺序值得学习, os.Exit会忽略所有的defer，所以必须放在最前面，最后执行)。 然后是各种profile的记录，最后来到了pipeline. 通过全局配置生成一个PipelineConfig，然后再遍历配置文件。 PreloadFromConfigFile从TOML配置文件里面生成PluginMaker，并存放起来(category-&gt;maker的映射)。这个过程中就调用了注册插件的构造函数。 LoadConfig集中处理MultiDecoder的情况，然后将plugin分类到几个不同的字段(runner)中。 最后，调用Run方法，开始运行。 运行过程定位到pipeline/pipeline_runner文件中的Run函数，该函数驱动整个工作流的进行。 首先启动的是Output插件，随之是Filter，最后是input相关插件。各个插件运行在不同的goroutine里。最后注册外界信号处理函数。 最后是注册各种清理函数，当程序收到信号退出时执行。 各类Runner要实现pipeline/pipeline_runners.go中的接口才能正常运行。 RunnerPluginRunner是各类Runner的接口（抽象基类），不过这里还有一个更基础的flag_interfaces.go，里面定义了一些接口。","tags":[{"name":"go","slug":"go","permalink":"http://yiuterran.github.io/tags/go/"},{"name":"heka","slug":"heka","permalink":"http://yiuterran.github.io/tags/heka/"}]}]